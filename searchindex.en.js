var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "Team Information\rFull Name Phone Number Email Class Unversity Phan Canh Tuan Dat 0867829257 pcanhtuandat@gmail.com DCT1226 Sai Gon University Ngo Tuan Hung 0776136425 hungnt.020404@gmail.com DKP1221 Sai Gon University Le Trung Kien 0931261009 trungkien1862@gmail.com DCT1213 Sai Gon University Duong Binh Minh 055578938 duongbinhminh10032004@gmail.com DCT1226 Sai Gon University Internship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to …\nReport Content\r1. Worklog\n2. Proposal\n3. Translated Blogs\n4. Events Participated\n5. Workshop\n6. Self-awareness\n7. Sharing and Feedback",
    "description": "Team Information\rFull Name Phone Number Email Class Unversity Phan Canh Tuan Dat 0867829257 pcanhtuandat@gmail.com DCT1226 Sai Gon University Ngo Tuan Hung 0776136425 hungnt.020404@gmail.com DKP1221 Sai Gon University Le Trung Kien 0931261009 trungkien1862@gmail.com DCT1213 Sai Gon University Duong Binh Minh 055578938 duongbinhminh10032004@gmail.com DCT1226 Sai Gon University Internship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to …",
    "tags": [],
    "title": "Internship Report",
    "uri": "/en/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\rTác giả: Gaurav Acharya, Jay Horne – 30/7/2025\nChủ đề: Advanced (300),Amazon FSx for NetApp ONTAP, Technical How-to\nNhững khách hàng on-premises đang sử dụng các mảng lưu trữ NetApp trong trung tâm dữ liệu của riêng họ thường áp dụng các quy tắc kiểm soát truy cập mạng và tường lửa nghiêm ngặt để bảo vệ dữ liệu của mình, tuy nhiên, kiểu bảo mật này thường đưa Network Address Translation (NAT) vào đường truyền giữa các mảng lưu trữ. ONTAP, dù được triển khai tại chỗ hay trên đám mây, đều yêu cầu các cụm lưu trữ được cấu hình với địa chỉ IP tĩnh, và giao thức SnapMirror™ được dùng để sao chép dữ liệu giữa chúng không hỗ trợ NAT. Điều này khiến việc kết nối giữa FSx for NetApp ONTAP và các phiên bản NetApp tại chỗ nằm sau tường lửa có NAT trở nên không thể. Người dùng trong những môi trường như vậy không thể dễ dàng di chuyển dữ liệu giữa hệ thống tại chỗ và Amazon FSx for NetApp ONTAP. Lý tưởng nhất, họ sẽ chọn kết nối thông qua SnapMirror qua internet công cộng, nhưng điều này là không thể trong cấu hình mặc định.\nNetApp SnapMirror™ là một tính năng thường được sử dụng cho khôi phục sau thảm họa (DR), sao lưu và sao chép dữ liệu trong hệ thống lưu trữ NetApp ONTAP, cả tại chỗ lẫn trên đám mây. Amazon FSx for NetApp ONTAP bao gồm SnapMirror như một phần của dịch vụ được quản lý toàn diện trong AWS. Tuy nhiên, vì NetApp SnapMirror không hỗ trợ NAT, và các địa chỉ IP này được xác minh đối chiếu với các hệ thống tệp được ghép cặp, nên cần triển khai một thiết bị NAT dựa trên Amazon Elastic Compute Cloud (Amazon EC2) với các Elastic IPs, để đảm bảo các tiêu đề lớp 3 (L3 headers) trùng khớp giữa mỗi hệ thống tệp và internet.\nTrong bài viết này, chúng tôi thảo luận về một kiến trúc và thiết kế nhằm hợp lý hóa và mở rộng quy mô cho thách thức di chuyển dữ liệu này trong môi trường AWS. Một lựa chọn khác có thể là thiết lập các đường hầm VPN riêng lẻ giữa trung tâm dữ liệu và AWS. Tuy nhiên, cách này sẽ rất khó quản lý khi mở rộng quy mô. Nguyên nhân khiến NetApp SnapMirror không hỗ trợ NAT là vì các siêu dữ liệu được trao đổi trong quá trình ghép cặp — chẳng hạn như các địa chỉ Logical Interface (LIF) — được xác minh đối chiếu với các hệ thống tệp đang được ghép cặp. Nếu chúng không khớp, kết nối sẽ thất bại. Từ thông tin này, ta có thể nói rằng NAT không phá vỡ SnapMirror, mà chính việc thay đổi địa chỉ IP mới là nguyên nhân. Vậy, nếu chúng ta có thể thực hiện NAT theo cách mà SnapMirror vẫn có thể xác minh các địa chỉ IP đó thì sao? Chúng ta chỉ cần đảm bảo rằng các tiêu đề lớp 3 (L3 Headers) trong các gói IP trùng khớp, và cách linh hoạt nhất để làm điều đó là sử dụng một lớp NAT thứ hai.\nTổng quan giải pháp\rĐể làm cho các headers lớp 3 (L3 headers) trùng khớp, chúng ta cần một thiết bị NAT nằm giữa mỗi hệ thống tệp và internet. Thiết bị này có thể là một máy chủ Linux, tường lửa, bộ định tuyến hoặc bất kỳ thiết bị nào trong trung tâm dữ liệu có khả năng thực hiện NAT và đáp ứng đủ băng thông cần thiết. Trong bài viết này, chúng tôi triển khai một phiên bản EC2 được tối ưu hóa cho mạng dựa trên kiến trúc Graviton trong Amazon Virtual Private Cloud (Amazon VPC). Chúng tôi sử dụng phiên bản c7gn.medium, có thông lượng mạng đạt 3.5 GB/s. Kích thước phiên bản này có thể được mở rộng tùy theo nhu cầu băng thông của bạn. Vì yêu cầu về CPU và bộ nhớ là rất nhỏ, lựa chọn này mang lại hiệu suất mạng tốt nhất so với chi phí tại thời điểm viết bài.\nĐiều kiện tiên quyết\rCác điều kiện sau là cần thiết để hoàn thành giải pháp này:\nMột thiết bị NAT mà SnapMirror có thể đi qua tại mỗi hệ thống tệp (filer). Một subnet riêng biệt cho từng hệ thống tệp. Hình 1. Sơ đồ kiến trúc AWS minh họa hai VPC được kết nối thông qua một cổng NAT tự quản lý dựa trên Linux.\rVí dụ\rCấu hình ví dụ được triển khai từ AWS đến AWS để đảm bảo tính trực quan, như minh họa trong hình trên, nhưng một trong hai phía đều có thể được thay thế bằng bất kỳ thiết bị NAT nào thực hiện chức năng tương tự. Tương tự, ví dụ này dựa trên hệ thống tệp FSx for ONTAP trong một Single-Availability Zone (AZ). Nếu bạn đang sử dụng hệ thống tệp Multi-AZ, chúng tôi khuyến nghị triển khai hai phiên bản Amazon EC2 trong từng Availability Zone (AZ) của hệ thống tệp Multi-AZ và định tuyến lưu lượng thông qua phiên bản nằm trong từng AZ đó.\nEIPs\rTrong ví dụ của chúng tôi, chúng tôi sử dụng một địa chỉ EIP cho mỗi giao diện liên cụm (inter-cluster interface) của FSx for ONTAP. Ban đầu, chúng tôi sẽ yêu cầu bốn địa chỉ EIP chưa được gán cho bất kỳ tài nguyên nào. Việc phân bổ cổng có thể cho phép sử dụng ít địa chỉ IP hơn, nhưng điều đó nằm ngoài phạm vi của ví dụ này.\nSecurity Group\rViệc gán trực tiếp các địa chỉ EIP cho Amazon EC2 mà không có bất kỳ giới hạn nào là một thực hành bảo mật kém. Do đó, chúng tôi đã tạo một nhóm bảo mật (security group) trong mỗi VPC và cho phép toàn bộ lưu lượng đến từ bốn địa chỉ EIP này. Về mặt kỹ thuật, chỉ cần mở các cổng TCP 10000, 11104, 11105 và ICMP là đủ, nhưng bộ định tuyến của chúng tôi chỉ chuyển tiếp các cổng này. Phần sau đây tóm tắt cấu hình mạng mẫu cho hai triển khai FSx for ONTAP. Các địa chỉ IP được liệt kê chỉ nhằm mục đích minh họa — các giá trị thực tế trong môi trường của bạn sẽ khác tùy theo cấu hình mạng. Side A: VPC: 10.1.0.0/16FSx ONTAP inter-cluster endpoint 1: 10.1.0.137FSx ONTAP inter-cluster endpoint 2: 10.1.0.125inter_1 EIP: 18.190.143.162inter_2 EIP: 3.128.12.212 Side B: VPC: 10.2.0.0/16FSx ONTAP inter-cluster endpoint 1: 10.2.0.155FSx ONTAP inter-cluster endpoint 2: 10.2.0.110inter_1 EIP: 3.135.134.67inter_2 EIP: 3.146.166.253\nAmazon EC2\rĐể xử lý các NAT, hãy triển khai một phiên bản EC2 chạy RedHat 9, kèm theo nhóm bảo mật mà chúng ta đã tạo trước đó. RedHat không phải là bắt buộc, và bất kỳ bản phân phối Linux nào hỗ trợ nftables đều có thể hoạt động cho bài thực hành này. Đối với mỗi phiên bản EC2, chúng ta cần gắn kết hai địa chỉ EIP trong số các địa chỉ đã tạo. Mỗi địa chỉ EIP này phải được liên kết với một địa chỉ IP riêng (private IP) khác nhau. Cuối cùng, chúng ta phải tắt kiểm tra nguồn/đích (source/destination check) trên giao diện mạng. Điều này cho phép Amazon EC2 gửi các gói tin có địa chỉ IP nguồn không thuộc quyền sở hữu của nó.\nHình 2. Ảnh chụp màn hình của trang tổng quan mạng (network summary page) của một phiên bản EC2, trong đó địa chỉ IP riêng (private IP) và địa chỉ IP công cộng (public IP) được tô sáng (highlighted).\rnftables\rTrên mỗi phiên bản Linux này, chúng ta cần thêm một số quy tắc nftables để xử lý các kết nối. Điều này tạo ra một ánh xạ 1:1 giữa các giao diện của cụm FSx for ONTAP và một địa chỉ EIP. Đối với môi trường ví dụ của chúng ta, cấu hình nftables cho Side B sẽ như sau.\nTùy chọn 1: Chỉnh sửa trực tiếp tệp nftables.\rtable ip nat {\rchain prerouting {\rtype nat hook prerouting priority dstnat; policy accept;\rtcp dport 11104 ip daddr 10.1.0.135 dnat to 10.1.0.125\rtcp dport 11105 ip daddr 10.1.0.135 dnat to 10.1.0.125\rtcp dport 10000 ip daddr 10.1.0.135 dnat to 10.1.0.125\ricmp type { echo-reply, echo-request } ip daddr 10.1.0.135 dnat to 10.1.0.125\rtcp dport 11104 ip daddr 10.1.0.123 dnat to 10.1.0.137\rtcp dport 11105 ip daddr 10.1.0.123 dnat to 10.1.0.137\rtcp dport 10000 ip daddr 10.1.0.123 dnat to 10.1.0.137\ricmp type { echo-reply, echo-request } ip daddr 10.1.0.123 dnat to 10.1.0.137\rip daddr 10.2.0.110 dnat to 3.146.166.253\ricmp type { echo-reply, echo-request } ip daddr 10.2.0.110 dnat to 3.146.166.253\rip daddr 10.2.0.155 dnat to 3.135.134.67\ricmp type { echo-reply, echo-request } ip daddr 10.2.0.155 dnat to 3.135.134.67\r}\rchain postrouting {\rtype nat hook postrouting priority srcnat; policy accept;\rip saddr 10.1.0.125 snat to 10.1.0.135\ricmp type { echo-reply, echo-request } ip saddr 10.1.0.125 snat to 10.1.0.135\rip saddr 10.1.0.137 snat to 10.1.0.123\ricmp type { echo-reply, echo-request } ip saddr 10.1.0.137 snat to 10.1.0.123\rtcp dport 11104 ip saddr 3.146.166.253 snat to 10.2.0.110\rtcp dport 11105 ip saddr 3.146.166.253 snat to 10.2.0.110\rtcp dport 10000 ip saddr 3.146.166.253 snat to 10.2.0.110\ricmp type { echo-reply, echo-request } ip saddr 3.146.166.253 snat to 10.2.0.110\rtcp dport 11104 ip saddr 3.135.134.67 snat to 10.2.0.155\rtcp dport 11105 ip saddr 3.135.134.67 snat to 10.2.0.155\rtcp dport 10000 ip saddr 3.135.134.67 snat to 10.2.0.155\ricmp type { echo-reply, echo-request } ip saddr 3.135.134.67 snat to 10.2.0.155\r}\r}\rTùy chọn 2: Script cấu hình nftables CLI\r#!/bin/bash\r# Install nftables and enable ip forwarding in the kernel\rdnf install -y\recho 1 \u003e /proc/sys/net/ipv4/ip_forward\recho \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf\r# Create the pre-routing and postrouting chains in nftables.\rnft add table ip nat\rnft -- add chain ip nat prerouting { type nat hook prerouting priority -100 \\; }\rnft add chain ip nat postrouting { type nat hook postrouting priority 100 \\; }\r# Unmap any incoming packets from the internet to the local fsx interface\r# Map packets destined to 3.146.166.253(10.2.0.70) -\u003e 10.2.0.110\rnft add rule ip nat prerouting tcp dport 11104 ip daddr 10.2.0.70 dnat to 10.2.0.110\rnft add rule ip nat prerouting tcp dport 11105 ip daddr 10.2.0.70 dnat to 10.2.0.110\rnft add rule ip nat prerouting tcp dport 10000 ip daddr 10.2.0.70 dnat to 10.2.0.110\rnft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.2.0.70 dnat to 10.2.0.110\r# Map packets destined to 3.135.134.67(10.2.0.186) -\u003e 10.2.0.155\rnft add rule ip nat prerouting tcp dport 11104 ip daddr 10.2.0.186 dnat to 10.2.0.155\rnft add rule ip nat prerouting tcp dport 11105 ip daddr 10.2.0.186 dnat to 10.2.0.155\rnft add rule ip nat prerouting tcp dport 10000 ip daddr 10.2.0.186 dnat to 10.2.0.155\rnft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.2.0.186 dnat to 10.2.0.155\r# Map any outgoing packets from the local fsx interface to its respective public IP\r# 10.2.0.110 -\u003e 3.146.166.253(10.2.0.70)\rnft add rule ip nat postrouting ip saddr 10.2.0.110 snat to 10.2.0.70\rnft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 10.2.0.110 snat to 10.2.0.70\r# 10.2.0.155 -\u003e 3.135.134.67(10.2.0.186)\rnft add rule ip nat postrouting ip saddr 10.2.0.155 snat to 10.2.0.186\rnft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 10.2.0.155 snat to 10.2.0.186\r# Unmap any incoming packets for the remote EIPs to the originating FSX internal IP\r# 3.128.12.212 -\u003e 10.1.0.125\rnft add rule ip nat postrouting tcp dport 11104 ip saddr 3.128.12.212 snat to 10.1.0.125\rnft add rule ip nat postrouting tcp dport 11105 ip saddr 3.128.12.212 snat to 10.1.0.125\rnft add rule ip nat postrouting tcp dport 10000 ip saddr 3.128.12.212 snat to 10.1.0.125\rnft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 3.128.12.212 snat to 10.1.0.125\r# 18.190.143.162 -\u003e 10.1.0.137\rnft add rule ip nat postrouting tcp dport 11104 ip saddr 18.190.143.162 snat to 10.1.0.137\rnft add rule ip nat postrouting tcp dport 11105 ip saddr 18.190.143.162 snat to 10.1.0.137\rnft add rule ip nat postrouting tcp dport 10000 ip saddr 18.190.143.162 snat to 10.1.0.137\rnft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 18.190.143.162 snat to 10.1.0.137\r# Map any outgoing packets destined to a remote fsx interface to their respective public IP\r# 10.1.0.125 -\u003e 3.128.12.212\rnft add rule ip nat prerouting ip daddr 10.1.0.125 dnat to 3.128.12.212\rnft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.1.0.125 dnat to 3.128.12.212\r# 10.1.0.137 -\u003e 18.190.143.162\rnft add rule ip nat prerouting ip daddr 10.1.0.137 dnat to 18.190.143.162\rnft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.1.0.137 dnat to 18.190.143.162\r# Persist the config\rnft list ruleset \u003e /etc/sysconfig/nftables.conf\rBảng định tuyến\rKhi cả hai bộ định tuyến đã được cấu hình, chúng ta cần đảm bảo rằng lưu lượng SnapMirror sẽ đi qua chúng. Để thực hiện điều này, chúng ta cập nhật bảng định tuyến (route table) được liên kết với FSx for ONTAP để gửi lưu lượng từ VPC ở xa đến giao diện mạng (network interface) của các phiên bản EC2. Ví dụ, ở Side B, chúng ta thêm một tuyến (route) trỏ 10.1.0.0/16 đến Elastic Network Interface của phiên bản EC2. Ở Side A, chúng ta sẽ làm ngược lại: trỏ 10.2.0.0/16 đến EC2 instance tương ứng.\nHình 3. Bảng định tuyến (Route table) được liên kết với FSx for ONTAP.\rFSx cho ONTAP security group\rLà bước thiết lập cuối cùng, chúng ta cần cho phép mạng VPC từ xa được kết nối đến các giao diện của FSx for ONTAP. Để làm điều này, chúng ta đã thêm dải địa chỉ 10.0.0.0/8 vào nhóm bảo mật (security group) trên cả hai phiên bản FSx for ONTAP.\nKết nối ngang hàng giữa các hệ thống tệp\rKhi các kết nối mạng đã được thiết lập, việc còn lại là kết nối ngang hàng (peer) giữa các hệ thống tệp FSx for ONTAP. Trước tiên, chúng ta đăng nhập vào Side A và bắt đầu yêu cầu peering.\nSau đó, chúng ta đăng nhập vào Side B và thực thi cùng một lệnh, nhưng không sử dụng tùy chọn generate passphrase và dùng các địa chỉ IP từ Side A. Thao tác này được thực hiện từ phía Side B của hệ thống tệp FSx for ONTAP.\nTừ đây, các SVM (Storage Virtual Machine) có thể được kết nối ngang hàng (peered) và một mối quan hệ SnapMirror có thể được tạo ra.\nDọn dẹp\rViệc chạy các phiên bản EC2 và hệ thống tệp FSx for ONTAP sẽ phát sinh chi phí. Hãy nhớ xóa và chấm dứt (terminate) các tài nguyên này nếu chúng không còn cần thiết. Để xóa một hệ thống tệp, hãy làm theo hướng dẫn trong tài liệu hướng dẫn người dùng FSx for NetApp ONTAP. Để chấm dứt các phiên bản EC2, hãy truy cập phần Terminate Your Instance trong tài liệu hướng dẫn người dùng Amazon EC2.\nLink bài viết gốc: (https://aws.amazon.com/blogs/storage/highly-scalable-solution-design-to-replicate-data-using-amazon-fsx-for-netapp-ontap-and-snapmirror/)",
    "description": "Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\rTác giả: Gaurav Acharya, Jay Horne – 30/7/2025\nChủ đề: Advanced (300),Amazon FSx for NetApp ONTAP, Technical How-to\nNhững khách hàng on-premises đang sử dụng các mảng lưu trữ NetApp trong trung tâm dữ liệu của riêng họ thường áp dụng các quy tắc kiểm soát truy cập mạng và tường lửa nghiêm ngặt để bảo vệ dữ liệu của mình, tuy nhiên, kiểu bảo mật này thường đưa Network Address Translation (NAT) vào đường truyền giữa các mảng lưu trữ. ONTAP, dù được triển khai tại chỗ hay trên đám mây, đều yêu cầu các cụm lưu trữ được cấu hình với địa chỉ IP tĩnh, và giao thức SnapMirror™ được dùng để sao chép dữ liệu giữa chúng không hỗ trợ NAT. Điều này khiến việc kết nối giữa FSx for NetApp ONTAP và các phiên bản NetApp tại chỗ nằm sau tường lửa có NAT trở nên không thể. Người dùng trong những môi trường như vậy không thể dễ dàng di chuyển dữ liệu giữa hệ thống tại chỗ và Amazon FSx for NetApp ONTAP. Lý tưởng nhất, họ sẽ chọn kết nối thông qua SnapMirror qua internet công cộng, nhưng điều này là không thể trong cấu hình mặc định.",
    "tags": [],
    "title": "Blog 1",
    "uri": "/en/3-translated_blogs/blog_1/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 1 Objectives\rLearn the regulations Connect with other FCJ members Form team and decide team project Understand and practice basic AWS services Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Get acquainted with FCJ members 29/09/2025 29/09/2025 - Read and take note of internship unit rules and regulations Rules and regulations - Learn and practice making a static website with Hugo Hugo quickstart, Learn Hugo Theme - Create AWS account. Practice creating Users group, Users (IAM user) Create AWS account; Create user, group user 2 - Learn and practice creating Budget (Template \u0026 Custom: Cost, Usage, Saving plans, Reservation) 30/09/2025 30/09/2025 Create budget - Update worklog Sample worklog 3 - Learn about support packages, types of support request, how to create a support 01/10/2025 01/10/2025 Support packages 4 - Update worklog (UI) 02/10/2025 5 - Learn theory about VPC (Subnet, Route Table, Internet Gateway, NAT Gateway) 03/10/2025 03/10/2025 AWS Virtual Private Cloud - Update worklog",
    "description": "Week 1 Objectives\rLearn the regulations Connect with other FCJ members Form team and decide team project Understand and practice basic AWS services Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Get acquainted with FCJ members 29/09/2025 29/09/2025 - Read and take note of internship unit rules and regulations Rules and regulations - Learn and practice making a static website with Hugo Hugo quickstart, Learn Hugo Theme - Create AWS account. Practice creating Users group, Users (IAM user) Create AWS account; Create user, group user 2 - Learn and practice creating Budget (Template \u0026 Custom: Cost, Usage, Saving plans, Reservation) 30/09/2025 30/09/2025 Create budget - Update worklog Sample worklog 3 - Learn about support packages, types of support request, how to create a support 01/10/2025 01/10/2025 Support packages 4 - Update worklog (UI) 02/10/2025 5 - Learn theory about VPC (Subnet, Route Table, Internet Gateway, NAT Gateway) 03/10/2025 03/10/2025 AWS Virtual Private Cloud - Update worklog",
    "tags": [],
    "title": "Week 1 Worklog",
    "uri": "/en/1-worklog/1.1-week_1/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Week 1: Orientation \u0026 Project Setup\nWeek 2: Core AWS Basics \u0026 Project Planning\nWeek 3: System Design \u0026 Intermediate AWS Services\nWeek 4: Authentication Development \u0026 API Foundations\nWeek 5: User Service Development \u0026 Scaling Concepts\nWeek 6: Database \u0026 Caching Integration\nWeek 7: Advanced Services \u0026 Deployment Preparation\nWeek 8: Experimental Implementation \u0026 Deployment\nWeek 9: Doing task H…\nWeek 10: Doing task I…\nWeek 11: Doing task J…\nWeek 12: Doing task K…",
    "description": "Week 1: Orientation \u0026 Project Setup\nWeek 2: Core AWS Basics \u0026 Project Planning\nWeek 3: System Design \u0026 Intermediate AWS Services\nWeek 4: Authentication Development \u0026 API Foundations\nWeek 5: User Service Development \u0026 Scaling Concepts\nWeek 6: Database \u0026 Caching Integration\nWeek 7: Advanced Services \u0026 Deployment Preparation\nWeek 8: Experimental Implementation \u0026 Deployment\nWeek 9: Doing task H…\nWeek 10: Doing task I…\nWeek 11: Doing task J…\nWeek 12: Doing task K…",
    "tags": [],
    "title": "Worklog",
    "uri": "/en/1-worklog/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\rTác giả: Gabe Kafity – 29/7/2025\nChủ đề: Best Practices, High Performance Computing\nTrong ngành hàng không vũ trụ đang phát triển nhanh chóng ngày nay, khả năng đổi mới nhanh chóng và hiệu quả không chỉ là một lợi thế – mà đó là một điều cần thiết. Khi các công nghệ như UAVs (Unmanned Aerial Vehicle) tự hành, các chùm vệ tinh (satellite constellations), tên lửa tái sử dụng và thực tế tăng cường/ảo (augmented/virtual reality) tiến bộ, khả năng đổi mới nhanh chóng mang lại cho các tổ chức hàng không vũ trụ lợi thế cạnh tranh. High Performance Computing (HPC) rất quan trọng đối với đổi mới hàng không vũ trụ và đã trở thành nền tảng của sự tiến bộ trong ngành hàng không vũ trụ. Bất kể quy mô, tuổi đời hay tốc độ lặp lại (iteration speed) của một tổ chức, Amazon Web Services (AWS) luôn sẵn sàng giúp thúc đẩy các sứ mệnh hàng không vũ trụ của họ tiến lên.\nTrong bài đăng này, chúng ta sẽ khám phá lý do tại sao, cách thức và những gì khách hàng hàng không vũ trụ thường làm với HPC trong AWS.\nHiện Trạng của HPC\rCơ sở hạ tầng HPC on-premises truyền thống thường đòi hỏi đầu tư vốn đáng kể và có thể mất hàng tháng, hoặc thậm chí hàng năm, để mua sắm và triển khai. Sau khi được triển khai, các cluster thường chạy ở mức hoặc gần 100% tỷ lệ sử dụng (utilization). Tỷ lệ sử dụng cơ sở hạ tầng cao này dẫn đến thời gian chờ đợi lâu cho các HPC job mới đi vào hàng đợi (queue). Các nhà khoa học nghiên cứu và kỹ sư phải chờ đợi (thường là hàng tuần) để job của họ đi qua hàng đợi và chạy, trước khi họ có thể phân tích kết quả và lặp lại sự đổi mới của họ. Ngoài ra, chu kỳ khấu hao (depreciation cycle) của cơ sở hạ tầng HPC on-premises thường là 5-8 năm. Điều này có nghĩa là trong khi cơ sở hạ tầng HPC ngày càng tốt hơn mỗi năm, các cluster on-premises bị mắc kẹt với việc sử dụng cơ sở hạ tầng kém hiệu quả hơn cho đến khi đến lúc làm mới phần cứng (hardware refresh), lúc đó chu kỳ cơ sở hạ tầng cũ (legacy infrastructure) lại bắt đầu lại.\nNgược lại, AWS cung cấp cho các tổ chức quyền truy cập tức thì vào các tài nguyên tính toán gần như không giới hạn, cho phép họ tăng tốc đổi mới trong khi kiểm soát chi phí. Việc triển khai diễn ra chỉ trong vài phút và khách hàng chỉ trả tiền cho những gì họ sử dụng. Tận dụng các khả năng của cloud, các HPC cluster trong AWS mở rộng quy mô (scale out) để đáp ứng nhu cầu, xử lý job thành công và thu hẹp quy mô (scale back in) khi hàng đợi trống. Tính đàn hồi (elasticity) này làm giảm đáng kể thời gian chờ đợi cho các kỹ sư và nhà khoa học, trong khi chỉ phải trả tiền cho các tài nguyên khi chúng đang chạy. Ngoài ra, AWS cải thiện cơ sở hạ tầng HPC của chúng tôi với tốc độ của phần mềm. Điều này có nghĩa là thay vì chờ đợi nhiều năm để làm mới phần cứng nhằm hiện đại hóa cơ sở hạ tầng HPC, khách hàng của AWS liên tục có quyền truy cập vào cơ sở hạ tầng HPC mới nhất, hiệu suất/giá cả tốt nhất từ Amazon và các đối tác của chúng tôi (NVIDIA, Intel, AMD, v.v.).\nHình 1: Đối lập giữa việc chạy các HPC workload on-premises (trái) so với trong AWS (phải). Bên trái bị giới hạn bởi dung lượng trung tâm dữ liệu cố định, nơi thời gian chờ đợi trong hàng đợi dài và cơ sở hạ tầng nhanh chóng trở nên lỗi thời. Bên phải có dung lượng đàn hồi (elastic capacity) có thể mở rộng theo nhu cầu, rút ngắn thời gian chờ đợi trong hàng đợi trong khi chạy trên cơ sở hạ tầng hiện đại hơn.\rCác HPC Workload Chủ chốt trong Hàng không Vũ trụ\rComputational Fluid Dynamics (CFD)\nCác tổ chức hàng không vũ trụ đang tận dụng các tài nguyên tính toán mạnh mẽ của AWS để thực hiện các mô phỏng CFD phức tạp nhằm tối ưu hóa thiết kế máy bay và phân tích hệ thống đẩy (propulsion systems). Sử dụng các dịch vụ HPC của AWS, các tổ chức có thể chạy các workload như Siemens STAR-CCM+, Ansys Fluent hoặc mô phỏng OpenFOAM với hàng nghìn core, giảm thời gian mô phỏng từ hàng tuần xuống hàng giờ.\nPhân tích Cấu trúc (Structural Analysis)\nNhu cầu của thiết kế hàng không vũ trụ hiện đại đòi hỏi phân tích cấu trúc chuyên sâu đối với những thứ như độ bền sản phẩm, độ rung và âm học (acoustics). Cho dù đó là thử nghiệm vật liệu composite mới hay thực hiện phân tích độ mỏi (fatigue analysis) trên các thành phần quan trọng, khả năng HPC của AWS cho phép khách hàng chạy nhiều mô phỏng đồng thời bằng cách sử dụng phần mềm như Dassault Systèmes Abaqus hoặc Simcenter Nastran, đẩy nhanh quá trình lặp lại thiết kế (design iteration process).\nLập kế hoạch Sứ mệnh và Hoạt động Không gian (Mission Planning and Space Operations)\nKhi ngành hàng không vũ trụ phát triển và đổi mới, các tổ chức đang sử dụng các dịch vụ HPC của AWS để mô phỏng cơ học quỹ đạo phức tạp (orbital mechanics), tối ưu hóa việc triển khai các chùm vệ tinh (satellite constellation deployments) và quản lý các cửa sổ phóng (launch windows) một cách hiệu quả. Các mô phỏng này đòi hỏi số lượng lớn các compute cluster, cơ sở hạ tầng mạng và lưu trữ thế hệ tiếp theo, có thể dễ dàng triển khai và tự động mở rộng quy mô dựa trên nhu cầu.\nHình 2: Ví dụ về các hình ảnh trực quan (visualizations) của các HPC workload dành cho khách hàng hàng không vũ trụ.\rMỗi loại workload mô phỏng đều có các yêu cầu riêng về loại cơ sở hạ tầng mà nó chạy trên. AWS cho phép khách hàng tối ưu hóa cấu hình cơ sở hạ tầng, cluster và hàng đợi của họ để chạy hiệu quả workload mô hình hóa hoặc mô phỏng đang thực hiện.\nBộ Công Cụ HPC của AWS\rHigh performance computing đòi hỏi cơ sở hạ tầng hiệu quả ở mọi lớp của stack. Điều này bao gồm các công cụ tính toán (compute), lưu trữ (storage), mạng (networking) và điều phối (orchestration) cho phép các tổ chức hàng không vũ trụ đổi mới nhanh chóng. Trong phần này, chúng ta sẽ xem xét một số công cụ mà khách hàng hàng không vũ trụ sử dụng trên AWS cho các HPC workload.\nAmazon Elastic Compute Cloud (Amazon EC2) cung cấp nền tảng tính toán rộng nhất và sâu nhất, với hơn 850 instance. Amazon EC2 có nhiều loại instance type hiệu suất cao được tối ưu hóa cho Accelerated Computing và HPC. AWS Nitro System được giới thiệu vào năm 2017 và được xây dựng dựa trên sự kết hợp giữa phần cứng, phần mềm và firmware được xây dựng có mục đích. Nó cung cấp cơ sở hạ tầng ảo hóa cơ bản cho các EC2 instance. Theo truyền thống, các hypervisor bảo vệ phần cứng vật lý và BIOS, ảo hóa CPU, lưu trữ, mạng và cung cấp một bộ khả năng quản lý phong phú. Với Nitro System, chúng tôi tách rời các chức năng đó, chuyển chúng sang phần cứng và phần mềm chuyên dụng, đồng thời giảm chi phí bằng cách cung cấp thực tế tất cả các tài nguyên của một server cho các instance của bạn. Điều này làm giảm thiểu chi phí ảo hóa (virtualization overhead).\nHình 3: Nitro System làm giảm thiểu chi phí hypervisor overhead để các instance của khách hàng có thể chạy ở mức ~100% dung lượng bare metal. Vùng màu nhạt hơn cho thấy các hoạt động kỹ thuật mà Nitro đảm nhiệm, trong khi vùng màu đậm hơn cho thấy các instance của khách hàng chạy trên Nitro.\rDịch vụ được quản lý (managed service) mới nhất của AWS giúp đơn giản hóa HPC trên AWS là AWS Parallel Computing Service (AWS PCS). AWS PCS giúp khách hàng dễ dàng chạy và mở rộng quy mô các HPC workload cũng như xây dựng các mô hình khoa học và kỹ thuật trên AWS bằng cách sử dụng Slurm làm trình quản lý workload. Dịch vụ được quản lý này cho phép bạn xây dựng các HPC cluster hoàn chỉnh tích hợp các tài nguyên tính toán (compute), lưu trữ (storage), mạng (networking) và hình ảnh trực quan (visualization), và mở rộng quy mô liền mạch từ 0 đến hàng nghìn instance. Thay vào đó, khách hàng có thể sử dụng AWS ParallelCluster, đây là một công cụ quản lý cluster mã nguồn mở (open-source), giàu tính năng, giúp dễ dàng cấu hình, triển khai và quản lý các HPC cluster trên AWS. Công cụ này được sử dụng thông qua các mẫu cơ sở hạ tầng dưới dạng mã (infrastructure as code templates), và có giao diện đồ họa dựa trên web tùy chọn. AWS ParallelCluster không phải là một dịch vụ được quản lý (managed service) và do đó yêu cầu khách hàng phải tự triển khai.\nAWS Batch giúp bạn chạy các batch computing workload trên AWS Cloud. Batch computing là một cách phổ biến để các nhà phát triển, nhà khoa học và kỹ sư truy cập vào một lượng lớn tài nguyên tính toán. AWS Batch loại bỏ công việc nặng nhọc không tạo ra sự khác biệt trong việc cấu hình và quản lý cơ sở hạ tầng cần thiết, giống như phần mềm batch computing truyền thống. Dịch vụ này có thể cấp phát tài nguyên hiệu quả để phản hồi các job đã gửi nhằm loại bỏ các hạn chế về dung lượng (capacity constraints), giảm chi phí tính toán và cung cấp kết quả nhanh chóng.\nCho đến nay, chúng ta đã thảo luận về các tài nguyên tính toán và công cụ điều phối (orchestration tooling) cho phép các HPC workload chạy trên AWS. Có những thành phần khác quan trọng đối với cơ sở hạ tầng HPC, chẳng hạn như mạng kết nối các compute node và lưu trữ hiệu suất cao (high-performance storage). Trước tiên, hãy xem xét về mạng.\nElastic Fabric Adapter (EFA) là một giao diện mạng cho các Amazon EC2 instance cho phép khách hàng chạy các ứng dụng đòi hỏi mức độ giao tiếp giữa các node (inter-node communications) cao trên quy mô lớn trên AWS. Giao diện phần cứng bỏ qua hệ điều hành (OS bypass hardware interface) được xây dựng tùy chỉnh của nó giúp tăng cường hiệu suất giao tiếp giữa các instance (inter-instance communications), điều này rất quan trọng để mở rộng quy mô các HPC workload có độ trễ thấp (low latency).\nHình 4: Cho thấy network infrastructure stack của EFA, trực quan hóa cách kernel được bỏ qua để tăng tốc hiệu suất.\rAWS cung cấp nhiều dịch vụ lưu trữ, chẳng hạn như Amazon Simple Storage Service (Amazon S3), Amazon Elastic Block Storage (Amazon EBS), cùng nhiều dịch vụ khác. Tất cả các dịch vụ lưu trữ này có thể được sử dụng khi xây dựng các HPC cluster trong AWS. Tuy nhiên, nhiều HPC workload được hưởng lợi rất nhiều từ bộ lưu trữ chuyên biệt, chẳng hạn như Lustre – một hệ thống tệp phân tán, song song, mã nguồn mở được thiết kế cho HPC và lưu trữ dữ liệu quy mô lớn. Amazon đã giải quyết nhu cầu này cho các HPC và AI/ML workload bằng cách cung cấp Amazon FSx for Lustre.\nAmazon FSx for Lustre là dịch vụ lưu trữ chia sẻ được quản lý hoàn toàn (fully managed shared storage service), được xây dựng trên hệ thống tệp song song, hiệu suất cao phổ biến nhất thế giới. Nó cho phép khách hàng tăng tốc các compute workload với bộ lưu trữ chia sẻ cung cấp độ trễ dưới mili giây (sub-millisecond latencies), thông lượng (throughput) lên đến hàng trăm GB/s, và hàng triệu IOPS, tất cả đều được quản lý hoàn toàn và có thể triển khai trong vài phút, mà không gặp khó khăn trong việc thiết lập và quản trị.\nMột Ngày của một HPC Job trên AWS\rGiờ đây chúng ta đã hiểu rõ hơn về các trường hợp sử dụng HPC và các dịch vụ mà khách hàng hàng không vũ trụ đang tận dụng trên AWS, hãy tổng hợp tất cả lại thành một quy trình làm việc (workflow) chức năng. Sơ đồ dưới đây minh họa một khách hàng đang chạy các HPC workload trong môi trường hybrid cloud của họ, giữa trung tâm dữ liệu on-premises và AWS. Người dùng cuối từ bên trong ranh giới mạng của khách hàng kết nối với Login Nodes thông qua SSH. Từ Login Nodes, các HPC job được gửi đi và thêm vào hàng đợi job. Điều này kích hoạt việc phân bổ các compute node, nơi các EC2 instance được mở rộng quy mô để đáp ứng nhu cầu hàng đợi và chạy các job. Các EC2 này có khả năng kết nối với các AWS services, chạy cho đến khi HPC job hoàn thành, và sau đó tự động thu hẹp quy mô trở lại (scale back down).\nHình 5: Ví dụ về quy trình làm việc triển khai các HPC job tận dụng AWS Parallel Computing Service.\rChúng ta đã đề cập đến một số trường hợp sử dụng, dịch vụ và quy trình làm việc mà khách hàng hàng không vũ trụ tận dụng trên AWS. Bước hợp lý tiếp theo là nghe từ chính khách hàng\nCác Câu Chuyện Thành Công trong Hàng không Vũ trụ từ Thực tế\rHypersonix Launch Systems đã giảm 92% thời gian CFD simulation pipeline của họ, từ 3 tháng xuống còn 1 tuần, bằng cách di chuyển sang AWS. Họ đã chạy các STAR-CCM+ workload on-premises, trong một HPC cluster bị sử dụng quá mức và lỗi thời. Thời gian chờ đợi trong hàng đợi kéo dài khiến các nhà nghiên cứu và kỹ sư của họ thường xuyên phải ngồi không. AWS đã trả lại thời gian cho các đội ngũ kỹ thuật này, để họ có thể đổi mới và đưa sản phẩm ra thị trường nhanh hơn. “Tôi tin rằng chúng tôi có thể nổi bật so với các công ty lớn hơn vì chúng tôi có khả năng và tài nguyên cloud mà chúng tôi cần trên AWS.”, Tiến sĩ Stephen Hall, Trưởng phòng Mô phỏng Cấu trúc Nhiệt CFD Tiên tiến tại Hypersonix Launch Systems, cho biết.\nBoom Supersonic sử dụng AWS để tăng tốc thiết kế và xây dựng máy bay siêu thanh của họ. Họ có thể chạy hàng nghìn mô phỏng tiên tiến đồng thời trên AWS, dẫn đến năng suất tăng ước tính gấp 6 lần so với môi trường on-prem của họ. Boom đã sử dụng hơn 53 triệu compute hours trên AWS để hoàn thành máy bay chở khách Overture của họ. “AWS, nhà cung cấp cloud hàng đầu thế giới, sẽ giúp chúng tôi liên tục tinh chỉnh các thiết kế của mình.”, Blake Scholl, Người sáng lập và CEO của Boom Supersonic, cho biết.\nĐể biết thêm thông tin về các câu chuyện thành công của khách hàng, vui lòng truy cập: (https://aws.amazon.com/solutions/case-studies/)\nKết Luận\rHPC dựa trên Cloud đang cách mạng hóa cách các tổ chức hàng không vũ trụ đổi mới. AWS cung cấp khả năng mở rộng (scalability), hiệu suất và bảo mật cần thiết cho các HPC workload hàng không vũ trụ khắt khe nhất. Khi ngành công nghiệp tiếp tục phát triển, cam kết của chúng tôi trong việc hỗ trợ đổi mới hàng không vũ trụ vẫn mạnh mẽ hơn bao giờ hết.\nLink bài viết gốc: (https://aws.amazon.com/blogs/hpc/accelerating-aerospace-innovation-high-performance-computing-hpc-on-amazon-web-services-aws/)",
    "description": "Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\rTác giả: Gabe Kafity – 29/7/2025\nChủ đề: Best Practices, High Performance Computing\nTrong ngành hàng không vũ trụ đang phát triển nhanh chóng ngày nay, khả năng đổi mới nhanh chóng và hiệu quả không chỉ là một lợi thế – mà đó là một điều cần thiết. Khi các công nghệ như UAVs (Unmanned Aerial Vehicle) tự hành, các chùm vệ tinh (satellite constellations), tên lửa tái sử dụng và thực tế tăng cường/ảo (augmented/virtual reality) tiến bộ, khả năng đổi mới nhanh chóng mang lại cho các tổ chức hàng không vũ trụ lợi thế cạnh tranh. High Performance Computing (HPC) rất quan trọng đối với đổi mới hàng không vũ trụ và đã trở thành nền tảng của sự tiến bộ trong ngành hàng không vũ trụ. Bất kể quy mô, tuổi đời hay tốc độ lặp lại (iteration speed) của một tổ chức, Amazon Web Services (AWS) luôn sẵn sàng giúp thúc đẩy các sứ mệnh hàng không vũ trụ của họ tiến lên.",
    "tags": [],
    "title": "Blog 2",
    "uri": "/en/3-translated_blogs/blog_2/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Multi-Region SaaS Task Management Platform\rA Global AWS Solution for Low-Latency, Resilient Collaboration\r1. Executive Summary\rThe Multi-Region SaaS Task Management Platform is designed to deliver a Trello/Asana-like experience with low latency, high availability, and regional scalability across Asia-Pacific.\nBuilt with Spring Boot microservices on EC2 Auto Scaling Groups and RDS MySQL Multi-Region setup, the platform ensures real-time collaboration, task/board management, and cross-region resilience.\nBy leveraging AWS global infrastructure, the system provides:\nLow-latency access through RDS Read Replicas and regional compute High availability via multi-AZ deployment and cross-region failover Global content delivery using S3 Multi-Region Access Points and CloudFront Cost-optimized architecture suitable for Free Tier constraints The result is a platform where users in Southeast Asia and Australia collaborate seamlessly — even during regional outages — while maintaining operational efficiency and cost predictability.\n2. Problem Statement\r2.1. What’s the Problem?\rTraditional SaaS task management platforms typically operate within a single AWS region, which can lead to several limitations:\nHigh Latency: Users located far from the primary region experience slow response times and poor user experience Single Point of Failure: Regional outages can cause complete service disruption Limited Scalability: Geographic expansion requires significant infrastructure changes Poor Disaster Recovery: No automated failover mechanisms for business continuity 2.2. The Solution\rThis project introduces a multi-region architecture using AWS global services.\nKey highlights:\nRDS MySQL with Cross-Region Read Replicas – Primary writer in Singapore (ap-southeast-1) with read replica in Sydney (ap-southeast-2) EC2 Auto Scaling Groups per region for scalable, resilient compute Route 53 latency-based routing for intelligent traffic distribution to the nearest region S3 Multi-Region Access Points + Cross-Region Replication (CRR) for global file delivery Regional caching with ElastiCache Redis for session management and hot data Application Load Balancers for high availability and health checks This architecture achieves resilience, performance, and scalability while optimizing for cost-effectiveness within AWS Free Tier constraints.\n2.3. Benefits and ROI\rReduced latency for users across Southeast Asia and Australia (20-30ms between regions) High availability with multi-AZ deployment and automated failover Cost-efficient design optimized for Free Tier and small-scale production Scalable foundation ready for enterprise growth and additional regions Business continuity with cross-region disaster recovery capabilities 3. Solution Architecture\rFigure 1. Architecture solution\r3.1. Architecture Overview\rPrimary Region: ap-southeast-1 (Singapore)\nRDS MySQL Writer (db.t3.micro) with Multi-AZ EC2 Auto Scaling Group (t3.micro instances) ElastiCache Redis (t3.micro) for session caching Application Load Balancer S3 bucket for primary storage VPC with public/private subnets, NAT Gateway, Internet Gateway Secondary Region: ap-southeast-2 (Sydney)\nRDS Read Replica (db.t3.micro) EC2 Auto Scaling Group (t3.micro instances) ElastiCache Redis (t3.micro) for session caching Application Load Balancer S3 bucket (replica via CRR) VPC with public/private subnets, NAT Gateway, Internet Gateway Global Services:\nRoute 53 for DNS and latency-based routing S3 Multi-Region Access Points CloudFront CDN for static asset delivery API Gateway (optional) for API management 3.2. Microservices Architecture\rThe platform consists of the following Spring Boot microservices:\nAuth Service - User authentication, JWT token management Board Service - Board creation, management, permissions Task Service - Task CRUD operations, assignments, status updates Notification Service - Real-time notifications, event handling User Service - User profile management, preferences Each service is:\nContainerized using Docker Deployed on EC2 instances via Auto Scaling Groups Load-balanced via Application Load Balancer Connected to RDS MySQL (writes to primary, reads from local replica) Caching frequently accessed data in ElastiCache Redis 3.3. AWS Services Used\rCategory Services Purpose Compute EC2 Auto Scaling Groups Scalable microservices hosting across regions Database Amazon RDS (MySQL/PostgreSQL) Relational database with Multi-AZ and Read Replicas Caching ElastiCache Redis Session management \u0026 hot data caching per region Storage Amazon S3 + Multi-Region Access Points Object storage with cross-region replication Networking VPC, Internet Gateway, NAT Gateway, ALB Global DNS routing and API management DNS \u0026 Routing Amazon Route 53, API Gateway Build, deploy, and replicate container images Security Security Groups, IAM Network security and access control Observability CloudWatch Logging, metrics, monitoring \u0026 alarms 4. Service Roles Overview\rAWS Service Role in Architecture Route 53 DNS routing users to nearest region based on latency with health check failover API Gateway API management layer with throttling, request validation and regional endpoints VPC Isolated virtual network (10.0.0.0/16 for ap-southeast-1, 10.1.0.0/16 for ap-southeast-2) Public Subnet Hosts Application Load Balancer with internet access via Internet Gateway Private Subnet Hosts EC2 instances, RDS, and ElastiCache without direct internet access Internet Gateway Enables public subnet resources (ALB) to communicate with the internet NAT Gateway Allows private subnet resources (EC2, RDS) to access internet securely for updates Application Load Balancer Distributes incoming traffic across EC2 instances with health checks and SSL termination EC2 Auto Scaling Groups Automatically scales Spring Boot microservices (t3.micro) based on CPU/traffic demand ElastiCache for Redis In-memory caching for sessions, API responses, and frequently accessed data per region Amazon RDS Primary database writer in Singapore with async read replica in Sydney S3 Buckets Object storage for user files, attachments, and static assets per region S3 Multi-Region Access Points Unified global endpoint for accessing S3 objects with automatic routing to nearest region S3 Cross-Region Replication Automatically replicates objects from Singapore S3 bucket to Sydney for redundancy Security Groups Stateful firewall rules controlling inbound/outbound traffic for EC2, RDS, ALB, ElastiCache IAM Roles Secure service-to-service authentication without hardcoded credentials CloudWatch Centralized monitoring, logging, custom metrics, dashboards and alarms 5. Service Flow\r5.1. User Request Flow\rRead Operations (90% of traffic):\nUser in Singapore accesses app.taskmanager.com Route 53 resolves to ap-southeast-1 (Singapore) based on latency CloudFront serves static assets (CSS, JS, images) from edge location API request → ALB (ap-southeast-1) → EC2 Auto Scaling Group Spring Boot service checks ElastiCache Redis for cached data Cache HIT → Return immediately (latency \u003c 5ms) Cache MISS → Query RDS MySQL Writer (local read, latency 5-10ms) Response returned to user User in Sydney/Australia:\nRoute 53 resolves to ap-southeast-2 (Sydney) based on latency CloudFront serves static assets from Sydney edge location API request → ALB (ap-southeast-2) → EC2 Auto Scaling Group Spring Boot service checks local ElastiCache Redis Cache HIT → Return immediately Cache MISS → Query RDS Read Replica (local read, latency 5-10ms) Response returned to user Write Operations (10% of traffic):\nUser in Singapore:\nWrite request → ALB (ap-southeast-1) → EC2 → RDS Writer Data committed to primary database (latency 10-20ms) Async replication to Sydney Read Replica (5-30 seconds lag) ElastiCache invalidated/updated in both regions via pub/sub Success response to user User in Sydney:\nWrite request → ALB (ap-southeast-2) → EC2 Spring Boot forwards write to ap-southeast-1 RDS Writer Cross-region write (latency 50-100ms, acceptable for writes) Async replication back to Sydney Read Replica Cache invalidation via EventBridge + Lambda Success response to user 5.2. Developer CI/CD Flow\rDevelopment \u0026 Deployment Workflow:\nDeveloper commits code to Git repository Build Spring Boot application (JAR or Docker image) Upload artifacts to S3 bucket in ap-southeast-1 S3 Cross-Region Replication automatically copies to ap-southeast-2 Update EC2 Auto Scaling Group launch template with new AMI/image Perform rolling deployment: Launch new EC2 instances with updated code ALB performs health checks Gradually shift traffic from old to new instances Terminate old instances after successful deployment CloudWatch monitors deployment metrics and application health Rollback mechanism: Keep previous version in S3 for quick revert Note: CI/CD services like CodePipeline can be added later for full automation. For initial implementation, focus on manual deployment process.\n5.3. Data \u0026 HA/DR Flow\rData Replication Strategy:\nData Type Replication Method Latency Purpose Transactional Data RDS async replication 5-30 seconds User data, boards, tasks, comments Session Data ElastiCache Redis (per region) N/A (regional) User sessions, temporary auth tokens Static Assets S3 Cross-Region Replication Minutes Images, attachments, frontend files Application Code S3 CRR for artifacts Minutes Spring Boot JARs, Docker images Failover Scenarios:\nScenario 1: EC2 Instance Failure\nALB health check detects unhealthy EC2 instance ALB stops routing traffic to failed instance Auto Scaling Group launches replacement instance New instance passes health check and receives traffic Duration: 2-3 minutes | Impact: None (other instances handle load)\nScenario 2: Availability Zone Failure\nAll EC2 instances in one AZ fail ALB routes all traffic to healthy AZ (if Multi-AZ configured) Auto Scaling Group launches replacement capacity RDS Multi-AZ automatically fails over to standby (if configured) Duration: 5-10 minutes | Impact: Possible brief latency spike\nScenario 3: Regional Failure (Singapore)\nRoute 53 health checks detect region failure DNS failover automatically routes to ap-southeast-2 (Sydney) Manual RDS promotion: Promote Sydney Read Replica to Writer Update application configuration to point to new writer endpoint All traffic now served from Sydney region Duration: 15-30 minutes | Impact: Read-only mode until promotion\n6. Budget Estimation\rMinimal Setup (Recommended for Free Tier)\nAWS Service Cost (per month) Notes EC2 (t3.micro) $0.00 750 hours Free Tier, 4 instances × 12h/day = 720h/month RDS MySQL (db.t3.micro) $15.00 Writer only, 744 hours - exceeds Free Tier RDS Read Replica (db.t3.micro) $15.00 Sydney region, 744 hours S3 Standard $2.00 10 GB storage, cross-region replication Route 53 $1.00 1 hosted zone, basic queries CloudWatch $3.00 Basic metrics, 3-day log retention Data Transfer $5.00 Cross-region + internet egress VPC $0.00 VPC itself is free, NAT Gateway excluded Total $41.00 $492/year 7. Risk Assessment\rRisk Matrix\nRisk Impact Probability Priority RDS Replication Lag Medium Medium High Cross-Region Write Latency Medium High Medium NAT Gateway SPOF High Low Medium Cost Overruns High High Critical Free Tier Exhaustion Medium High High Manual Failover Complexity High Medium High Security Vulnerabilities High Medium Critical Data Consistency Issues High Low Medium Mitigation Strategies\nNetwork \u0026 Infrastructure:\nRDS Replication: Monitor replication lag with CloudWatch alarms (\u003c60s threshold). Implement application-level checks for critical writes. NAT Gateway: Deploy in multiple Availability Zones. Consider VPC endpoints for S3/CloudWatch to reduce NAT dependency. Auto Scaling: Pre-warm instances during known traffic peaks. Optimize Spring Boot startup time.\nCost Management:\nAWS Budgets: Set up alerts at 80%, 90%, 100% of monthly budget. Resource Scheduling: Stop non-essential resources during off-hours (weeknights, weekends). Right-sizing: Start small (t3.micro), scale up only when metrics justify it. Free Tier Monitoring: Track usage daily via Cost Explorer to stay within 750-hour limits.\nSecurity:\nSecurity Groups: Follow least-privilege principle, review quarterly. CloudTrail: Enable logging for all API calls, retain for 90 days minimum. Regular Audits: Weekly log reviews, monthly security assessments. Secrets Management: Use environment variables, rotate credentials regularly.\nContingency Plans Scenario 1: Regional Failure (Singapore)\nRoute 53 automatically redirects traffic to Sydney (5-10 minutes). Manually promote Sydney RDS Read Replica to Writer (10-20 minutes). Update application configuration to use new database endpoint. Total RTO: ~30 minutes, RPO: \u003c1 minute.\nScenario 2: Budget Exceeded\nIdentify cost spike via AWS Cost Explorer. Stop non-essential resources (dev/test EC2, unused snapshots). Reduce Auto Scaling maximum capacity temporarily. Optimize database queries to reduce RDS load. Consider reverting to manual deployment if CI/CD costs spike.\nScenario 3: Replication Lag \u003e5 Minutes\nTemporarily direct critical reads to primary database. Investigate cause (high write volume, network issues, large transactions). Implement aggressive caching to reduce database load. Consider scaling up RDS instance class if CPU-bound.\n8. Expected Outcomes\r8.1. Technical Improvements\rPerformance Gains:\nLatency Reduction: 80% improvement for Sydney users (from 200ms to 20ms for reads). Availability: 99.5%+ uptime vs 95% with single-region architecture. Scalability: Support 1,000+ concurrent users with current infrastructure. Response Time: \u003c50ms for cached data, \u003c100ms for database queries. Operational Capabilities:\nReal-time monitoring and alerting via CloudWatch dashboards. Automated scaling based on traffic patterns (2-10 instances per region). Cross-region disaster recovery with \u003c30 minute RTO. Cost-optimized infrastructure using AWS Free Tier benefits.\nArchitecture Foundation:\nMulti-region pattern replicable to other geographic areas (US, Europe). Microservices architecture ready for containerization (ECS/EKS). Scalable from 100 to 100,000+ users by upgrading instance sizes. Production-ready security with VPC isolation, encryption, IAM roles.\n8.2. Long-term Value\rSkills Development:\nHands-on experience with AWS core services (EC2, RDS, VPC, Route 53, S3). Understanding of multi-region architecture patterns and trade-offs. DevOps practices: Infrastructure as Code, CI/CD, monitoring, incident response. Cost optimization and cloud financial management expertise. Portfolio Project:\nDemonstrates cloud architecture expertise to potential employers. Shows end-to-end project delivery: planning, implementation, testing, documentation. Proves ability to work within constraints (budget, time, technology). Real-world production-ready system (not just tutorial follow-along). Business Foundation:\nReusable architecture for future SaaS applications. 1-year operational data for analytics and AI/ML projects. Foundation for enterprise features (SSO, audit logging, multi-tenancy). Potential monetization path (charge per user/tenant). Career Impact:\nAWS certification preparation (Cloud Practitioner, Solutions Architect, SysOps). Interview talking points for cloud/DevOps positions. Open-source contribution opportunity (template for multi-region apps). Foundation for technical blog posts and conference talks.",
    "description": "Multi-Region SaaS Task Management Platform\rA Global AWS Solution for Low-Latency, Resilient Collaboration\r1. Executive Summary\rThe Multi-Region SaaS Task Management Platform is designed to deliver a Trello/Asana-like experience with low latency, high availability, and regional scalability across Asia-Pacific.",
    "tags": [],
    "title": "Proposal",
    "uri": "/en/2-proposal/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 2 Objectives\rStudy Module 1 practicing VPC and EC2 Learn and practice configure VPC, EC2 and their related features Assign tasks for team project Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Learn about VPC and its feature 06/10/2025 06/10/2025 VPC, Youtube Lesson 2 - Practice creating VPC, Subnets, Internet Gateway 07/10/2025 07/10/2025 Create VPC, Create Subnets, Create Internet Gateway - Update worklog 3 - Practice creating Route table, Security groups 08/10/2025 08/10/2025 Create Route Table, Create Security Groups - Decide project scopes, assgign tasks 4 - Learn about Deploying Amazon EC2 Instances 09/10/2025 09/10/2025 Deploying Amazon EC2 Instances, Youtube Tutorial - Practice creating EC2 server, Checking connection, creating NAT Gateway Create EC2 instance, Check connection, Create NAT Gateway 5 - Practice using Reachability Analyzer 10/10/2025 10/10/2025 Create Reachability Analyzer - Team meeting to decide proposal project - Update worklog",
    "description": "Week 2 Objectives\rStudy Module 1 practicing VPC and EC2 Learn and practice configure VPC, EC2 and their related features Assign tasks for team project Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Learn about VPC and its feature 06/10/2025 06/10/2025 VPC, Youtube Lesson 2 - Practice creating VPC, Subnets, Internet Gateway 07/10/2025 07/10/2025 Create VPC, Create Subnets, Create Internet Gateway - Update worklog 3 - Practice creating Route table, Security groups 08/10/2025 08/10/2025 Create Route Table, Create Security Groups - Decide project scopes, assgign tasks 4 - Learn about Deploying Amazon EC2 Instances 09/10/2025 09/10/2025 Deploying Amazon EC2 Instances, Youtube Tutorial - Practice creating EC2 server, Checking connection, creating NAT Gateway Create EC2 instance, Check connection, Create NAT Gateway 5 - Practice using Reachability Analyzer 10/10/2025 10/10/2025 Create Reachability Analyzer - Team meeting to decide proposal project - Update worklog",
    "tags": [],
    "title": "Week 2 Worklog",
    "uri": "/en/1-worklog/1.2-week_2/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Blog 1: Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\nBlog 2: Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\nBlog 3: Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\nBlog 4: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên\nBlog 5: Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa\nBlog 6: Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\nWeek 7: Xây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng(30/09/2025 - W4)\nWeek 8: Doing task G…\nWeek 9: Doing task H…\nWeek 10: Doing task I…\nWeek 11: Doing task J…\nWeek 12: Doing task K…",
    "description": "Blog 1: Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\nBlog 2: Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\nBlog 3: Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\nBlog 4: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên",
    "tags": [],
    "title": "Translated Blogs",
    "uri": "/en/3-translated_blogs/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\rTác giả: Adarsh Suresh, Chandu Utlapalli – 29/7/2025\nChủ đề: Amazon Q Developer, AWS Elastic Beanstalk, Technical How-to\nGiới thiệu\rCác nhà phát triển làm việc với AWS nhận thấy AWS Elastic Beanstalk là một dịch vụ vô giá giúp việc triển khai và chạy các ứng dụng web trở nên đơn giản mà không cần phải lo lắng về cơ sở hạ tầng nền tảng (underlying infrastructure). Bạn chỉ cần tải mã ứng dụng của mình lên, và Elastic Beanstalk sẽ tự động xử lý các chi tiết về cấp phát dung lượng (capacity provisioning), cân bằng tải (load balancing), điều chỉnh quy mô (scaling), và giám sát (monitoring), cho phép bạn tập trung vào việc viết code.\nVới việc phát hành CLI agent mới được tăng cường của Amazon Q Developer, chúng ta đã thấy cách Q CLI có thể được sử dụng để chuyển đổi phương pháp tiếp cận quy trình phát triển phần mềm.\nNgoài phát triển phần mềm, các nhà phát triển và đội ngũ DevOps có thể dành phần lớn thời gian của họ cho các tác vụ vận hành (operational tasks) như triển khai và kiểm thử mã của họ trên nhiều môi trường, bao gồm cả việc khắc phục sự cố các lỗi liên quan đến triển khai (deployment related failures) hoặc các vấn đề về tình trạng ứng dụng (application health issues). Các tính năng dựa trên tác nhân (agentic features) mới của Q CLI có thể được sử dụng để đơn giản hóa đáng kể quy trình này bằng cách giúp bạn xác định và giải quyết các vấn đề vận hành theo cách hiệu quả hơn.\nKhi khắc phục sự cố môi trường Elastic Beanstalk, Q CLI trở thành người bạn đồng hành không thể thiếu. Khi các môi trường hiển thị tình trạng sức khỏe bị suy giảm (degraded health) hoặc lỗi triển khai (deployment failures), các nhà phát triển có thể sử dụng Q CLI để nhanh chóng điều tra mà không cần phải điều hướng qua nhiều trang AWS console hoặc phân tích nhiều logs thủ công.\nVí dụ, khi đối mặt với lỗi triển khai, bạn có thể chạy q chat để bắt đầu một cuộc trò chuyện mới và mô tả vấn đề. Q CLI có thể giúp phân tích instance logs, kiểm tra cấu hình môi trường (environment configurations), và xác định các cấu hình sai (misconfigurations) trong ứng dụng. Nó có thể lấy các thông báo lỗi liên quan từ Elastic Beanstalk logs và đề xuất các biện pháp khắc phục cụ thể dựa trên các mẫu lỗi mà nó nhận ra.\nKhi giải quyết các vấn đề về tình trạng sức khỏe (health issues), các nhà phát triển có thể yêu cầu Q CLI kiểm tra trạng thái môi trường, mức sử dụng tài nguyên (resource utilization) và các sự kiện gần đây. Nó có thể xác định xem một ứng dụng có đang gặp vấn đề thiếu bộ nhớ (out of memory problems), vấn đề kết nối (connectivity issues), hay lỗi liên quan đến dependency hay không. Q CLI cũng có thể kiểm tra application logs để tìm các lỗi lặp lại có thể gây ra suy giảm tình trạng sức khỏe (health degradation).\nĐiều mà các nhà phát triển đánh giá cao nhất là cách Q CLI kết nối các điểm giữa các dịch vụ AWS khác nhau. Nếu một môi trường Elastic Beanstalk gặp sự cố do vấn đề cấu hình Amazon VPC cơ bản hoặc vấn đề quyền Amazon S3, Q CLI có thể xác định các kết nối này và cung cấp các giải pháp toàn diện (holistic solutions).\nViệc tiết kiệm thời gian là rất đáng kể – những gì trước đây mất hàng giờ điều tra trên nhiều trang AWS console giờ đây chỉ mất vài phút với các truy vấn Q CLI có mục tiêu. Điều này đã cải thiện đáng kể khả năng của các nhà phát triển trong việc duy trì các môi trường khỏe mạnh và nhanh chóng giải quyết các vấn đề khi chúng phát sinh.\nDưới đây, chúng tôi sẽ hướng dẫn bạn một số ví dụ về cách bạn có thể sử dụng Q CLI để khắc phục một số sự cố mà bạn có thể gặp phải khi quản lý môi trường Elastic Beanstalk.\nHướng dẫn Giải pháp\rĐiều kiện Tiên quyết\nNếu bạn muốn làm theo trên máy tính của riêng mình, vui lòng đảm bảo bạn hoàn thành các điều kiện tiên quyết sau:\nMột tài khoản AWS có quyền truy cập Elastic Beanstalk Sự quen thuộc cơ bản với các khái niệm Elastic Beanstalk (environments, applications, deployments) AWS CLI được cài đặt và cấu hình với các quyền thích hợp để truy cập tài nguyên Elastic Beanstalk, và thu thập logs AWS Q Developer CLI được cài đặt và thiết lập EB CLI được cài đặt và thiết lập (tùy chọn) Các môi trường web server Elastic Beanstalk đã được tạo để khắc phục sự cố Bây giờ chúng ta hãy đi sâu vào việc khắc phục các sự cố Elastic Beanstalk cụ thể với Q CLI. Tất cả các kịch bản dưới đây đều được kiểm tra với Amazon Q Developer CLI bằng gói đăng ký Pro tier vì nó cung cấp giới hạn yêu cầu cao hơn (higher request limits), nhưng điều này không bắt buộc cho mục đích của bản demo này. Khắc phục sự cố tình trạng môi trường\nHãy xem xét một môi trường Elastic Beanstalk đang chạy Node.js 22 trên Amazon Linux 2023, nơi chúng ta sẽ triển khai một phiên bản ứng dụng mới. Sau khi triển khai một phiên bản ứng dụng mới vào môi trường Elastic Beanstalk dựa trên Node.js của chúng ta, chúng tôi nhận thấy rằng tình trạng sức khỏe (health status) của nó đã chuyển sang trạng thái “Warning” (Cảnh báo) với thông báo sau hiển thị trong các sự kiện môi trường (environment events):\n100% of requests failing with HTTP 5xx errors\rHình 1. Bảng điều khiển EB hiển thị trạng thái sức khỏe Cảnh báo, cùng với lý do cho trạng thái sức khỏe\rThông báo sự kiện này có thể là kết quả của một số vấn đề, bao gồm nhưng không giới hạn ở lỗi ứng dụng Node.js, sự cố cấu hình reverse proxy, vấn đề sử dụng tài nguyên (resource utilization issues) v.v..\nHãy sử dụng Q CLI để giúp chúng ta điều tra thêm. Chúng ta sẽ bắt đầu một cuộc trò chuyện mới với agent bằng cách chạy q chat, và hỏi câu hỏi sau:\nWhy is my beanstalk environment nodejs-app in us-east-1 unhealthy? Check the logs if required, and recommend steps to resolve the issue (Tại sao môi trường beanstalk nodejs-app của tôi ở us-east-1 không khỏe mạnh? Kiểm tra các logs nếu cần, và đề xuất các bước để giải quyết vấn đề)",
    "description": "Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\rTác giả: Adarsh Suresh, Chandu Utlapalli – 29/7/2025\nChủ đề: Amazon Q Developer, AWS Elastic Beanstalk, Technical How-to\nGiới thiệu\rCác nhà phát triển làm việc với AWS nhận thấy AWS Elastic Beanstalk là một dịch vụ vô giá giúp việc triển khai và chạy các ứng dụng web trở nên đơn giản mà không cần phải lo lắng về cơ sở hạ tầng nền tảng (underlying infrastructure). Bạn chỉ cần tải mã ứng dụng của mình lên, và Elastic Beanstalk sẽ tự động xử lý các chi tiết về cấp phát dung lượng (capacity provisioning), cân bằng tải (load balancing), điều chỉnh quy mô (scaling), và giám sát (monitoring), cho phép bạn tập trung vào việc viết code.",
    "tags": [],
    "title": "Blog 3",
    "uri": "/en/3-translated_blogs/blog_3/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 3 Objectives\rStudy Module 2 in the First Cloud Journey Bootcamp – 2025 playlist Learn and get familiar with Route 53, CloudFormation and their related features Design the database and set up Backend \u0026 Frontend Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Learn about Route 53 and its feature 13/10/2025 13/10/2025 Route 53 2 - Practice creating Key pair, CloudFormation Template, Configure Security Group 14/10/2025 14/10/2025 Create Key pair, Initialize CloudFormation Template 3 - Practice creating Key pair, CloudFormation Template, Configure Security Group 15/10/2025 15/10/2025 Create Key pair, Initialize CloudFormation Template, Configure Security Group - Team meeting and discuss about Database design, Backend, Frontend 4 - Practice connecting to Remote Desktop Gateway (RDGW) by Remote Desktop Protocol (RDP) 16/10/2025 16/10/2025 Connecting to RDGW, Youtube tutorial - Design solution architecture - Team meeting to discuss about workshop project 5 - Practice deploy Microsoft Active Directory 17/09/2025 17/10/2025 Deploy Microsoft Active Directory - Practice deploy Microsoft Active Directory Deploy Microsoft Active Directory - Pratice configure DNS Configure DNS - Update worklog",
    "description": "Week 3 Objectives\rStudy Module 2 in the First Cloud Journey Bootcamp – 2025 playlist Learn and get familiar with Route 53, CloudFormation and their related features Design the database and set up Backend \u0026 Frontend Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Learn about Route 53 and its feature 13/10/2025 13/10/2025 Route 53 2 - Practice creating Key pair, CloudFormation Template, Configure Security Group 14/10/2025 14/10/2025 Create Key pair, Initialize CloudFormation Template 3 - Practice creating Key pair, CloudFormation Template, Configure Security Group 15/10/2025 15/10/2025 Create Key pair, Initialize CloudFormation Template, Configure Security Group - Team meeting and discuss about Database design, Backend, Frontend 4 - Practice connecting to Remote Desktop Gateway (RDGW) by Remote Desktop Protocol (RDP) 16/10/2025 16/10/2025 Connecting to RDGW, Youtube tutorial - Design solution architecture - Team meeting to discuss about workshop project 5 - Practice deploy Microsoft Active Directory 17/09/2025 17/10/2025 Deploy Microsoft Active Directory - Practice deploy Microsoft Active Directory Deploy Microsoft Active Directory - Pratice configure DNS Configure DNS - Update worklog",
    "tags": [],
    "title": "Week 3 Worklog",
    "uri": "/en/1-worklog/1.3-week_3/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên\rJagdish Komakula, Aditya Ambati và Anand Krishna Varanasi | 17/07/2025 | Amazon Elastic Kubernetes Service, Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to | Permalink\nGiới thiệu\rArgoCD là một bộ công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernets một cách khai báo, sử dụng Git là nguồn thông tin đáng tin cậy duy nhất. Bộ tính năng mạnh mẽ của nó bao gồm hệ thống đồng bộ tự động, hỗ trợ khôi phục, phát hiện sai lệch, chiến lược triển khai nâng cao, Tích hợp RBAC, và hỗ trợ đa cụm (multi-cluster), khiến nó trở thành giải pháp được ưa chuộng cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi các tổ chức mở rộng quy mô, một vài điểm khó khăn và thử thách vận hành bắt đầu xuất hiện.\nĐiểm khó khăn khi sử dụng ArgoCD theo phương pháp truyền thống\rGiao diện của ArgoCD và CLI được thiết kế cho người dùng có nền tảng công nghệ kỹ thuật chuyên sâu. Việc tích hợp tương tác với manifests YAML, hiểu mối quan hệ giữa các tài nguyên Kubernets, và việc khắc phục lỗi đồng bộ đòi hỏi kiến thức chuyên môn cao. Điều này hạn chế khả năng tiếp cập vào quy trình GitOps đối với các bên liên quan ít am hiểu công nghệ và làm tăng sự phụ thuộc vào các kỹ sư DevOps.\nViệc quản lý ArgoCD trên nhiều cụm (clusters) hoặc nhiều môi trường (environments) (sử dụng mô hình hub-spoke, per-cluster, hoặc grouped) tạo ra sự phức tạp đáng kể trong việc vận hành. Các nhóm phải xử lý nhiều instance ArgoCD, duy trì cấu hình nhất quán, và điều phối các triển khai, điều này có thể trở thành một nút thắt khi các quy mô dịch vụ ngày càng mở rộng.\nArgoCD vượt trội trong việc đồng bộ và giám sát các tài nguyên Kubernetes nhưng thiếu cơ chế tích hợp sẵn cho các tác vụ tiền triển khai (ví dụ: quét hình ảnh) và hậu triển khai (ví dụ: việc kiểm tra tải). Điều này khiến các nhóm phải dựa vào các bộ công cụ bên ngoài hoặc các script tùy chỉnh, khiến quy trình triển khai bị phân mảnh và tăng thêm gánh nặng bảo trì.\nViệc chuyển ứng dụng giữa các môi trường (Dev -\u003e Test -\u003e Prod) không được tinh gọn một cách tự nhiên. Các nhóm phải tự mình điều phối thủ công hoặc viết script cho các quy trình chuyển đổi này, việc này làm chậm việc triển khai các bản vá lỗi khẩn cấp và làm phức tạp hóa quá trình phát hành.\nKhi các tổ chức áp dụng các chiến lược đa cụm (multi-cluster), việc quản lý quyền truy cập, RBAC và khả năng hiển thị tài nguyên của ArgoCD trên nhiều môi trường trở nên công kềnh, thường dẫn tới việc làm phân mảnh quy trình làm việc và tạo ra các lỗ hổng bảo mật tiềm ẩn.\nCách ArgoCD MCP Server cùng với Amazon Q CLI giải quyết các vấn đề trên:\rViệc tích hợp máy chủ ArgoCD MCP với Amazon Q CLI về cơ bản đã thay đổi trải nghiệm người dùng bằng cách giới thiệu tương tác bằng ngôn ngữ tự nhiên cho các thao tác GitOps.\nVới MCP, người dùng có thể quản lý việc triển khai, giám sát trạng thái ứng dụng, và thực hiện thao tác đồng bộ hóa và khôi phục việc vận hành bằng cách sử dụng sử dụng ngôn ngữ giao tiếp thông thường thay vì các câu lệnh kỹ thuật (commands) hoặc YAML. Ví dụ, một người dùng có thể hỏi đơn giản là: “Những ứng dụng nào đang không đồng bộ ở môi trường production?” hay “Đồng bộ ứng dụng api-service,” và hệ thống sẽ thực hiện ngầm các lệnh gọi API ArgoCD phù hợp.\nĐiều này giúp dân chủ hóa quyền truy cập vào GitOps, cho phép các thành viên trong nhóm ít chuyên kỹ thuật (như QA, các người quản lý sản phẩm hoặc kỹ sư hỗ trợ) có thể tương tác an toàn với các quy trình triển khai.\nGiao diện ngôn ngữ tự nhiên giúp loại bỏ độ phức tạp của việc quản lý đa cụm (multi-cluster) và đa môi trường (multi-environment). Người dùng có thể truy vấn hoặc thực hiện hành động trên các tài nguyên giữa các cụm mà không cần ghi nhớ tên tài nguyên, namespace hoặc endpoint API.\nMCP Server xử lý việc xác thực, quản lý session và xử lý lỗi mạnh mẽ, giảm nhu cầu khắc phục sự cố thủ công và viết script tùy chỉnh.\nViệc tích hợp cung cấp các phản hồi chi tiết, xử lý các endpoint thông minh, và các thông báo lỗi toàn diện, giúp cho việc chẩn đoán và giải quyết vấn đề trở nên dễ dàng hơn. Việc kiểm tra kiểu tĩnh hoàn toàn và cấu hình theo môi trường còn nâng cao thêm độ tin cậy và khả năng bảo trì.\nBằng cách tận dụng khả năng mở rộng của Amazon Q CLI, người dùng được tiếp cận với các tích hợp sẵn và gợi ý theo ngữ cảnh, từ đó đẩy nhanh quy trình phát triển và triển khai.\nMCP Server cho phép các trợ lý AI và mô hình ngôn ngữ tự động hóa các tác vụ định kỳ, đề xuất hành động và thậm chí gỡ lỗi (debug) các vấn đề, hoạt động như một kỹ sư DevOps ảo. Điều này có thể giảm đáng kể công sức thủ công và tăng tốc độ phản hồi sự cố.\nSo sánh ArgoCD truyền thống với ArgoCD MCP Server và Amazon Q CLI\rTính năng/Thách thức ArgoCD truyền thống MPC Server + Amazon Q CLI Giao diện người dùng Giao diện kỹ thuật (UI/CLI), yêu cầu thao tác với YAML Ngôn ngữ tự nhiên, tương tác hội thoại Khả năng truy cập cho người không phải kỹ sư Hạn chế Mở rộng, dân chủ hóa Quản lý đa cụm Phức tạp, thủ công Đơn giản hóa, được trừu tượng hóa Tác vụ Tiền/Hậu Triển khai Cần công cụ bên ngoài/script Vẫn dùng công cụ bên ngoài, nhưng dễ gọi hơn Chuyển đổi ứng dụng Thủ công hoặc dùng script Ngôn ngữ tự nhiên, điều phối dễ dàng hơn Khắc phục sự cố Mang tính kỹ thuật, dễ xảy ra lỗi Được hướng dẫn, có hỗ trợ AI, phản hồi chi tiết Tự động hóa Yêu cầu viết script Do AI/agent điều khiển, chủ động Bạn có thể thực hiện các thao tác sau bằng ngôn ngữ tự nhiên nhờ tích hợp Amazon Q CLI với ArgoCD MCP server:\nQuản lý ứng dụng: Liệt kê, khởi tạo, cập nhật và xóa các ứng dụng ArgoCD.\nThao tác đồng bộ: Kích hoạt đồng bộ và theo dõi trạng thái\nTrực quan hóa cây tài nguyên: Xem cấu trúc phân cấp của các tài nguyên do ứng dụng quản lý\nGiám sát trạng thái sức khỏe: Kiểm tra trạng thái sức khỏe của các ứng dụng và các tài nguyên của chúng.\nTheo dõi sự kiện: Xem các sự kiện liên quan đến ứng dụng và tài nguyên.\nTruy cập log: Truy xuất log từ các workload của ứng dụng.\nThực hiện hành động trên tài nguyên: Gọi các thao tác trên tài nguyên được quản lý bởi ứng dụng\nThiết lập môi trường của bạn\rCác điều kiện tiên quyết\rSau đây là các điều kiện tiên quyết cho việc thiết lập môi trường EKS của bạn, sau đó sẽ được quản lý bởi ArgoCD thông qua Amazon CLI.\nMột tài khoản AWS với quyền thích hợp\nAWS CLI phiên bản 2.13.0 hoặc mới hơn\nNode.js phiên bản 18.0.0 hoặc mới hơn\nnpm phiên bản 9.0.0 hoặc mới hơn\nAmazon Q CLI phiên bản 1.0.0 hoặc mới hơn (npm install -g @aws/amazon-q-cli)\nMột cụm EKS (phiên bản 1.27 hoặc mới hơn) đã được cài ArgoCD phiên bản 2.8 hoặc mới hơn\nKết nối với cụm EKS của bạn\rSử dụng AWS CLI để cập nhật kubeconfig của bạn aws eks update-kubeconfig --name \u003ccluster_name\u003e --region \u003cregion\u003e --role-arn \u003ciam_role_arn\u003e\nXác minh các pod ArgoCD đang chạy đúng cách trong namespace argocd kubectl get pods -n argocd\nTruy cập giao diện người dùng ArgoCD server trên máy cục bộ bằng lệnh chuyển tiếp port kubectl port-forward svc/blueprints-addon-argocd-server -n argocd 8080:443\nTạo ArgoCD API token\rTruy cập vào ArgoCD UI tại https://localhost:8080 Đăng nhập bằng thông tin đăng nhập của tài khoản admin Điều hướng đến User Settings \u003e API Tokens Nhấp vào “Generate New” để tạo một token mới Tạo một tệp cấu hình Amazon Q CLI MCP tại đường dẫn .amazonq/mcp.json và cập nhật các giá trị ARGOCD_BASE_URL và ARGOCD_API_TOKEN sao cho phù hợp với thiết lập môi trường của bạn. Tích hợp với Amazon Q CLI\r{ \"mcpServers\": { \"argocd-mcp-stdio\": { \"type\": \"stdio\", \"command\": \"npx\", \"args\": [ \"argocd-mcp@latest\", \"stdio\" ], \"env\": { \"ARGOCD_BASE_URL\": \"\u003cARGOCD_BASE_URL\u003e\", \"ARGOCD_API_TOKEN\": \"\u003cARGOCD_API_TOKEN\u003e\", \"NODE_TLS_REJECT_UNAUTHORIZED\": \"0\" } } } }\rKhi cấu hình xong, bạn có thể bắt đầu sử dụng câu lệnh bằng ngôn ngữ tự nhiên với Amazon Q CLI để tương tác với các ứng dụng ArgoCD của mình.\nQuản lý các ứng dụng bằng cách sử dụng ngôn ngữ tự nhiên\rDưới đây là một số câu lệnh (prompts) để tương tác với các ứng dụng ArgoCD trong cụm EKS của bạn\nLiệt kê ứng dụng Argo\nCâu lệnh: List all ArgoCD applications in my cluster\nTạo ứng dụng ArgoCD mới\nCâu lệnh: Create new argocd application using App name: game-2048 Repo: https://github.com/aws-ia/terraform-aws-eks-blueprints Path: patterns/gitops/getting-started-argocd/k8s. Branch: main Namespace: argocd\nXem trạng thái triển khai\nCâu lệnh: Show me the resource tree for team-carmen app\nĐồng bộ hóa ứng dụng\nCâu lệnh: Show me the applications that’s out of sync\nCâu lệnh: Sync the application\nAmazon Q sẽ:\nKhởi tạo hoạt động đồng bộ cho ứng dụng đã chỉ định Giám sát quá trình động bộ hóa Báo trạng thái cuối cùng của hoạt động đồng bộ hóa Kiểm tra sức khỏe và giám sát\nCâu lệnh: Check the health of all resources in the team-geordie application\nAmazon Q sẽ:\nTruy vấn trạng thái sức khỏe của tất cả tài nguyên Xác định bất cứ thành phần nào không lành mạnh Cung cấp các khuyến nghị để giải quyết các vấn đề Câu lệnh: Show me the logs for the failing pod in the team-platform application\nAmazon Q sẽ:\nXác định các pod gặp sự cố Truy vấn và hiển thị các log có liên quan Làm nổi bật các thông báo lỗi tiềm ẩn Tổng kết\rViệc tích hợp Amazon Q CLI với ArgoCD thông qua MCP server đánh dấu một bước tiến mang tính chuyển đổi trong việc quản lý Kubernets, kết hợp khả năng GitOps của ArgoCD với công nghệ xử lý ngôn ngữ tự nhiên của Amazon Q. Bằng cách chuyển đổi các thao tác phức tạp trên Kubernets thành các tương tác hội thoại đơn giản, giải pháp này cho phép các nhóm có thể tập trung vào điều thực sự quan trọng - tạo ra giá trị cho doanh nghiệp. Hơn là dành thời gian ghi nhớ các lệnh hoặc vật lộn với những kỹ thuật phức tạp, giờ đây các nhóm có thể quản lý hạ tầng cloud của họ thông qua đối thoại tự nhiên, giúp hành trình cloud-native trở nên dễ tiếp cận và hiệu quả hơn cho mọi người. Sẵn sàng cho việc chuyển đổi trải nghiệm EKS và ArgoCD của bạn chưa? Hãy thử tích hợp Amazon Q CLI với ArgoCD MCP ngay và khám phá lý do vì sao các đội DevOps đang đưa nó vào bộ công cụ thiết yếu của họ.",
    "description": "Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên\rJagdish Komakula, Aditya Ambati và Anand Krishna Varanasi | 17/07/2025 | Amazon Elastic Kubernetes Service, Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to | Permalink\nGiới thiệu\rArgoCD là một bộ công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernets một cách khai báo, sử dụng Git là nguồn thông tin đáng tin cậy duy nhất. Bộ tính năng mạnh mẽ của nó bao gồm hệ thống đồng bộ tự động, hỗ trợ khôi phục, phát hiện sai lệch, chiến lược triển khai nâng cao, Tích hợp RBAC, và hỗ trợ đa cụm (multi-cluster), khiến nó trở thành giải pháp được ưa chuộng cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi các tổ chức mở rộng quy mô, một vài điểm khó khăn và thử thách vận hành bắt đầu xuất hiện.",
    "tags": [],
    "title": "Blog 4",
    "uri": "/en/3-translated_blogs/blog_4/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Events Participated",
    "uri": "/en/4-events_participated/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 4 Objectives\rBegin coding the backend authentication service and frontend Discuss and list the APIs required for the taskflow service. Learn and practice S3 Explore API Gateway Translate technical blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the architecture, backend and front end configuration 20/10/2025 20/10/2025 - Translate blog Translated Blog 1 2 - Learn and practice S3 service 21/10/2025 21/10/2025 S3 lesson - Code backend Authentication Service 3 - Code backend Authentication Service 22/10/2025 22/10/2025 - Code frontend 4 - Learn and practice API Gateway service 23/10/2025 23/10/2025 AWS API Gateway Introduction, Tạo API sử dụng Amazon API Gateway AWS Serverless Development Journey - Code backend Authentication Service - Code frontend - Translate blog Translated Blog 2, Translated Blog 3 5 - Code backend Authentication Service 24/10/2025 24/10/2025 - Code frontend - Translate blog Translated Blog 4, Translated Blog 5",
    "description": "Week 4 Objectives\rBegin coding the backend authentication service and frontend Discuss and list the APIs required for the taskflow service. Learn and practice S3 Explore API Gateway Translate technical blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the architecture, backend and front end configuration 20/10/2025 20/10/2025 - Translate blog Translated Blog 1 2 - Learn and practice S3 service 21/10/2025 21/10/2025 S3 lesson - Code backend Authentication Service 3 - Code backend Authentication Service 22/10/2025 22/10/2025 - Code frontend 4 - Learn and practice API Gateway service 23/10/2025 23/10/2025 AWS API Gateway Introduction, Tạo API sử dụng Amazon API Gateway AWS Serverless Development Journey - Code backend Authentication Service - Code frontend - Translate blog Translated Blog 2, Translated Blog 3 5 - Code backend Authentication Service 24/10/2025 24/10/2025 - Code frontend - Translate blog Translated Blog 4, Translated Blog 5",
    "tags": [],
    "title": "Week 4 Worklog",
    "uri": "/en/1-worklog/1.4-week_4/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Workshop",
    "uri": "/en/5-workshop/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa\rRyan Coleman và Belle Guttman | 15/07/2025 | Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source| Permalink | Comments\nHôm nay, chúng tôi vui mừng thông báo về phiên bản 1.0 của Strands Agents SDK, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production. Strands Agents là một SDK mã nguồn mở, áp dụng phương pháp model-driven, giúp bạn xây dựng và vận hành các agent AI chỉ trong vài dòng code. Strands có khả năng mở rộng từ các trường hợp sử dụng agent đơn giản đến phức tạp, cũng như từ phát triển cục bộ đến triển khai trong môi trường production.\nKể từ khi ra mắt bản xem trước vào tháng 5 năm 2025, chúng tôi đã nhận được hơn 2.000 lượt sao trên GitHub và hơn 150 ngàn lượt tải xuống trên PyPI. Strands 1.0 mang đến mức độ đơn giản tương tự cho các ứng dụng multi-agent như những gì Strands đã làm được với các agent đơn lẻ, với việc bổ sung bốn primitive mới và hỗ trợ cho giao thức Agent to Agent (A2A). Để đưa kiến trúc multi-agent vào môi trường production, phiên bản 1.0 cũng bao gồm một trình quản lý session mới để truy xuất trạng thái agent từ một kho dữ liệu từ xa, cùng với việc cải thiện hỗ trợ bất đồng bộ xuyên suốt toàn bộ SDK. Nhằm tăng tính linh hoạt để xây dựng agent của bạn với bất kỳ mô hình nào, cStrands 1.0 đã mở rộng hỗ trợ thêm API của năm nhà cung cấp mô hình mới, được đóng góp bởi các đối tác như Anthropic, Meta, OpenAI, Cohere, Mistral, Stability, Writer và Baseten (xem pull request). Bây giờ, hãy cùng đi sâu vào chi tiết các cập nhật này. Các mẫu code đầy đủ có sẵn tại trang strandsagents.com.\nĐơn giản hóa các mô hình multi-agent\rCác mô hình multi-agent cho phép các agent AI chuyên biệt cùng nhau làm việc—phân công nhiệm vụ, chia sẻ kiến thức và phối hợp hành động—nhằm giải quyết những vấn đề phức tạp mà một agent đơn lẻ không thể xử lý được. Strands 1.0 giới thiệu bốn primitive trực quan, giúp việc điều phối nhiều agent trở thành một phần mở rộng đơn giản của tổ hợp mô hình/công cụ/prompt mà bạn vốn đã sử dụng để tạo ra các agent đơn lẻ.\n1. Agents-as-Tools: Đơn giản hóa việc ủy quyền theo cấp bậc\nMô hình agents-as-tools biến các agent chuyên biệt thành những công cụ thông minh mà các agent khác có thể gọi đến. Điều này tạo điều kiện cho việc ủy quyền theo cấp bậc, nơi các agent hoạt động như người điều phối có thể chủ động tham vấn các chuyên gia theo từng lĩnh vực cụ thể mà không từ bỏ quyền kiểm soát yêu cầu. Điều này phản ánh cách thức làm việc của các đội nhóm con người — một quản lý dự án không cần phải biết mọi thứ, họ chỉ cần biết nên tham khảo ý kiến của chuyên gia nào cho từng nhiệm vụ cụ thể.\nfrom strands import Agent, tool from strands_tools import calculator, file_write, python_repl, journal @tool def web_search(query: str) -\u003e str: return \"Dummy web search results here!\" # Create specialized agents research_analyst_agent = Agent( system_prompt=\"You are a research specialist who gathers and analyzes information about local startup markets\", tools=[web_search, calculator, file_write, python_repl] ) travel_advisor_agent = Agent( system_prompt=\"You are a travel expert who helps with trip planning and destination advice\", tools=[web_search, journal] ) # Convert the agents into tools @tool def research_analyst(query: str) -\u003e str: response = research_analyst_agent(query) return str(response) @tool def travel_advisor(query: str) -\u003e str: response = travel_advisor_agent(query) return str(response) # Orchestrator naturally delegates to specialists executive_assistant = Agent( tools=[research_analyst, travel_advisor] ) result = executive_assistant(\"I have a business meeting in Portland next week. Suggest a nice place to stay near the local startup scene, and suggest a few startups to visit\") Trong ví dụ rút gọn này, chúng ta định nghĩa hai agent du lịch và nghiên cứu, mỗi agent có prompt và công cụ chuyên biệt cho lĩnh vực của mình, mà agent trợ lý điều hành có thể gọi đến để lấy thông tin phục vụ yêu cầu của người dùng. agent trợ lý điều hành chịu trách nhiệm tổng hợp đầu vào từ các agent khác và tạo ra phản hồi gửi lại cho người dùng. Tìm hiểu thêm về mô hình Agents-as-Tools trong tài liệu chính thức của Strands.\n2. Handoffs: chuyển giao quyền kiểm soát rõ ràng\nTính năng Handoffs cho phép các agent chủ động chuyển trách nhiệm sang con người khi gặp phải nhiệm vụ vượt quá phạm vi chuyên môn của mình, đồng thời giữ nguyên toàn bộ ngữ cảnh cuộc trò chuyện trong quá trình chuyển giao. Strands cung cấp sẵn công cụ được tích hợp sẵn handoff_to_user giúp cho các agent có thể dùng để chuyển giao quyền kiểm soát một cách liền mạch trong khi vẫn duy trì lịch sử và ngữ cảnh cuộc trò chuyện - giống như một nhân viên dịch vụ khách hàng cung cấp chủ động yêu cầu khách cung cấp thêm thông tin về trường hợp của họ.\nfrom strands import Agent from strands_tools import handoff_to_user SYSTEM_PROMPT=\"\"\" Answer the user's support query. Ask them questions with the handoff_to_user tool when you need more information \"\"\" # Include the handoff_to_user tool in our agent's tool list agent = Agent( system_prompt=SYSTEM_PROMPT, tools=[handoff_to_user] ) # The agent calls the handoff_to_user tool which includes the question for the customer agent(\"I have a question about my order.\")\rCác agent cũng có thể đặt câu hỏi cho con người khi được yêu cầu làm như vậy\nfrom strands import Agent SYSTEM_PROMPT=\"\"\" Answer the user's support query. Ask them questions when you need more information \"\"\" agent = Agent( system_prompt=SYSTEM_PROMPT, ) # The agent asks questions by streaming them back as text agent(\"I have a question about my order.\")\r3. Swarms: Các nhóm cộng tác tự tổ chức\nMột Swarm tạo ra các agent tự chủ phối hợp động thông qua việc chia sẻ bộ nhớ,cho phép nhiều chuyên gia có thể cộng tác cho các tác vụ phức tạp. Hãy hình dung nó giống như một buổi thảo luận nhóm, nơi các chuyên gia xây dựng ý tưởng dựa trên ý tưởng của nhau, với đội ngũ tự tổ chức để mang lại kết quả tập thể tốt nhất.\nimport logging from strands import Agent from strands.multiagent import Swarm from strands_tools import memory, calculator, file_write # Enables Strands debug logs level, and prints to stderr logging.getLogger(\"strands.multiagent\").setLevel(logging.DEBUG) logging.basicConfig( format=\"%(levelname)s | %(name)s | %(message)s\", handlers=[logging.StreamHandler()] ) researcher = Agent( name=\"researcher\", system_prompt=\"You research topics thoroughly using your memory and built-in knowledge\", tools=[memory] ) analyst = Agent( name=\"analyst\", system_prompt=\"You analyze data and create insights\", tools=[calculator, memory] ) writer = Agent( name=\"writer\", system_prompt=\"You write comprehensive reports based on research and analysis\", tools=[file_write, memory] ) # Swarm automatically coordinates agents market_research_team = Swarm([researcher, analyst, writer]) result = market_research_team( \"What is the history of AI since 1950? Create a comprehensive report\" ) Nghiên cứu thêm về Swarms trong tài liệu về Strands\n4. Graphs: Kiểm soát quy trình làm việc mang tính xác định\nGraphs cho phép bạn xác định quy trình làm việc của các agent một cách rõ ràng với những định tuyến có điều kiện và những điểm ra quyết định, rất hữu ích cho những quy trình yêu cầu các bước cụ thể, cơ chế phê duyệt hoặc các ngưỡng kiểm soát chất lượng. Giống như một dây chuyền lắp ráp hoặc chuỗi phê duyệt được thiết kế tốt, graphs đảm bảo các agent luôn tuân thủ các quy tắc nghiệp vụ đã định sẵn theo đúng trình tự mỗi lần thực thi.\nfrom strands import Agent from strands.multiagent import GraphBuilder analyzer_agent = Agent( name=\"analyzer\", system_prompt=\"Analyze customer requests and categorize them\", tools=[text_classifier, sentiment_analyzer] ) normal_processor = Agent( name=\"normal_processor\", system_prompt=\"Handle routine requests automatically\", tools=[knowledge_base, auto_responder] ) critical_processor = Agent( name=\"critical_processor\", system_prompt=\"Handle critical requests quickly\", tools=[knowledge_base, escalate_to_support_agent] ) # Build deterministic workflow builder = GraphBuilder() builder.add_node(analyzer_agent, \"analyze\") builder.add_node(normal_processor, \"normal_processor\") builder.add_node(critical_processor, \"critical_processor\") # Define conditional routing def is_approved(state): return True def is_critical(state): return False builder.add_edge(\"analyze\", \"normal_processor\", condition=is_approved) builder.add_edge(\"analyze\", \"critical_processor\", condition=is_critical) builder.set_entry_point(\"analyze\") customer_support_graph = builder.build() # Execute the graph with user input results = customer_support_graph(\"I need help with my order!\") Nghiên cứu thêm về Graphs trong tài liệu về Strands\nCác mô hình multi-agent (multi-agent patterns) này được thiết kế để được áp dụng dần dần và kết hợp một cách tự do — hãy bắt đầu với các agent đơn lẻ, thêm các chuyên gia như là công cụ, phát triển thành các Swarms, và điều phối bằng các Graphs khi nhu cầu của bạn tăng lên. Hãy kết hợp và tùy chỉnh các mô hình để tạo ra các hệ thống tinh vi: swarms có thể chứa các graphs, graphs có thể điều phối các swarms, và bất kỳ mô hình nào cũng có thể sử dụng các agent được trang bị thêm các agent khác làm công cụ.\nfrom strands import Agent, tool from strands.multiagent import GraphBuilder, Swarm from strands_tools import memory, calculator, python_repl, file_write # Start simple with a single agent agent = Agent(tools=[memory]) # Create specialist agents that a lead orchestrator agent can consult data_analyst = Agent(name=\"analyst\", tools=[calculator, python_repl]) @tool def data_analyst_tool(query: str) -\u003e str: return str(data_analyst(query)) analyst_orchestrator = Agent(tools=[memory, data_analyst_tool]) # Agents-as-tools # Compose patterns together - a graph that uses a swarm researcher = Agent(name=\"researcher\", tools=[memory]) writer = Agent(name=\"writer\", tools=[file_write]) research_swarm = Swarm([researcher, analyst_orchestrator, writer]) review_agent = Agent(system_prompt=\"Review the research quality and suggest improvements\") builder = GraphBuilder() builder.add_node(research_swarm, \"research\") # Swarm as graph node builder.add_node(review_agent, \"review\") builder.add_edge(\"research\", \"review\") graph = builder.build() # The patterns nest naturally - swarms in graphs, agents as tools everywhere result = graph(\"How has green energy evolved over the last few years?\") Hệ thống Multi-Agent với A2A\rStrand 1.0 đã bao gồm việc hỗ trợ cho giao thức Agent-to-Agent (A2A), một tiêu chuẩn mở cho phép các agent từ các nền tảng khác nhau có thể giao tiếp một cách liền mạch. Bất kỳ agent Strands cũng có thể được tích hợp các khả năng A2A để trở nên có thể truy cập qua mạng và tuân thủ giao thức A2A. Các agent A2A từ các tổ chức bên ngoài cũng có thể được sử dụng trực tiếp trong tất cả các mô hình multi-agent của Strands.\nfrom strands import Agent from strands.multiagent.a2a import A2AServer from strands_tools.a2a_client import A2AClientToolProvider # Serve your agent via A2A protocol local_agent = Agent(name=\"analyzer\", tools=[web_search, data_analysis]) a2a_agent = A2AServer(agent=local_agent, port=9000) a2a_agent.serve() # AgentCard available at http://localhost:9000/.well-known/agent.json # Use remote A2A agents partner_agent_url = \"https://partner.com\" cloud_agent_url = \"https://cloud.ai\" # Connect to remote A2A enabled agents a2a_tool_provider = A2AClientToolProvider(known_agent_urls=[partner_agent_url, cloud_agent_url]) # Orchestrate remote agents orchestrator = Agent(tools=[a2a_tool_provider.tools]) Bởi vì A2A cung cấp các tính năng như agent card, một mô tả được chuẩn hóa về khả năng của agent, các hệ thống multi-agent được bật A2A có thể dễ dàng khám phá và kết nối với các agent được tạo ra bởi các nhóm hoặc các tổ chức khác. Strands tự động tạo ra thẻ agent dựa trên các công cụ bạn đã cung cấp cho agent. Để xem các ví dụ hoạt động hoàn chỉnh và bắt đầu với tính năng tích hợp A2A, hãy tham khảo repository mẫu của chúng tôi và tài liệu A2A của Strands.\nSẵn sàng cho môi trường production\rMặc dù Strands đã được các đội nội bộ của Amazon như Amazon Q Developer và AWS Glue sử dụng trong môi trường production từ lâu trước khi ra mắt công chúng, chúng tôi đã và đang làm việc ngược lại với hàng trăm khách hàng trên toàn thế giới để mở rộng Strands nhằm đáp ứng các nhu cầu production của bạn. Các cập nhật này bao gồm một tầng trừu tượng quản lý session để hỗ trợ việc lưu trữ liên tục dữ liệu vào và phục hồi từ các kho dữ liệu bên ngoài, đầu ra có cấu trúc, cải thiện hỗ trợ bất đồng bộ, và nhiều thứ khác nữa (xem chi tiết trong changelog các phiên bản phát hành)\nQuản lý session bền vững: Chúng tôi đã thêm vào SessionManager, một công cụ trừu tượng hóa quản lý session cho phép tự động lưu trữ liên tục và khôi phục lịch sử hội thoại cũng như trạng thái của agent. Nhờ đó, các agent có thể lưu toàn bộ lịch sử cuộc trò chuyện vào một hệ thống lưu trữ như Amazon Simple Storage Service (Amazon S3) và tiếp tục cuộc hội thoại một cách liền mạch ngay cả sau khi hệ thống khởi động lại. Dưới đây là một ví dụ sử dụng cơ chế lưu trữ liên tục dựa trên file cơ bản.\nfrom strands import Agent from strands.session.file_session_manager import FileSessionManager # Create a session manager with file-based storage Session_manager = FileSessionManager(session_id=”customer_support”, base_dir=\"./agent_sessions\") # Agent automatically persists all conversations agent = Agent( id=\"support_bot_1\", session_manager=session_manager, tools=[knowledge_base, ticket_system] ) # Messages are automatically saved as the conversation progresses agent(\"Help me reset my password\") agent(\"I can't access my email\") # Later, even after a restart, restore the full conversation Bạn có thể mở rộng lớp trừu tượng này bằng cách tự triển khai backend lưu trữ của riêng mình thông qua mẫu thiết kế Data Access Object (DAO), và Strands đã tích hợp sẵn hai backend mặc định: hệ thống file cục bộ và Amazon S3. Mỗi agent nhận một ID duy nhất để theo dõi, và hệ thống xử lý các agent đồng thời trong cùng một session cho các kịch bản multi-agent, đảm bảo rằng các agent luôn duy trì ngữ cảnh qua các lần triển khai, mở rộng quy mô hệ thống hoặc khởi động lại. Tìm hiểu thêm về Session Management trong tài liệu của Strands.\nHỗ trợ bất đồng bộ nguyên bản và cải thiện hiệu năng: Các workload trong môi trường production đòi hỏi độ tin cậy cao và hiệu năng phản hồi nhanh. Trong phiên bản 1.0, chúng tôi đã cải tiến kiến trúc vòng lặp sự kiện của Strands để hỗ trợ thao tác bất đồng bộ trên toàn bộ stack. Các công cụ và nhà cung cấp mô hình giờ đây có thể chạy bất đồng bộ mà không bị chặn, cho phép thực thi đồng thời thực sự. Phương thức stream_async mới truyền phát tất cả các sự kiện của agent — văn bản, việc sử dụng công cụ, các bước suy luận — theo thời gian thực, vđồng thời tích hợp cơ chế hủy khi người dùng rời khỏi trang.\nimport asyncio from fastapi import FastAPI from fastapi.responses import StreamingResponse from strands import Agent from strands_tools import calculator app = FastAPI() @app.post(\"/chat\") async def chat_endpoint(message: str): async def stream_response(): agent = Agent(tools=[web_search, calculator]) # Stream agent responses in real-time async for event in agent.stream_async(message): if \"data\" in event: yield f\"data: {event['data']}\\n\\n\" elif \"current_tool_use\" in event: yield f\"event: tool\\ndata: Using {event['current_tool_use']['name']}\\n\\n\" return StreamingResponse(stream_response(), media_type=\"text/event-stream\") # Concurrent agent evaluation async def evaluate_models_concurrently(prompt: str): async def stream(agent: Agent): print(f\"STARTING: {agent.name}\") async for event in agent.stream_async(prompt): # handle events print(f\"ENDING: {agent.name}\") return event[“result”] # last event is the agent result agents = [ Agent(name=\"claude\", model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0”), Agent(name=\"deepseek”, model=\"us.deepseek.r1-v1:0”), Agent(name=\"nova\", model=\"us.amazon.nova-pro-v1:0\") ] # Execute all agents concurrently responses = await asyncio.gather(*[stream(agent) for agent in agents]) return responses Tìm hiểu thêm về Hỗ trợ bất động bộ nguyên bản trong tài liệu chính thức của Strands.\nMở rộng hỗ trợ đa dạng nhà cung cấp mô hình: Khách hàng đã chia sẻ rằng họ cần linh hoạt trong việc sử dụng các mô hình khác nhau cho các tác vụ khác nhau. Để đáp ứng nhu cầu này, Strands Agents đã nhận được sự hỗ trợ mạnh mẽ từ cộng đồng các nhà cung cấp mô hình. Các nhà cung cấp như Anthropic, Meta, OpenAI, Cohere, Mistral, Stability và Writer đã đóng góp cho phép API mô hình của họ được sử dụng bởi một Strands Agent thông qua code. Việc truy cập Strands Agents thông qua hạ tầng API do chính các nhà cung cấp này cung cấp giúp các nhà phát triển tập trung vào việc xây dựng các giải pháp AI-powered, mà không cần lo lắng về quản lý cơ sở hạ tầng. Những bổ sung này bổ trợ hoàn hảo cho khả năng hỗ trợ từ giai đoạn xem trước đối với mọi mô hình trên Amazon Bedrock, OpenAI, và bất kỳ endpoint tương thích OpenAI nào thông qua LiteLLM. Strands cho phép bạn sử dụng các mô hình khác nhau cho mỗi agent, hoặc chuyển đổi mô hình và nhà cung cấp mô hình mà không cần sửa đổi công cụ hoặc logic của bạn.\nfrom strands import Agent from strands.models import BedrockModel from strands.models.openai import OpenAIModel from strands.models.anthropic import AnthropicModel # Configure different model providers bedrock_model = BedrockModel( model_id=\"us.amazon.nova-pro-v1:0\", temperature=0.3, top_p=0.8, region_name=\"us-west-2\" ) openai_model = OpenAIModel( client_args={ \"api_key\": \"your-api-key\", }, model_id=\"gpt-4o\", params={ \"max_tokens\": 1000, \"temperature\": 0.7, } ) anthropic_model = AnthropicModel( client_args={ \"api_key\": \"your-api-key\", }, max_tokens=1028, model_id=\"claude-3-7-sonnet-20250219\", params={ \"temperature\": 0.5, } ) # Swap models or use different models for different agents in the same system researcher = Agent( name=\"researcher\", model=anthropic_model, tools=[web_search] ) writer = Agent( name=\"writer\", model=openai_model, tools=[document_formatter] ) analyzer = Agent( name=\"analyzer\", model=bedrock_model, tools=[data_processor] )\rCộng đồng Strands đã đóng vai trò then chốt trong việc định hình tất cả những cải tiến này thông qua việc sử dụng thực tế, phản hồi và những đóng góp mã nguồn trực tiếp. Trong số hơn 150 pull request (PR) đã được merge vào Strands từ phiên bản 0.1.0 đến 1.0, 22% được đóng góp bởi các thành viên cộng đồng, những người đã sửa lỗi, thêm nhà cung cấp mô hình, viết tài liệu, thêm tính năng và tái cấu trúc các lớp để cải thiện hiệu suất. Chúng tôi vô cùng biết ơn mỗi người trong số các bạn vì đã giúp Strands trở thành cách đơn giản nhất để đưa một agent từ nguyên mẫu đến triển khai thực tế.\nTương lai của AI là multi-agent (multi-agent), và với Strands 1.0, tương lai đó đã sẵn sàng để triển khai trong môi trường production. Hãy bắt đầu xây dựng ngay hôm nay tại strandsagents.com.",
    "description": "Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa\rRyan Coleman và Belle Guttman | 15/07/2025 | Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source| Permalink | Comments\nHôm nay, chúng tôi vui mừng thông báo về phiên bản 1.0 của Strands Agents SDK, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production. Strands Agents là một SDK mã nguồn mở, áp dụng phương pháp model-driven, giúp bạn xây dựng và vận hành các agent AI chỉ trong vài dòng code. Strands có khả năng mở rộng từ các trường hợp sử dụng agent đơn giản đến phức tạp, cũng như từ phát triển cục bộ đến triển khai trong môi trường production.",
    "tags": [],
    "title": "Blog 5",
    "uri": "/en/3-translated_blogs/blog_5/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 5 Objectives\rContinue frontend and backend development Learn EC2 Auto Scaling Group Practice AWS CloudShell setups Translate blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 27/10/2025 27/10/2025 - Translate blogs Translated Blog 6, Translated Blog 7 - Code backend Authentication Service, User Service - Code frontend 2 - Learn and practice EC2 Auto Scaling Group 28/10/2025 28/10/2025 Module-03-02 - EC2 Autoscaling - EFS/FSx - Lightsail - MGN, AWS EC2 Auto Scaling : Step By Step Tutorial - Code backend Authentication Service, User Service, Taskflow Service - Code frontend - Translate blog Translated Blog 8, Translated Blog 9 3 - Code backend Authentication Service, User Service 29/10/2025 29/10/2025 - Learn and pratice Kafka for messaging - Code frontend - Update worklog 4 - Code backend Authentication Service, User Service 30/10/2025 30/10/2025 - Code frontend - Learn about Caching to apply cache for database - Translate blog Translated Blog 10, Translated Blog 11 5 - Learn and practice using CloudShell 31/10/2025 31/10/2025 AWS Certified Cloud Practitioner Certification Course (CLF-C02) - Translate blog Translated Blog 12",
    "description": "Week 5 Objectives\rContinue frontend and backend development Learn EC2 Auto Scaling Group Practice AWS CloudShell setups Translate blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 27/10/2025 27/10/2025 - Translate blogs Translated Blog 6, Translated Blog 7 - Code backend Authentication Service, User Service - Code frontend 2 - Learn and practice EC2 Auto Scaling Group 28/10/2025 28/10/2025 Module-03-02 - EC2 Autoscaling - EFS/FSx - Lightsail - MGN, AWS EC2 Auto Scaling : Step By Step Tutorial - Code backend Authentication Service, User Service, Taskflow Service - Code frontend - Translate blog Translated Blog 8, Translated Blog 9 3 - Code backend Authentication Service, User Service 29/10/2025 29/10/2025 - Learn and pratice Kafka for messaging - Code frontend - Update worklog 4 - Code backend Authentication Service, User Service 30/10/2025 30/10/2025 - Code frontend - Learn about Caching to apply cache for database - Translate blog Translated Blog 10, Translated Blog 11 5 - Learn and practice using CloudShell 31/10/2025 31/10/2025 AWS Certified Cloud Practitioner Certification Course (CLF-C02) - Translate blog Translated Blog 12",
    "tags": [],
    "title": "Week 5 Worklog",
    "uri": "/en/1-worklog/1.5-week_5/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\rEric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)\nViệc phân tích lượng dữ liệu genomic và multiomic ngày càng gia tăng đòi hỏi các giải pháp tính toán hiệu quả, có khả năng mở rộng và tiết kiệm chi phí. Amazon Web Services (AWS) tiếp tục hỗ trợ các workload này thông qua các dịch vụ tính toán tăng tốc FPGA như các instance Amazon EC2 F2.\nGiải pháp phân tích thứ cấp DRAGEN (Dynamic Read Analysis for GENomics) của Illumina đã khẳng định vị thế là một trong những giải pháp phân tích thứ cấp hàng đầu cho dữ liệu sequencing thế hệ mới, cung cấp các thuật toán được tối ưu hóa cao cho phân tích genomic và triển khai tăng tốc phần cứng cho các pipeline phân tích toàn diện về genomics và multiomics, bao gồm DNA germline, DNA somatic, cũng như phân tích RNA ở mức bulk và single-cell, proteomics, spatial, và nhiều hơn nữa.\nDRAGEN chạy nguyên bản trên các instance EC2 F2 và cung cấp cho khách hàng một phương pháp nhanh chóng để phân tích tập dữ liệu sinh học của họ. Việc di chuyển sang F2 được đơn giản hóa vì cùng một DRAGEN AMI được sử dụng cho cả F1 và F2, và kết quả phân tích sẽ tương đương nhau. Trong bài viết này, chúng tôi sẽ thảo luận về các đặc tính hiệu năng của DRAGEN trên các môi trường tính toán AWS khác nhau, cũng như cách triển khai phiên bản DRAGEN v4.4 mới ra mắt gần đây trên các instance Amazon EC2 F2.\nTổng quan về các instance Amazon EC2 F2\rCác instance F2 là thế hệ thứ 2 của các instance EC2 được trang bị FPGA để tăng tốc phân tích dữ liệu genomic và multimedia trong môi trường cloud. Những instance này mang lại cải tiến đáng kể so với thế hệ trước — các instance F1 — với hiệu suất giá thành được cải thiện tốt hơn tới 60%. Dưới đây là các tính năng và thông số kỹ thuật chính của instance F2:\nCấu hình FPGA: Instance F2 được trang bị tối đa tám AMD Virtex UltraScale+ HBM VU47P FPGAs, mỗi FPGA tích hợp 16GB bộ nhớ băng thông cao (HBM – High-Bandwidth Memory).\nBộ xử lý: Được vận hành bởi bộ vi xử lý AMD EPYC thế hệ thứ 3 (Milan), instance F2 cung cấp tới 192 vCPU — gấp ba lần số lõi xử lý so với instance F1.\nBộ nhớ: Instance này hỗ trợ tới 2 TiB bộ nhớ hệ thống, gấp đôi dung lượng bộ nhớ của instance F1.\nLưu trữ: F2 đi kèm với tối đa 7.6 TiB bộ nhớ SSD NVMe, gấp đôi dung lượng lưu trữ của F1.\nNetworking: Tốc độ băng thông mạng lên tới 100 Gbps, cao gấp bốn lần so với băng thông mạng có sẵn trên instance F1.\nBảng 1: Bảng so sánh thông số kỹ thuật về compute, memory, storage, và networking giữa các instance F1 và F2.\nPhương pháp đánh giá hiệu năng\rIllumina khuyến nghị sử dụng f1.4xlarge khi dùng instance F1 và f2.6xlarge khi dùng instance F2. Để đánh giá hiệu năng trên các instance này, DRAGEN đã được cấu hình và chạy trên AWS theo hướng dẫn người dùng Illumina DRAGEN, và các liên kết tới genome reference file có thể tìm thấy trên trang web Illumina DRAGEN Product Files.\nPhân tích Whole Genome Sequencing (WGS) với độ phủ khoảng 35x sử dụng một mẫu có sẵn công khai. Mẫu HG002 từ dự án NIST Genome in a Bottle đã được sử dụng. Mẫu này được phân tích bằng DRAGEN v4.4 Germline pipeline theo hai cách khác nhau. Phân tích “cơ bản” chỉ bao gồm alignment cơ bản và small variant calling, nhằm tạo điều kiện so sánh với các pipeline tin sinh học phổ biến cho mẫu germline như BWA/GATK. Phân tích “đầy đủ” sử dụng tất cả các variant caller, bao gồm cả copy number và structural variants, cùng các tùy chọn bổ sung như gọi pharmacogenetic star allele và gọi HLA (Human Leukocyte Antigen), để tạo ra một bộ genome được phân tích đầy đủ. Trong cả hai trường hợp, tham chiếu đồ thị multigenome hg38 của DRAGEN được sử dụng cho phân tích WGS. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: fastq R1, fastq R2.\nPhân tích Tumor-Normal sử dụng một cặp mẫu đã được khảo sát trong một ấn phẩm về phân tích ung thư của DRAGEN trước đây. Hai mẫu này có độ phủ khoảng 110x (tumor) và 40x (normal). Các mẫu được phân tích bằng DRAGEN v4.4 Somatic pipeline, bao gồm alignment, small variant calling, cũng như phân tích CNV và SV. Phân tích Tumor-Normal sử dụng hg38 linear genome reference của DRAGEN. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: Tumor fastq R1, Tumor fastq R2, Normal fastq R1, Normal fastq R2.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích WGS\rPhân tích WGS sử dụng DRAGEN v4.4 cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn cho ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích WGS cơ bản, bao gồm alignment và small variant calling. DRAGEN v4.4 chạy trên f2.6xlarge đạt tốc độ nhanh hơn 1,5 lần và chỉ tốn 40% chi phí compute EC2 so với f1.4xlarge.\nPhân tích WGS đầy đủ, bao gồm alignment, small variant calling, calling of CNVs, SVs, repeat expansions, và variant annotation. Phân tích DRAGEN trên f2.6xlarge đạt tốc độ nhanh gấp 2 lần và chỉ tốn 30% chi phí compute EC2 so với f1.4xlarge.\nHình 1: Instance f2.6xlarge nhanh hơn 1.5 lần trong Phân tích WGS cơ bản và nhanh hơn 2.1 lần trong Phân tích WGS đầy đủ so với f1.4xlarge.\nHình 2: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 40% chi phí trên f1.4xlarge cho Phân tích WGS cơ bản và bằng 30% chi phí trên f1.4xlarge cho Phân tích WGS đầy đủ.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích Tumor-Normal\rGiống như kết quả WGS, trong phân tích Tumor-Normal, DRAGEN v4.4 cũng cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn tạo ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích Tumor-Normal, bao gồm alignment, small variant calling và calling CNVs/SVs. Phân tích bằng DRAGEN trên f2.6xlarge đạt tốc độ nhanh hơn 1.7 lần và chỉ tốn 35% chi phí compute EC2 so với f1.4xlarge. Hình 3: Instance f2.6xlarge nhanh hơn 1.7 lần so với f1.4xlarge trong Phân tích Tumor-Normal.\nHình 4: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 35% chi phí trên f1.4xlarge cho Phân tích Tumor-Normal WGS.\nCác lợi ích khác\rCác pipeline phân tích genomic truyền thống sử dụng BWA-MEM và GATK chạy trên CPU từng là tiêu chuẩn công nghiệp trong quá khứ, nhưng DRAGEN đã ngày càng được ưa chuộng nhờ những ưu thế vượt trội về tốc độ và độ chính xác. Nhiều công bố đã được bình duyệt đã so sánh tốc độ và độ chính xác của DRAGEN với các pipeline dựa trên BWA/GATK chạy trên CPU. Ví dụ, Ziegler et al. (2022) đã phát hiện ra rằng phân tích DRAGEN trên phần cứng FPGA nhanh hơn gấp hơn 8 lần và chính xác hơn so với các pipeline dựa trên BWA/GATK chạy trên CPU, trong khi Sedlazek et al. (2024) cũng ghi nhận DRAGEN cho hiệu suất và độ chính xác cao hơn so với các pipeline dựa trên BWA/GATK.\nViệc sử dụng DRAGEN trên các instance F, được tăng tốc bởi FPGA, còn mang lại lợi thế về tiêu thụ điện năng so với các giải pháp truyền thống dựa trên CPU và GPU. FPGA vốn dĩ tiết kiệm năng lượng hơn, tiêu thụ ít điện năng hơn nhưng vẫn đạt hiệu năng tính toán tương đương cho các workload này. Điều này đặc biệt quan trọng trong các tác vụ phân tích dữ liệu genomic, nơi khối lượng dữ liệu và thời gian xử lý có thể rất lớn.\nChẳng hạn, FPGA đạt được hiệu suất trên mỗi watt cao hơn so với CPU và GPU trong các tác vụ WGS của DRAGEN. Các bộ tăng tốc dựa trên FPGA có thể cung cấp thông lượng vượt trội với mức tiêu thụ điện năng thấp hơn. Điều này là nhờ khả năng tùy chỉnh linh hoạt của FPGA, cho phép cấu hình tối ưu hóa nhằm nâng cao hiệu quả năng lượng. Ngược lại, CPU và GPU, dù mạnh mẽ, thường tiêu tốn nhiều năng lượng hơn để thực hiện cùng một tác vụ, dẫn đến chi phí vận hành cao hơn và tác động môi trường lớn hơn.\nViệc tiêu thụ điện năng thấp hơn của các FPGA dẫn đến giảm các yêu cầu về làm mát, đây có thể là một yếu tố chi phí đáng kể trong các môi trường điện toán quy mô lớn. Ngoài ra, hiệu quả năng lượng của FPGA khiến chúng trở thành lựa chọn hấp dẫn cho các ứng dụng điện toán hiệu năng cao, nơi khả năng mở rộng và hiệu quả chi phí đóng vai trò then chốt.\nTóm lại, việc triển khai DRAGEN trên các instance thuộc họ ‘F’ của Amazon EC2 mang lại một giải pháp tiết kiệm năng lượng hơn cho phân tích dữ liệu genomic so với các phương pháp truyền thống dựa trên CPU hoặc GPU, đồng thời mang lại cả lợi ích về chi phí lẫn lợi ích môi trường.\nKhả năng triển khai và các tùy chọn triển khai trên cloud của instance F2\rCác instance Amazon EC2 F2 hiện đã có sẵn tại nhiều Region của AWS, bao gồm US East (N. Virginia), US West (Oregon), Europe (London) và Asia Pacific (Sydney), với kế hoạch mở rộng thêm sang nhiều Region khác trong tương lai. F2 cung cấp nhiều kích cỡ khác nhau như f2.6xlarge, f2.12xlarge và f2.48xlarge, nhằm đáp ứng đa dạng nhu cầu workload.\nKhi cấu hình lưu trữ và compute để chạy các workload DRAGEN trên các instance F của AWS, bạn cần lựa chọn các tùy chọn phù hợp để cân bằng giữa hiệu năng và chi phí. Hãy cân nhắc các tùy chọn lưu trữ như là Amazon EBS gp3 volumes được cấu hình theo RAID, Amazon FSx for Lustre cho thông lượng cao hơn và Amazon Elastic File System (EFS) cho lưu trữ liên tục. Ngoài ra, việc truyền trực tuyến các tệp BAM và dữ liệu tham chiếu từ Amazon Simple Storage Service (Amazon S3) hoặc sử dụng Mountpoint for Amazon S3 để mount bucket S3 vào hệ thống file cục bộ giúp truy cập dữ liệu một cách tiết kiệm chi phí và dễ dàng. Bằng cách lựa chọn và cấu hình cẩn thận các giải pháp lưu trữ này, bạn có thể đảm bảo hiệu năng tối ưu và hiệu quả chi phí cho các workload HPC của mình. Bên cạnh đó, bạn cũng nên cân nhắc sử dụng Illumina Connected Analytics (ICA) hoặc AWS Batch để quản lý workflow. Illumina cung cấp hướng dẫn chi tiết về cách triển khai DRAGEN trên AWS trong tài liệu hướng dẫn người dùng DRAGEN trực tuyến của họ.\nKết luận\rTóm lại, các instance Amazon EC2 F2 đánh dấu một bước tiến đáng kể trong lĩnh vực điện toán đám mây được cung cấp bởi FPGA, mang lại hiệu năng, bộ nhớ, dung lượng lưu trữ và khả năng kết nối mạng vượt trội so với thế hệ trước. Sự kết hợp giữa các pipeline toàn diện của DRAGEN và sức mạnh tính toán được nâng cấp của Amazon EC2 F2 cho phép xử lý nhanh hơn, hiệu quả hơn đối với các bộ dữ liệu phức tạp – từ whole genome sequencing đến phân tích single-cell RNA.\nHãy bắt đầu chuyển đổi sang F2 ngay hôm nay. Vui lòng liên hệ với đội ngũ tài khoản AWS của bạn hoặc Illumina để được hỗ trợ trong quá trình chuyển đổi sang Amazon EC2 F2 instances.\nĐể biết thêm thông tin về DRAGEN trên AWS, hãy tìm kiếm DRAGEN Complete Suite trên AWS Marketplace, xem blog DRAGEN v4.4, hoặc truy cập trang chủ Illumina Informatics Solutions.\nTài liệu tham khảo\rScheffler, K. et al. “Somatic small-variant calling methods in Illumina DRAGEN™ Secondary Analysis.” BioRxiv (2023). https://www.biorxiv.org/content/10.1101/2023.03.23.534011v2\nSedlazeck, F. J. et al. “Comprehensive genome analysis and variant detection at scale using DRAGEN.” Nature Biotechnology (2024). https://www.nature.com/articles/s41587-024-02382-1\nZiegler, A. et al. “Comparison of calling pipelines for whole genome sequencing: an empirical study demonstrating the importance of mapping and alignment.” Scientific Reports (2022). https://pubmed.ncbi.nlm.nih.gov/36513709/\nChú thích\rSự tương đương giữa F1 và F2 hard-filtered.vcf cùng các tệp kết quả khác dựa trên kết quả phân tích sử dụng DRAGEN 4.4.4 theo hướng dẫn sử dụng DRAGEN của Illumina. Lệnh vim diff cho thấy sự khác biệt duy nhất giữa hai tệp VCF là một mục hiển thị thời gian thực hiện phân tích. Khách hàng có thể tự thực hiện các phân tích tương tự để xác minh hoặc liên hệ với Illumina để biết thêm thông tin.",
    "description": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\rEric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)",
    "tags": [],
    "title": "Blog 6",
    "uri": "/en/3-translated_blogs/blog_6/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Self Assesment",
    "uri": "/en/6-self-assesment/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 6 Objectives\rContinue frontend and backend development Explore Elasticache for Redis and Amazon RDS services Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 03/11/2025 03/11/2025 - Code backend Authentication Service, User Service - Code frontend 2 - Learn about Elasticache for Redis 04/10/2025 04/10/2025 Amazon AWS ElastiCache Deployment, AWS Elasticache Redis Creation and redis-cli Configuration step by step process - Code backend Authentication Service, User Service - Code frontend - Integrate message sending via Kafka into the Taskflow Service so it can notify the Notification Service to send alerts to users. 3 - Update worklog 05/11/2025 05/11/2025 - Code backend Authentication Service, User Service - Code frontend - Learn and integrate WebSocket into the Notification Service to deliver real-time notifications to users. 4 - Learn and practice Amazon RDS 06/11/2025 06/11/2025 Module 06-02 - Amazon RDS \u0026 Amazon Aurora, Module 06-Lab05-2.3 - Create RDS Security group, Module 06-Lab05-4 - Create RDS database instance - Code backend Authentication Service, User Service - Code frontend 5 - Code backend Authentication Service, User Service 07/11 07/11/2025 - Code frontend - Develop the Upcoming Task UI for the project and integrate the API calls from the Taskflow Service. - Update worklog",
    "description": "Week 6 Objectives\rContinue frontend and backend development Explore Elasticache for Redis and Amazon RDS services Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 03/11/2025 03/11/2025 - Code backend Authentication Service, User Service - Code frontend 2 - Learn about Elasticache for Redis 04/10/2025 04/10/2025 Amazon AWS ElastiCache Deployment, AWS Elasticache Redis Creation and redis-cli Configuration step by step process - Code backend Authentication Service, User Service - Code frontend - Integrate message sending via Kafka into the Taskflow Service so it can notify the Notification Service to send alerts to users. 3 - Update worklog 05/11/2025 05/11/2025 - Code backend Authentication Service, User Service - Code frontend - Learn and integrate WebSocket into the Notification Service to deliver real-time notifications to users. 4 - Learn and practice Amazon RDS 06/11/2025 06/11/2025 Module 06-02 - Amazon RDS \u0026 Amazon Aurora, Module 06-Lab05-2.3 - Create RDS Security group, Module 06-Lab05-4 - Create RDS database instance - Code backend Authentication Service, User Service - Code frontend 5 - Code backend Authentication Service, User Service 07/11 07/11/2025 - Code frontend - Develop the Upcoming Task UI for the project and integrate the API calls from the Taskflow Service. - Update worklog",
    "tags": [],
    "title": "Week 6 Worklog",
    "uri": "/en/1-worklog/1.6-week_6/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng\rTác giả: Joe Chapman và Sebastian Leks - 28/03/2022\nChủ đề: AWS CloudFormation, AWS Config\nTrong Phần 1 của loạt bài này, chúng ta đã xây dựng nền tảng cho ứng dụng đa vùng bằng cách sử dụng các dịch vụ tính toán, mạng và bảo mật của AWS. Trong Phần 2, chúng ta đã tích hợp các dịch vụ dữ liệu và sao chép của AWS để di chuyển và đồng bộ dữ liệu giữa các vùng AWS.\nTrong Phần 3, chúng ta sẽ tìm hiểu về các dịch vụ và tính năng của AWS được sử dụng cho nhắn tin, triển khai, giám sát và quản lý.\nCông cụ dành cho nhà phát triển\rTự động hóa với cơ sở hạ tầng dưới dạng mã (Infrastructure as Code – IaC) giúp loại bỏ các bước thủ công khi tạo và cấu hình hạ tầng. Nó cung cấp một mẫu có thể tái sử dụng, cho phép triển khai các môi trường nhất quán ở nhiều Vùng khác nhau.\nIaC với AWS CloudFormation StackSets sử dụng một mẫu duy nhất để tạo, cập nhật và xóa các stack trên nhiều tài khoản và Vùng chỉ trong một lần thực hiện. Khi viết một mẫu AWS CloudFormation, bạn có thể thay đổi hành vi triển khai bằng cách kết hợp các tham số với logic điều kiện. Ví dụ, bạn có thể đặt một tham số “standby” mà khi được gán giá trị “true” sẽ giới hạn số lượng Amazon Elastic Compute Cloud (Amazon EC2) instances trong một nhóm Auto Scaling của Amazon EC2 được triển khai tại một Vùng dự phòng.\nCác ứng dụng có triển khai trải rộng trên nhiều Vùng có thể sử dụng cross-Region actions trong AWS CodePipeline để xây dựng một pipeline phát hành nhất quán. Cách này giúp bạn không cần phải thiết lập các hành động khác nhau cho từng Vùng. EC2 Image Builder và Amazon Elastic Container Registry (Amazon ECR) có các tính năng sao chép liên vùng (cross-Region copy) để hỗ trợ triển khai AMI và image một cách đồng nhất, như đã đề cập ở Phần 1.\nKiến trúc hướng sự kiện\rCác ứng dụng hướng sự kiện và tách rời (decoupled, event-driven) tạo ra một kiến trúc có khả năng mở rộng và dễ bảo trì hơn, nhờ vào việc mỗi thành phần thực hiện nhiệm vụ cụ thể của nó một cách độc lập.\nAmazon EventBridge, một dịch vụ event bus không máy chủ (serverless), có thể gửi sự kiện giữa các tài nguyên AWS. Bằng cách tận dụng định tuyến sự kiện liên vùng (cross-Region event routing), bạn có thể chia sẻ sự kiện giữa các workloads ở các Vùng (Hình 1) và giữa các tài khoản. Ví dụ, bạn có thể chia sẻ các sự kiện về tình trạng và mức sử dụng (health and utilization) giữa các Vùng để xác định workload nào ở Vùng nào là phù hợp nhất để xử lý yêu cầu.\nHình 1. EventBridge định tuyến sự kiện từ một Vùng sang các event bus ở các Vùng khác\rNếu ứng dụng hướng sự kiện của bạn dựa trên mô hình pub/sub messaging, thì Amazon Simple Notification Service (Amazon SNS) có thể phân phối (fan out) thông điệp đến nhiều đích khác nhau. Khi các đích đến là Amazon Simple Queue Service (Amazon SQS) queues hoặc AWS Lambda functions, Amazon SNS có thể gửi thông báo đến các đối tượng nhận ở nhiều Vùng khác nhau. Ví dụ, bạn có thể gửi thông điệp đến một SQS queue trung tâm để xử lý các đơn hàng cho một ứng dụng đa vùng.\nGiám sát và khả năng quan sát (Monitoring and observability)\rKhả năng quan sát (observability) càng trở nên quan trọng khi số lượng tài nguyên và vị trí triển khai tăng lên. Việc có thể nhanh chóng xác định được tác động và nguyên nhân gốc rễ của một sự cố sẽ ảnh hưởng đến các hoạt động khắc phục, và đảm bảo rằng hệ thống quan sát của bạn có khả năng chống chịu với sự cố sẽ giúp bạn đưa ra những quyết định này. Khi xây dựng trên AWS, bạn có thể kết hợp tình trạng sức khỏe của các dịch vụ AWS với các chỉ số ứng dụng của bạn để có được cái nhìn toàn diện hơn về sức khỏe của cơ sở hạ tầng.\nAWS Health cung cấp bảng điều khiển (dashboards) và API hiển thị các sự kiện và hoạt động đã lên lịch có thể ảnh hưởng đến tài nguyên của bạn. Những sự kiện này bao phủ tất cả các Region, và có thể mở rộng để bao gồm toàn bộ tài khoản trong AWS Organization. EventBridge có thể giám sát các sự kiện từ AWS Health để thực hiện ngay hành động dựa trên sự kiện đó. Ví dụ, nếu nhiều dịch vụ được báo cáo là đang suy giảm, bạn có thể đặt EventBridge target tới một AWS Systems Manager automated runbook nhằm chuẩn bị ứng dụng disaster recovery (DR) cho việc chuyển đổi dự phòng (failover).\nAWS Trusted Advisor cung cấp các cảnh báo mang tính hành động nhằm tối ưu chi phí, tăng hiệu năng, cũng như cải thiện bảo mật và khả năng chịu lỗi. Trusted Advisor hiển thị kết quả trên tất cả các Region và có thể tạo báo cáo tổng hợp kết quả kiểm tra trên toàn bộ tài khoản trong một tổ chức.\nĐể duy trì khả năng quan sát đối với một ứng dụng được triển khai trên nhiều Region và nhiều tài khoản, bạn có thể tạo Trusted Advisor dashboard và operations dashboard bằng AWS Systems Manager Explorer. Operations dashboard mang đến cái nhìn hợp nhất về các tài nguyên như Amazon EC2, Amazon CloudWatch, và dữ liệu AWS Config. Bạn có thể kết hợp metadata với Amazon Athena để tạo ra một bảng kiểm kê (inventory) đa-Region và đa-tài khoản về các tài nguyên.\nBạn có thể xem các metric từ ứng dụng và tài nguyên được triển khai trên nhiều Region ngay trong CloudWatch console. Điều này giúp dễ dàng tạo biểu đồ và dashboard cho ứng dụng đa-Region. CloudWatch cũng hỗ trợ cross-account, cho phép bạn tạo một cái nhìn tập trung về dashboards, alarms, và metrics trên toàn bộ tổ chức của mình.\nAmazon OpenSearch Service tập hợp các log file không cấu trúc hoặc bán cấu trúc, message, metric, document, dữ liệu cấu hình, và nhiều loại dữ liệu khác. Cross-cluster replication (nhân bản chéo cụm) sẽ sao chép indices, mappings, và metadata trong mô hình active-passive từ một domain OpenSearch sang một domain khác. Điều này giúp giảm độ trễ giữa các Region và đảm bảo tính sẵn sàng cao cho dữ liệu.\nAWS Resilience Hub đánh giá và theo dõi khả năng chịu lỗi (resiliency) của ứng dụng. Nó kiểm tra mức độ ứng dụng có thể duy trì tính khả dụng khi thực hiện failover ở cấp độ Region. Ví dụ, nó có thể kiểm tra xem ứng dụng đã cấu hình cross-Region replication trên các bucket Amazon S3 chưa, hoặc các instance Amazon RDS đã có read-replica cross-Region hay chưa. Hình 2 minh họa kết quả đánh giá từ Resilience Hub. Nó cũng gợi ý việc sử dụng Route 53 Application Recovery Controller (được đề cập trong Phần 1) để đảm bảo Auto Scaling group của Amazon EC2 trong một Region được scale sẵn và sẵn sàng nhận traffic trước khi chuyển failover sang đó.\nHình 2. Các khuyến nghị của Resilience Hub\rQuản lý: Quản trị (Governance)\rViệc mở rộng một ứng dụng sang một quốc gia mới đồng nghĩa với việc có thể sẽ có thêm những luật và quy định về quyền riêng tư dữ liệu cần tuân thủ. Những điều này sẽ khác nhau tùy theo từng quốc gia, và chúng tôi khuyến nghị bạn nên tham khảo với nhóm pháp lý của mình để hiểu đầy đủ cách chúng ảnh hưởng đến ứng dụng của bạn.\nAWS Control Tower hỗ trợ tuân thủ dữ liệu bằng cách cung cấp các guardrails nhằm kiểm soát và đáp ứng các yêu cầu về lưu trú dữ liệu. Các guardrails này là tập hợp của Service Control Policies (SCPs) và các quy tắc AWS Config. Bạn có thể triển khai chúng độc lập với AWS Control Tower nếu cần. Các dịch vụ đa vùng (multi-Region) tập trung vào bảo mật bổ sung đã được đề cập trong Phần 1.\nAWS Config cung cấp một cái nhìn chi tiết về cấu hình và lịch sử của các tài nguyên AWS. Một AWS Config aggregator thu thập dữ liệu cấu hình và tuân thủ từ nhiều tài khoản và nhiều Vùng (Region) về một tài khoản trung tâm. Cái nhìn tập trung này mang lại một cái nhìn toàn diện về sự tuân thủ và các hành động trên tài nguyên, bất kể chúng nằm ở tài khoản hay Vùng nào.\nQuản lý: Vận hành (Operations)\rMột số khả năng của AWS Systems Manager cho phép quản trị tài nguyên AWS dễ dàng hơn, đặc biệt khi ứng dụng phát triển. Systems Manager Automation đơn giản hóa các tác vụ bảo trì và triển khai phổ biến cho tài nguyên AWS thông qua các runbook tự động. Những runbook này tự động hóa các hành động trên tài nguyên trải rộng nhiều Vùng và nhiều tài khoản.\nBạn có thể kết hợp Systems Manager Automation với Systems Manager Patch Manager để đảm bảo các phiên bản (instances) luôn duy trì bản vá mới nhất trên nhiều tài khoản và nhiều Vùng. Hình 3 cho thấy Systems Manager đang chạy nhiều tài liệu tự động (automation documents) trên một kiến trúc đa vùng.\nHình 3. Sử dụng Systems Manager Automation từ một tài khoản vận hành trung tâm của AWS để tự động hóa các hành động trên nhiều Vùng (Region).\rKết hợp lại\rỞ cuối mỗi phần của loạt blog này, chúng tôi xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho bạn thấy cách kết hợp các dịch vụ để tạo ra một ứng dụng đa vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả các dịch vụ đã nhắc đến, mà chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến một đối tượng toàn cầu. Ứng dụng này yêu cầu tính khả dụng cao trên nhiều vùng và ưu tiên hiệu năng hơn là tính nhất quán nghiêm ngặt. Chúng tôi đã chọn các dịch vụ sau (được đề cập trong bài viết này) để đạt được mục tiêu, đồng thời xây dựng dựa trên nền tảng từ phần 1 và phần 2:\nCloudFormation StackSets để triển khai toàn bộ bằng IaC. Điều này đảm bảo hạ tầng được triển khai nhất quán trên các vùng.\nAWS Config rules cung cấp một nơi tập trung để giám sát, ghi nhận và đánh giá cấu hình tài nguyên của chúng tôi.\nĐể tăng khả năng quan sát (observability), chúng tôi đã tạo dashboard với CloudWatch dashboard, Personal Health dashboard, và Trusted Advisor dashboard.\nHình 4. Xây dựng một ứng dụng với các dịch vụ đa vùng (multi-Region).\rMặc dù mục tiêu chính của chúng tôi là mở rộng đến một đối tượng người dùng toàn cầu, chúng tôi lưu ý rằng một số dịch vụ như CloudFormation StackSets phụ thuộc vào Vùng 1. Mỗi triển khai theo vùng được thiết lập để có tính ổn định tĩnh, nhưng nếu xảy ra sự cố ngừng hoạt động kéo dài ở Vùng 1, kế hoạch khắc phục thảm họa (DR playbook) của chúng tôi sẽ nêu rõ cách thực hiện các thay đổi CloudFormation tại Vùng 2.\nTóm tắt\rNhiều dịch vụ AWS có các tính năng hỗ trợ bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể gây choáng ngợp.\nTrong loạt blog 3 phần này, chúng tôi đã khám phá các dịch vụ AWS với những tính năng giúp bạn xây dựng ứng dụng đa vùng:\nỞ Phần 1, chúng tôi xây dựng nền tảng với các dịch vụ về bảo mật, mạng và điện toán của AWS.\nỞ Phần 2, chúng tôi bổ sung chiến lược dữ liệu và sao chép.\nCuối cùng, ở Phần 3, chúng tôi xem xét các lớp ứng dụng và quản lý.\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-3-application-management-and-monitoring/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép",
    "description": "Xây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng\rTác giả: Joe Chapman và Sebastian Leks - 28/03/2022\nChủ đề: AWS CloudFormation, AWS Config\nTrong Phần 1 của loạt bài này, chúng ta đã xây dựng nền tảng cho ứng dụng đa vùng bằng cách sử dụng các dịch vụ tính toán, mạng và bảo mật của AWS. Trong Phần 2, chúng ta đã tích hợp các dịch vụ dữ liệu và sao chép của AWS để di chuyển và đồng bộ dữ liệu giữa các vùng AWS.",
    "tags": [],
    "title": "Blog 7",
    "uri": "/en/3-translated_blogs/blog_7/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Sharing and Feedback",
    "uri": "/en/7-sharing_and_feedback/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 10/11/2025 10/11/2025 - Code backend User Service, Notification Service - Code frontend 2 - Learn about Application Load Balancer 11/11/2025 11/11/2025 AWS ALB (Application Load Balancer) - Step By Step Tutorial, Create an Application Load Balancer (ALB) in AWS - AWS Elastic Load Balancing Tutorial for Beginners - Code backend User Service, Notification Service - Code frontend 3 - Learn how to deploy the system on cloud resources 12/11/2025 12/11/2025 - Code backend User Service, Notification Service - Code frontend 4 - Code backend User Service, Notification Service 13/11/2025 13/11/2025 - Code frontend 5 - Code backend User Service, Notification Service 14/11/2025 14/11/2025 - Code frontend - Test deploying the Frontend on S3",
    "description": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 10/11/2025 10/11/2025 - Code backend User Service, Notification Service - Code frontend 2 - Learn about Application Load Balancer 11/11/2025 11/11/2025 AWS ALB (Application Load Balancer) - Step By Step Tutorial, Create an Application Load Balancer (ALB) in AWS - AWS Elastic Load Balancing Tutorial for Beginners - Code backend User Service, Notification Service - Code frontend 3 - Learn how to deploy the system on cloud resources 12/11/2025 12/11/2025 - Code backend User Service, Notification Service - Code frontend 4 - Code backend User Service, Notification Service 13/11/2025 13/11/2025 - Code frontend 5 - Code backend User Service, Notification Service 14/11/2025 14/11/2025 - Code frontend - Test deploying the Frontend on S3",
    "tags": [],
    "title": "Week 7 Worklog",
    "uri": "/en/1-worklog/1.7-week_7/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share\nNhiều dịch vụ AWS có các tính năng giúp bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể là một thách thức lớn.\nTrong loạt blog gồm 3 phần này, chúng tôi sẽ chọn lọc từ hơn 200 dịch vụ đó và tập trung vào những dịch vụ có tính năng cụ thể hỗ trợ bạn xây dựng ứng dụng đa vùng. Trong Phần 1, chúng ta sẽ xây dựng nền tảng với các dịch vụ bảo mật, mạng, và tính toán của AWS. Ở Phần 2, chúng ta sẽ bổ sung các chiến lược dữ liệu và sao chép. Cuối cùng, trong Phần 3, chúng ta sẽ tìm hiểu về lớp ứng dụng và quản lý. Khi đi qua từng phần, chúng ta sẽ dần xây dựng một ứng dụng mẫu để minh họa cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững điều cần cân nhắc trước khi bắt đầu\rCác AWS Region được xây dựng với nhiều Availability Zone (AZ) tách biệt và cách ly về mặt vật lý. Cách tiếp cận này cho phép bạn tạo ra các workload có độ sẵn sàng cao, tuân thủ nguyên tắc Well-Architected, trải rộng trên nhiều AZ để đạt được khả năng chịu lỗi tốt hơn. Điều này đáp ứng được mục tiêu khả dụng cho hầu hết các ứng dụng, nhưng vẫn có một số lý do chung khiến bạn có thể muốn mở rộng ra ngoài một Region duy nhất:\nMở rộng ra khán giả toàn cầu: khi ứng dụng phát triển và lượng người dùng trở nên phân tán về mặt địa lý, có thể sẽ cần giảm độ trễ cho các khu vực khác nhau trên thế giới.\nGiảm RPO (Recovery Point Objective) và RTO (Recovery Time Objective): như một phần của kế hoạch khắc phục thảm họa (Disaster Recovery – DR) đa vùng.\nLuật pháp và quy định địa phương: có thể có những yêu cầu nghiêm ngặt về lưu trú dữ liệu (data residency) và quyền riêng tư mà bạn buộc phải tuân thủ.\nNếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn nên cân nhắc tập trung vào các dịch vụ AWS có sẵn chức năng hỗ trợ. Với những ứng dụng hiện có, cần phải xem xét kỹ hơn để xác định kiến trúc nào có khả năng mở rộng nhất nhằm đáp ứng sự phát triển. Các phần tiếp theo sẽ xem xét những dịch vụ này, đồng thời nêu bật các trường hợp sử dụng và thực tiễn tốt nhất.\nQuản lý danh tính và truy cập trên nhiều Region\rXây dựng nền tảng bảo mật bắt đầu từ việc thiết lập các quy tắc xác thực (authentication) và phân quyền (authorization) phù hợp. Hệ thống xử lý các yêu cầu này phải có khả năng chịu lỗi cao để xác minh và cấp quyền nhanh chóng, đáng tin cậy. AWS Identity and Access Management (IAM) đáp ứng điều này bằng cách cung cấp một cơ chế đáng tin cậy để bạn quản lý quyền truy cập vào các dịch vụ và tài nguyên AWS. IAM có khả năng sẵn sàng trên nhiều Region một cách tự động, mà bạn không cần phải cấu hình gì thêm.\nĐể hỗ trợ quản lý người dùng Windows, thiết bị và ứng dụng trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory Enterprise Edition, dịch vụ này sẽ tự động sao chép dữ liệu thư mục giữa các Region. Điều này giúp giảm độ trễ khi tra cứu thư mục bằng cách sử dụng thư mục gần nhất, đồng thời tăng tính bền vững bằng cách trải rộng trên nhiều Region. Lưu ý rằng điều này cũng kéo theo “số phận chung” giữa các domain controller trong kiến trúc đa vùng, vì các thay đổi group policy sẽ được lan truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, luân chuyển và kiểm toán bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật bằng khóa của AWS Key Management Service (AWS KMS) và có thể sao chép các bí mật sang Region thứ cấp để đảm bảo ứng dụng có thể nhanh chóng lấy được bí mật từ Region gần nhất.\nMã hóa trên nhiều Region\rAWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ (data at rest) và được dùng rộng rãi cho việc mã hóa trên các dịch vụ AWS. Theo mặc định, các khóa chỉ giới hạn trong một Region. Những dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) cross-Region replication và Amazon Aurora Global Database (sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã bằng các khóa khác nhau ở từng Region.\nĐối với các phần khác trong ứng dụng đa vùng của bạn phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép cả key material và key ID sang Region thứ hai. Điều này loại bỏ nhu cầu giải mã rồi mã hóa lại dữ liệu với một khóa khác ở từng Region. Ví dụ, multi-Region keys có thể được dùng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng cho dữ liệu được lưu trữ trên nhiều Region.\nKiểm toán và khả năng quan sát trên nhiều Region\rMột thực tiễn tốt nhất là cấu hình AWS CloudTrail để lưu lại toàn bộ hoạt động AWS API liên quan trong tài khoản của bạn nhằm phục vụ mục đích kiểm toán. Khi bạn sử dụng nhiều Region hoặc nhiều tài khoản, các log CloudTrail này nên được tập hợp về một bucket Amazon S3 duy nhất để thuận tiện cho việc phân tích. Để ngăn chặn việc sử dụng sai mục đích, các log tập trung này cần được coi là dữ liệu nhạy cảm hơn, chỉ cấp quyền truy cập cho các hệ thống và nhân sự chủ chốt.\nĐể theo dõi các phát hiện từ AWS Security Hub, bạn có thể tổng hợp và liên kết các phát hiện từ nhiều vị trí về một Region duy nhất. Đây là cách đơn giản để tạo một cái nhìn tập trung về các phát hiện của Security Hub trên nhiều tài khoản và nhiều Region. Sau khi thiết lập, các phát hiện sẽ liên tục được đồng bộ giữa các Region để giúp bạn luôn nắm được kết quả toàn cầu trên một bảng điều khiển duy nhất.\nChúng tôi đã kết hợp những tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trong các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin đăng nhập cơ sở dữ liệu nhạy cảm. Dữ liệu của chúng tôi, di chuyển tự do giữa các Region, được mã hóa bằng KMS multi-Region keys, và toàn bộ hoạt động truy cập AWS API được ghi lại bởi CloudTrail, sau đó tập trung vào một bucket S3 trung tâm mà chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Các dịch vụ bảo mật, danh tính và tuân thủ đa vùng\rXây dựng mạng toàn cầu\rĐối với các tài nguyên được triển khai trong các mạng ảo ở những Region khác nhau, Amazon Virtual Private Cloud (Amazon VPC) cho phép định tuyến riêng tư giữa các Region và tài khoản bằng VPC peering. Các tài nguyên này có thể giao tiếp với nhau bằng địa chỉ IP riêng mà không cần internet gateway, VPN, hoặc thiết bị mạng riêng biệt. Tính năng này hoạt động tốt cho các mạng nhỏ chỉ cần một vài kết nối peering. Tuy nhiên, định tuyến bắc cầu (transitive routing) không được hỗ trợ, và khi số lượng VPC peering tăng lên, cấu trúc mạng dạng mesh có thể trở nên khó quản lý và khắc phục sự cố.\nAWS Transit Gateway giúp giảm bớt những khó khăn này bằng cách tạo một hub trung chuyển mạng, kết nối các VPC và mạng tại chỗ (on-premises). Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Region khác thông qua Transit Gateway inter-Region peering, để tạo ra một mạng riêng tư phân tán toàn cầu cho tài nguyên của bạn.\nXây dựng một cách định tuyến đáng tin cậy và tiết kiệm chi phí để đưa người dùng đến các ứng dụng internet phân tán đòi hỏi những bản ghi Domain Name System (DNS) có độ sẵn sàng cao và khả năng mở rộng tốt. Amazon Route 53 chính là dịch vụ làm được điều đó.\nRoute 53 có nhiều chính sách định tuyến khác nhau. Ví dụ, bạn có thể định tuyến một yêu cầu đến bản ghi có độ trễ mạng thấp nhất, hoặc đưa người dùng ở một vị trí địa lý cụ thể đến endpoint ứng dụng cục bộ. Đối với kịch bản khắc phục thảm họa (DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp một giải pháp failover toàn diện với mức phụ thuộc tối thiểu. Các routing policy, safety check, và readiness check của Route 53 ARC giúp bạn thực hiện failover qua nhiều Region, AZ, và môi trường on-premises một cách đáng tin cậy.\nAmazon CloudFront – mạng phân phối nội dung (CDN) – là một dịch vụ toàn cầu, được xây dựng trên hơn 300 điểm hiện diện (PoP) khắp thế giới. Các ứng dụng có nhiều origin khả dụng (ví dụ như nhiều Region) có thể dùng CloudFront origin failover để tự động chuyển hướng sang origin dự phòng khi origin chính gặp sự cố. Khả năng của CloudFront không chỉ dừng lại ở việc phân phát nội dung, mà còn có thể chạy tính toán ở edge. CloudFront Functions giúp dễ dàng chạy các đoạn mã JavaScript nhẹ, trong khi AWS Lambda@Edge cho phép bạn chạy các hàm Node.js và Python gần hơn với người dùng ứng dụng, từ đó cải thiện hiệu năng và giảm độ trễ. Việc đưa compute ra edge giúp giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nĐược xây dựng trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm truy cập duy nhất cho các ứng dụng hướng internet. Bạn có thể linh hoạt thêm hoặc xóa origin trong khi hệ thống vẫn tự động định tuyến lưu lượng đến endpoint khu vực khỏe mạnh gần nhất. Nếu phát hiện lỗi, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến một endpoint khả dụng chỉ trong vài giây, mà không cần thay đổi địa chỉ IP tĩnh.\nHình 2 minh họa việc sử dụng Route 53 latency-based routing policy để định tuyến người dùng đến endpoint nhanh nhất, CloudFront để phân phát nội dung tĩnh như video và hình ảnh, và Transit Gateway để tạo một mạng riêng toàn cầu, giúp các thiết bị của chúng tôi có thể giao tiếp an toàn trên nhiều Region.\nHình 2. Kết nối AWS VPC và phân phối nội dung\rXây dựng và quản lý lớp tính toán (compute layer)\rMặc dù Amazon Elastic Compute Cloud (Amazon EC2) và các Amazon Elastic Block Store (Amazon EBS) volume liên kết chỉ tồn tại trong một AZ, Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot EBS giữa các Region. Điều này giúp nâng cao chiến lược khắc phục thảm họa (DR) bằng cách cung cấp một lựa chọn sao lưu và khôi phục lạnh (cold backup-and-restore) đơn giản cho các volume EBS. Nếu bạn cần sao lưu nhiều hơn chỉ các EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ (sẽ được đề cập trong phần 2).\nMột EC2 instance được xây dựng dựa trên một Amazon Machine Image (AMI). AMI xác định cấu hình của instance như lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một image chuẩn mới, EC2 Image Builder giúp đơn giản hóa quá trình xây dựng, kiểm thử, và triển khai AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region bổ sung, loại bỏ việc phải sao chép thủ công AMI nguồn sang các Region đích.\nCác ứng dụng dựa trên microservice sử dụng container sẽ hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) có thể đảm bảo điều này diễn ra nhất quán trên nhiều Region bằng cách sao chép image riêng tư ở cấp độ registry. Một ECR private registry có thể được cấu hình cho cả cross-Region hoặc cross-account replication, để đảm bảo image của bạn luôn sẵn sàng ở các Region thứ cấp khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi tài nguyên được cấp phát ở đâu có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt vấn đề này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instance, VPC, subnet, security group, và volume trong tất cả các Region đang hoạt động.\nChúng tôi kết hợp các tính năng compute layer này trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép AMI chuẩn mới nhất của chúng tôi sang nhiều Region để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép nó sang nhiều Region bằng Data Lifecycle Manager.\nHình 3. Sao chép AMI và ảnh chụp nhanh EBS giữa các Vùng (Regions)\rĐưa tất cả lại với nhau\rỞ cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\rTóm tắt\rKhi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\n*** Sẵn sàng để bắt đầu? *** Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\n*** Bạn đang tìm thêm nội dung về kiến trúc? *** AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng",
    "description": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share",
    "tags": [],
    "title": "Blog 8",
    "uri": "/en/3-translated_blogs/blog_8/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Week 8 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 17/11/2025 17/11/2025 - Build the Notification interface for the project, integrate the APIs, and establish a WebSocket connection to the backend. - Check the services code",
    "description": "Week 8 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 17/11/2025 17/11/2025 - Build the Notification interface for the project, integrate the APIs, and establish a WebSocket connection to the backend. - Check the services code",
    "tags": [],
    "title": "Week 8 Worklog",
    "uri": "/en/1-worklog/1.8-week_8/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share\nNhiều dịch vụ AWS có các tính năng giúp bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể là một thách thức lớn.\nTrong loạt blog gồm 3 phần này, chúng tôi sẽ chọn lọc từ hơn 200 dịch vụ đó và tập trung vào những dịch vụ có tính năng cụ thể hỗ trợ bạn xây dựng ứng dụng đa vùng. Trong Phần 1, chúng ta sẽ xây dựng nền tảng với các dịch vụ bảo mật, mạng, và tính toán của AWS. Ở Phần 2, chúng ta sẽ bổ sung các chiến lược dữ liệu và sao chép. Cuối cùng, trong Phần 3, chúng ta sẽ tìm hiểu về lớp ứng dụng và quản lý. Khi đi qua từng phần, chúng ta sẽ dần xây dựng một ứng dụng mẫu để minh họa cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững điều cần cân nhắc trước khi bắt đầu\rCác AWS Region được xây dựng với nhiều Availability Zone (AZ) tách biệt và cách ly về mặt vật lý. Cách tiếp cận này cho phép bạn tạo ra các workload có độ sẵn sàng cao, tuân thủ nguyên tắc Well-Architected, trải rộng trên nhiều AZ để đạt được khả năng chịu lỗi tốt hơn. Điều này đáp ứng được mục tiêu khả dụng cho hầu hết các ứng dụng, nhưng vẫn có một số lý do chung khiến bạn có thể muốn mở rộng ra ngoài một Region duy nhất:\nMở rộng ra khán giả toàn cầu: khi ứng dụng phát triển và lượng người dùng trở nên phân tán về mặt địa lý, có thể sẽ cần giảm độ trễ cho các khu vực khác nhau trên thế giới.\nGiảm RPO (Recovery Point Objective) và RTO (Recovery Time Objective): như một phần của kế hoạch khắc phục thảm họa (Disaster Recovery – DR) đa vùng.\nLuật pháp và quy định địa phương: có thể có những yêu cầu nghiêm ngặt về lưu trú dữ liệu (data residency) và quyền riêng tư mà bạn buộc phải tuân thủ.\nNếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn nên cân nhắc tập trung vào các dịch vụ AWS có sẵn chức năng hỗ trợ. Với những ứng dụng hiện có, cần phải xem xét kỹ hơn để xác định kiến trúc nào có khả năng mở rộng nhất nhằm đáp ứng sự phát triển. Các phần tiếp theo sẽ xem xét những dịch vụ này, đồng thời nêu bật các trường hợp sử dụng và thực tiễn tốt nhất.\nQuản lý danh tính và truy cập trên nhiều Region\rXây dựng nền tảng bảo mật bắt đầu từ việc thiết lập các quy tắc xác thực (authentication) và phân quyền (authorization) phù hợp. Hệ thống xử lý các yêu cầu này phải có khả năng chịu lỗi cao để xác minh và cấp quyền nhanh chóng, đáng tin cậy. AWS Identity and Access Management (IAM) đáp ứng điều này bằng cách cung cấp một cơ chế đáng tin cậy để bạn quản lý quyền truy cập vào các dịch vụ và tài nguyên AWS. IAM có khả năng sẵn sàng trên nhiều Region một cách tự động, mà bạn không cần phải cấu hình gì thêm.\nĐể hỗ trợ quản lý người dùng Windows, thiết bị và ứng dụng trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory Enterprise Edition, dịch vụ này sẽ tự động sao chép dữ liệu thư mục giữa các Region. Điều này giúp giảm độ trễ khi tra cứu thư mục bằng cách sử dụng thư mục gần nhất, đồng thời tăng tính bền vững bằng cách trải rộng trên nhiều Region. Lưu ý rằng điều này cũng kéo theo “số phận chung” giữa các domain controller trong kiến trúc đa vùng, vì các thay đổi group policy sẽ được lan truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, luân chuyển và kiểm toán bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật bằng khóa của AWS Key Management Service (AWS KMS) và có thể sao chép các bí mật sang Region thứ cấp để đảm bảo ứng dụng có thể nhanh chóng lấy được bí mật từ Region gần nhất.\nMã hóa trên nhiều Region\rAWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ (data at rest) và được dùng rộng rãi cho việc mã hóa trên các dịch vụ AWS. Theo mặc định, các khóa chỉ giới hạn trong một Region. Những dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) cross-Region replication và Amazon Aurora Global Database (sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã bằng các khóa khác nhau ở từng Region.\nĐối với các phần khác trong ứng dụng đa vùng của bạn phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép cả key material và key ID sang Region thứ hai. Điều này loại bỏ nhu cầu giải mã rồi mã hóa lại dữ liệu với một khóa khác ở từng Region. Ví dụ, multi-Region keys có thể được dùng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng cho dữ liệu được lưu trữ trên nhiều Region.\nKiểm toán và khả năng quan sát trên nhiều Region\rMột thực tiễn tốt nhất là cấu hình AWS CloudTrail để lưu lại toàn bộ hoạt động AWS API liên quan trong tài khoản của bạn nhằm phục vụ mục đích kiểm toán. Khi bạn sử dụng nhiều Region hoặc nhiều tài khoản, các log CloudTrail này nên được tập hợp về một bucket Amazon S3 duy nhất để thuận tiện cho việc phân tích. Để ngăn chặn việc sử dụng sai mục đích, các log tập trung này cần được coi là dữ liệu nhạy cảm hơn, chỉ cấp quyền truy cập cho các hệ thống và nhân sự chủ chốt.\nĐể theo dõi các phát hiện từ AWS Security Hub, bạn có thể tổng hợp và liên kết các phát hiện từ nhiều vị trí về một Region duy nhất. Đây là cách đơn giản để tạo một cái nhìn tập trung về các phát hiện của Security Hub trên nhiều tài khoản và nhiều Region. Sau khi thiết lập, các phát hiện sẽ liên tục được đồng bộ giữa các Region để giúp bạn luôn nắm được kết quả toàn cầu trên một bảng điều khiển duy nhất.\nChúng tôi đã kết hợp những tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trong các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin đăng nhập cơ sở dữ liệu nhạy cảm. Dữ liệu của chúng tôi, di chuyển tự do giữa các Region, được mã hóa bằng KMS multi-Region keys, và toàn bộ hoạt động truy cập AWS API được ghi lại bởi CloudTrail, sau đó tập trung vào một bucket S3 trung tâm mà chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Các dịch vụ bảo mật, danh tính và tuân thủ đa vùng\rXây dựng mạng toàn cầu\rĐối với các tài nguyên được triển khai trong các mạng ảo ở những Region khác nhau, Amazon Virtual Private Cloud (Amazon VPC) cho phép định tuyến riêng tư giữa các Region và tài khoản bằng VPC peering. Các tài nguyên này có thể giao tiếp với nhau bằng địa chỉ IP riêng mà không cần internet gateway, VPN, hoặc thiết bị mạng riêng biệt. Tính năng này hoạt động tốt cho các mạng nhỏ chỉ cần một vài kết nối peering. Tuy nhiên, định tuyến bắc cầu (transitive routing) không được hỗ trợ, và khi số lượng VPC peering tăng lên, cấu trúc mạng dạng mesh có thể trở nên khó quản lý và khắc phục sự cố.\nAWS Transit Gateway giúp giảm bớt những khó khăn này bằng cách tạo một hub trung chuyển mạng, kết nối các VPC và mạng tại chỗ (on-premises). Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Region khác thông qua Transit Gateway inter-Region peering, để tạo ra một mạng riêng tư phân tán toàn cầu cho tài nguyên của bạn.\nXây dựng một cách định tuyến đáng tin cậy và tiết kiệm chi phí để đưa người dùng đến các ứng dụng internet phân tán đòi hỏi những bản ghi Domain Name System (DNS) có độ sẵn sàng cao và khả năng mở rộng tốt. Amazon Route 53 chính là dịch vụ làm được điều đó.\nRoute 53 có nhiều chính sách định tuyến khác nhau. Ví dụ, bạn có thể định tuyến một yêu cầu đến bản ghi có độ trễ mạng thấp nhất, hoặc đưa người dùng ở một vị trí địa lý cụ thể đến endpoint ứng dụng cục bộ. Đối với kịch bản khắc phục thảm họa (DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp một giải pháp failover toàn diện với mức phụ thuộc tối thiểu. Các routing policy, safety check, và readiness check của Route 53 ARC giúp bạn thực hiện failover qua nhiều Region, AZ, và môi trường on-premises một cách đáng tin cậy.\nAmazon CloudFront – mạng phân phối nội dung (CDN) – là một dịch vụ toàn cầu, được xây dựng trên hơn 300 điểm hiện diện (PoP) khắp thế giới. Các ứng dụng có nhiều origin khả dụng (ví dụ như nhiều Region) có thể dùng CloudFront origin failover để tự động chuyển hướng sang origin dự phòng khi origin chính gặp sự cố. Khả năng của CloudFront không chỉ dừng lại ở việc phân phát nội dung, mà còn có thể chạy tính toán ở edge. CloudFront Functions giúp dễ dàng chạy các đoạn mã JavaScript nhẹ, trong khi AWS Lambda@Edge cho phép bạn chạy các hàm Node.js và Python gần hơn với người dùng ứng dụng, từ đó cải thiện hiệu năng và giảm độ trễ. Việc đưa compute ra edge giúp giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nĐược xây dựng trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm truy cập duy nhất cho các ứng dụng hướng internet. Bạn có thể linh hoạt thêm hoặc xóa origin trong khi hệ thống vẫn tự động định tuyến lưu lượng đến endpoint khu vực khỏe mạnh gần nhất. Nếu phát hiện lỗi, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến một endpoint khả dụng chỉ trong vài giây, mà không cần thay đổi địa chỉ IP tĩnh.\nHình 2 minh họa việc sử dụng Route 53 latency-based routing policy để định tuyến người dùng đến endpoint nhanh nhất, CloudFront để phân phát nội dung tĩnh như video và hình ảnh, và Transit Gateway để tạo một mạng riêng toàn cầu, giúp các thiết bị của chúng tôi có thể giao tiếp an toàn trên nhiều Region.\nHình 2. Kết nối AWS VPC và phân phối nội dung\rXây dựng và quản lý lớp tính toán (compute layer)\rMặc dù Amazon Elastic Compute Cloud (Amazon EC2) và các Amazon Elastic Block Store (Amazon EBS) volume liên kết chỉ tồn tại trong một AZ, Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot EBS giữa các Region. Điều này giúp nâng cao chiến lược khắc phục thảm họa (DR) bằng cách cung cấp một lựa chọn sao lưu và khôi phục lạnh (cold backup-and-restore) đơn giản cho các volume EBS. Nếu bạn cần sao lưu nhiều hơn chỉ các EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ (sẽ được đề cập trong phần 2).\nMột EC2 instance được xây dựng dựa trên một Amazon Machine Image (AMI). AMI xác định cấu hình của instance như lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một image chuẩn mới, EC2 Image Builder giúp đơn giản hóa quá trình xây dựng, kiểm thử, và triển khai AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region bổ sung, loại bỏ việc phải sao chép thủ công AMI nguồn sang các Region đích.\nCác ứng dụng dựa trên microservice sử dụng container sẽ hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) có thể đảm bảo điều này diễn ra nhất quán trên nhiều Region bằng cách sao chép image riêng tư ở cấp độ registry. Một ECR private registry có thể được cấu hình cho cả cross-Region hoặc cross-account replication, để đảm bảo image của bạn luôn sẵn sàng ở các Region thứ cấp khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi tài nguyên được cấp phát ở đâu có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt vấn đề này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instance, VPC, subnet, security group, và volume trong tất cả các Region đang hoạt động.\nChúng tôi kết hợp các tính năng compute layer này trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép AMI chuẩn mới nhất của chúng tôi sang nhiều Region để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép nó sang nhiều Region bằng Data Lifecycle Manager.\nHình 3. Sao chép AMI và ảnh chụp nhanh EBS giữa các Vùng (Regions)\rĐưa tất cả lại với nhau\rỞ cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\rTóm tắt\rKhi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\n*** Sẵn sàng để bắt đầu? *** Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\n*** Bạn đang tìm thêm nội dung về kiến trúc? *** AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng",
    "description": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share",
    "tags": [],
    "title": "Blog 9",
    "uri": "/en/3-translated_blogs/blog_9/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Week 9 Worklog",
    "uri": "/en/1-worklog/1.9-week_9/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share\nNhiều dịch vụ AWS có các tính năng giúp bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể là một thách thức lớn.\nTrong loạt blog gồm 3 phần này, chúng tôi sẽ chọn lọc từ hơn 200 dịch vụ đó và tập trung vào những dịch vụ có tính năng cụ thể hỗ trợ bạn xây dựng ứng dụng đa vùng. Trong Phần 1, chúng ta sẽ xây dựng nền tảng với các dịch vụ bảo mật, mạng, và tính toán của AWS. Ở Phần 2, chúng ta sẽ bổ sung các chiến lược dữ liệu và sao chép. Cuối cùng, trong Phần 3, chúng ta sẽ tìm hiểu về lớp ứng dụng và quản lý. Khi đi qua từng phần, chúng ta sẽ dần xây dựng một ứng dụng mẫu để minh họa cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững điều cần cân nhắc trước khi bắt đầu\rCác AWS Region được xây dựng với nhiều Availability Zone (AZ) tách biệt và cách ly về mặt vật lý. Cách tiếp cận này cho phép bạn tạo ra các workload có độ sẵn sàng cao, tuân thủ nguyên tắc Well-Architected, trải rộng trên nhiều AZ để đạt được khả năng chịu lỗi tốt hơn. Điều này đáp ứng được mục tiêu khả dụng cho hầu hết các ứng dụng, nhưng vẫn có một số lý do chung khiến bạn có thể muốn mở rộng ra ngoài một Region duy nhất:\nMở rộng ra khán giả toàn cầu: khi ứng dụng phát triển và lượng người dùng trở nên phân tán về mặt địa lý, có thể sẽ cần giảm độ trễ cho các khu vực khác nhau trên thế giới.\nGiảm RPO (Recovery Point Objective) và RTO (Recovery Time Objective): như một phần của kế hoạch khắc phục thảm họa (Disaster Recovery – DR) đa vùng.\nLuật pháp và quy định địa phương: có thể có những yêu cầu nghiêm ngặt về lưu trú dữ liệu (data residency) và quyền riêng tư mà bạn buộc phải tuân thủ.\nNếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn nên cân nhắc tập trung vào các dịch vụ AWS có sẵn chức năng hỗ trợ. Với những ứng dụng hiện có, cần phải xem xét kỹ hơn để xác định kiến trúc nào có khả năng mở rộng nhất nhằm đáp ứng sự phát triển. Các phần tiếp theo sẽ xem xét những dịch vụ này, đồng thời nêu bật các trường hợp sử dụng và thực tiễn tốt nhất.\nQuản lý danh tính và truy cập trên nhiều Region\rXây dựng nền tảng bảo mật bắt đầu từ việc thiết lập các quy tắc xác thực (authentication) và phân quyền (authorization) phù hợp. Hệ thống xử lý các yêu cầu này phải có khả năng chịu lỗi cao để xác minh và cấp quyền nhanh chóng, đáng tin cậy. AWS Identity and Access Management (IAM) đáp ứng điều này bằng cách cung cấp một cơ chế đáng tin cậy để bạn quản lý quyền truy cập vào các dịch vụ và tài nguyên AWS. IAM có khả năng sẵn sàng trên nhiều Region một cách tự động, mà bạn không cần phải cấu hình gì thêm.\nĐể hỗ trợ quản lý người dùng Windows, thiết bị và ứng dụng trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory Enterprise Edition, dịch vụ này sẽ tự động sao chép dữ liệu thư mục giữa các Region. Điều này giúp giảm độ trễ khi tra cứu thư mục bằng cách sử dụng thư mục gần nhất, đồng thời tăng tính bền vững bằng cách trải rộng trên nhiều Region. Lưu ý rằng điều này cũng kéo theo “số phận chung” giữa các domain controller trong kiến trúc đa vùng, vì các thay đổi group policy sẽ được lan truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, luân chuyển và kiểm toán bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật bằng khóa của AWS Key Management Service (AWS KMS) và có thể sao chép các bí mật sang Region thứ cấp để đảm bảo ứng dụng có thể nhanh chóng lấy được bí mật từ Region gần nhất.\nMã hóa trên nhiều Region\rAWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ (data at rest) và được dùng rộng rãi cho việc mã hóa trên các dịch vụ AWS. Theo mặc định, các khóa chỉ giới hạn trong một Region. Những dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) cross-Region replication và Amazon Aurora Global Database (sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã bằng các khóa khác nhau ở từng Region.\nĐối với các phần khác trong ứng dụng đa vùng của bạn phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép cả key material và key ID sang Region thứ hai. Điều này loại bỏ nhu cầu giải mã rồi mã hóa lại dữ liệu với một khóa khác ở từng Region. Ví dụ, multi-Region keys có thể được dùng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng cho dữ liệu được lưu trữ trên nhiều Region.\nKiểm toán và khả năng quan sát trên nhiều Region\rMột thực tiễn tốt nhất là cấu hình AWS CloudTrail để lưu lại toàn bộ hoạt động AWS API liên quan trong tài khoản của bạn nhằm phục vụ mục đích kiểm toán. Khi bạn sử dụng nhiều Region hoặc nhiều tài khoản, các log CloudTrail này nên được tập hợp về một bucket Amazon S3 duy nhất để thuận tiện cho việc phân tích. Để ngăn chặn việc sử dụng sai mục đích, các log tập trung này cần được coi là dữ liệu nhạy cảm hơn, chỉ cấp quyền truy cập cho các hệ thống và nhân sự chủ chốt.\nĐể theo dõi các phát hiện từ AWS Security Hub, bạn có thể tổng hợp và liên kết các phát hiện từ nhiều vị trí về một Region duy nhất. Đây là cách đơn giản để tạo một cái nhìn tập trung về các phát hiện của Security Hub trên nhiều tài khoản và nhiều Region. Sau khi thiết lập, các phát hiện sẽ liên tục được đồng bộ giữa các Region để giúp bạn luôn nắm được kết quả toàn cầu trên một bảng điều khiển duy nhất.\nChúng tôi đã kết hợp những tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trong các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin đăng nhập cơ sở dữ liệu nhạy cảm. Dữ liệu của chúng tôi, di chuyển tự do giữa các Region, được mã hóa bằng KMS multi-Region keys, và toàn bộ hoạt động truy cập AWS API được ghi lại bởi CloudTrail, sau đó tập trung vào một bucket S3 trung tâm mà chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Các dịch vụ bảo mật, danh tính và tuân thủ đa vùng\rXây dựng mạng toàn cầu\rĐối với các tài nguyên được triển khai trong các mạng ảo ở những Region khác nhau, Amazon Virtual Private Cloud (Amazon VPC) cho phép định tuyến riêng tư giữa các Region và tài khoản bằng VPC peering. Các tài nguyên này có thể giao tiếp với nhau bằng địa chỉ IP riêng mà không cần internet gateway, VPN, hoặc thiết bị mạng riêng biệt. Tính năng này hoạt động tốt cho các mạng nhỏ chỉ cần một vài kết nối peering. Tuy nhiên, định tuyến bắc cầu (transitive routing) không được hỗ trợ, và khi số lượng VPC peering tăng lên, cấu trúc mạng dạng mesh có thể trở nên khó quản lý và khắc phục sự cố.\nAWS Transit Gateway giúp giảm bớt những khó khăn này bằng cách tạo một hub trung chuyển mạng, kết nối các VPC và mạng tại chỗ (on-premises). Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Region khác thông qua Transit Gateway inter-Region peering, để tạo ra một mạng riêng tư phân tán toàn cầu cho tài nguyên của bạn.\nXây dựng một cách định tuyến đáng tin cậy và tiết kiệm chi phí để đưa người dùng đến các ứng dụng internet phân tán đòi hỏi những bản ghi Domain Name System (DNS) có độ sẵn sàng cao và khả năng mở rộng tốt. Amazon Route 53 chính là dịch vụ làm được điều đó.\nRoute 53 có nhiều chính sách định tuyến khác nhau. Ví dụ, bạn có thể định tuyến một yêu cầu đến bản ghi có độ trễ mạng thấp nhất, hoặc đưa người dùng ở một vị trí địa lý cụ thể đến endpoint ứng dụng cục bộ. Đối với kịch bản khắc phục thảm họa (DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp một giải pháp failover toàn diện với mức phụ thuộc tối thiểu. Các routing policy, safety check, và readiness check của Route 53 ARC giúp bạn thực hiện failover qua nhiều Region, AZ, và môi trường on-premises một cách đáng tin cậy.\nAmazon CloudFront – mạng phân phối nội dung (CDN) – là một dịch vụ toàn cầu, được xây dựng trên hơn 300 điểm hiện diện (PoP) khắp thế giới. Các ứng dụng có nhiều origin khả dụng (ví dụ như nhiều Region) có thể dùng CloudFront origin failover để tự động chuyển hướng sang origin dự phòng khi origin chính gặp sự cố. Khả năng của CloudFront không chỉ dừng lại ở việc phân phát nội dung, mà còn có thể chạy tính toán ở edge. CloudFront Functions giúp dễ dàng chạy các đoạn mã JavaScript nhẹ, trong khi AWS Lambda@Edge cho phép bạn chạy các hàm Node.js và Python gần hơn với người dùng ứng dụng, từ đó cải thiện hiệu năng và giảm độ trễ. Việc đưa compute ra edge giúp giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nĐược xây dựng trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm truy cập duy nhất cho các ứng dụng hướng internet. Bạn có thể linh hoạt thêm hoặc xóa origin trong khi hệ thống vẫn tự động định tuyến lưu lượng đến endpoint khu vực khỏe mạnh gần nhất. Nếu phát hiện lỗi, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến một endpoint khả dụng chỉ trong vài giây, mà không cần thay đổi địa chỉ IP tĩnh.\nHình 2 minh họa việc sử dụng Route 53 latency-based routing policy để định tuyến người dùng đến endpoint nhanh nhất, CloudFront để phân phát nội dung tĩnh như video và hình ảnh, và Transit Gateway để tạo một mạng riêng toàn cầu, giúp các thiết bị của chúng tôi có thể giao tiếp an toàn trên nhiều Region.\nHình 2. Kết nối AWS VPC và phân phối nội dung\rXây dựng và quản lý lớp tính toán (compute layer)\rMặc dù Amazon Elastic Compute Cloud (Amazon EC2) và các Amazon Elastic Block Store (Amazon EBS) volume liên kết chỉ tồn tại trong một AZ, Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot EBS giữa các Region. Điều này giúp nâng cao chiến lược khắc phục thảm họa (DR) bằng cách cung cấp một lựa chọn sao lưu và khôi phục lạnh (cold backup-and-restore) đơn giản cho các volume EBS. Nếu bạn cần sao lưu nhiều hơn chỉ các EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ (sẽ được đề cập trong phần 2).\nMột EC2 instance được xây dựng dựa trên một Amazon Machine Image (AMI). AMI xác định cấu hình của instance như lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một image chuẩn mới, EC2 Image Builder giúp đơn giản hóa quá trình xây dựng, kiểm thử, và triển khai AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region bổ sung, loại bỏ việc phải sao chép thủ công AMI nguồn sang các Region đích.\nCác ứng dụng dựa trên microservice sử dụng container sẽ hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) có thể đảm bảo điều này diễn ra nhất quán trên nhiều Region bằng cách sao chép image riêng tư ở cấp độ registry. Một ECR private registry có thể được cấu hình cho cả cross-Region hoặc cross-account replication, để đảm bảo image của bạn luôn sẵn sàng ở các Region thứ cấp khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi tài nguyên được cấp phát ở đâu có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt vấn đề này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instance, VPC, subnet, security group, và volume trong tất cả các Region đang hoạt động.\nChúng tôi kết hợp các tính năng compute layer này trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép AMI chuẩn mới nhất của chúng tôi sang nhiều Region để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép nó sang nhiều Region bằng Data Lifecycle Manager.\nHình 3. Sao chép AMI và ảnh chụp nhanh EBS giữa các Vùng (Regions)\rĐưa tất cả lại với nhau\rỞ cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\rTóm tắt\rKhi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\n*** Sẵn sàng để bắt đầu? *** Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\n*** Bạn đang tìm thêm nội dung về kiến trúc? *** AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng",
    "description": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share",
    "tags": [],
    "title": "Blog 10",
    "uri": "/en/3-translated_blogs/blog_10/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Week 10 Worklog",
    "uri": "/en/1-worklog/1.10-week_10/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share\nNhiều dịch vụ AWS có các tính năng giúp bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể là một thách thức lớn.\nTrong loạt blog gồm 3 phần này, chúng tôi sẽ chọn lọc từ hơn 200 dịch vụ đó và tập trung vào những dịch vụ có tính năng cụ thể hỗ trợ bạn xây dựng ứng dụng đa vùng. Trong Phần 1, chúng ta sẽ xây dựng nền tảng với các dịch vụ bảo mật, mạng, và tính toán của AWS. Ở Phần 2, chúng ta sẽ bổ sung các chiến lược dữ liệu và sao chép. Cuối cùng, trong Phần 3, chúng ta sẽ tìm hiểu về lớp ứng dụng và quản lý. Khi đi qua từng phần, chúng ta sẽ dần xây dựng một ứng dụng mẫu để minh họa cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững điều cần cân nhắc trước khi bắt đầu\rCác AWS Region được xây dựng với nhiều Availability Zone (AZ) tách biệt và cách ly về mặt vật lý. Cách tiếp cận này cho phép bạn tạo ra các workload có độ sẵn sàng cao, tuân thủ nguyên tắc Well-Architected, trải rộng trên nhiều AZ để đạt được khả năng chịu lỗi tốt hơn. Điều này đáp ứng được mục tiêu khả dụng cho hầu hết các ứng dụng, nhưng vẫn có một số lý do chung khiến bạn có thể muốn mở rộng ra ngoài một Region duy nhất:\nMở rộng ra khán giả toàn cầu: khi ứng dụng phát triển và lượng người dùng trở nên phân tán về mặt địa lý, có thể sẽ cần giảm độ trễ cho các khu vực khác nhau trên thế giới.\nGiảm RPO (Recovery Point Objective) và RTO (Recovery Time Objective): như một phần của kế hoạch khắc phục thảm họa (Disaster Recovery – DR) đa vùng.\nLuật pháp và quy định địa phương: có thể có những yêu cầu nghiêm ngặt về lưu trú dữ liệu (data residency) và quyền riêng tư mà bạn buộc phải tuân thủ.\nNếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn nên cân nhắc tập trung vào các dịch vụ AWS có sẵn chức năng hỗ trợ. Với những ứng dụng hiện có, cần phải xem xét kỹ hơn để xác định kiến trúc nào có khả năng mở rộng nhất nhằm đáp ứng sự phát triển. Các phần tiếp theo sẽ xem xét những dịch vụ này, đồng thời nêu bật các trường hợp sử dụng và thực tiễn tốt nhất.\nQuản lý danh tính và truy cập trên nhiều Region\rXây dựng nền tảng bảo mật bắt đầu từ việc thiết lập các quy tắc xác thực (authentication) và phân quyền (authorization) phù hợp. Hệ thống xử lý các yêu cầu này phải có khả năng chịu lỗi cao để xác minh và cấp quyền nhanh chóng, đáng tin cậy. AWS Identity and Access Management (IAM) đáp ứng điều này bằng cách cung cấp một cơ chế đáng tin cậy để bạn quản lý quyền truy cập vào các dịch vụ và tài nguyên AWS. IAM có khả năng sẵn sàng trên nhiều Region một cách tự động, mà bạn không cần phải cấu hình gì thêm.\nĐể hỗ trợ quản lý người dùng Windows, thiết bị và ứng dụng trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory Enterprise Edition, dịch vụ này sẽ tự động sao chép dữ liệu thư mục giữa các Region. Điều này giúp giảm độ trễ khi tra cứu thư mục bằng cách sử dụng thư mục gần nhất, đồng thời tăng tính bền vững bằng cách trải rộng trên nhiều Region. Lưu ý rằng điều này cũng kéo theo “số phận chung” giữa các domain controller trong kiến trúc đa vùng, vì các thay đổi group policy sẽ được lan truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, luân chuyển và kiểm toán bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật bằng khóa của AWS Key Management Service (AWS KMS) và có thể sao chép các bí mật sang Region thứ cấp để đảm bảo ứng dụng có thể nhanh chóng lấy được bí mật từ Region gần nhất.\nMã hóa trên nhiều Region\rAWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ (data at rest) và được dùng rộng rãi cho việc mã hóa trên các dịch vụ AWS. Theo mặc định, các khóa chỉ giới hạn trong một Region. Những dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) cross-Region replication và Amazon Aurora Global Database (sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã bằng các khóa khác nhau ở từng Region.\nĐối với các phần khác trong ứng dụng đa vùng của bạn phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép cả key material và key ID sang Region thứ hai. Điều này loại bỏ nhu cầu giải mã rồi mã hóa lại dữ liệu với một khóa khác ở từng Region. Ví dụ, multi-Region keys có thể được dùng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng cho dữ liệu được lưu trữ trên nhiều Region.\nKiểm toán và khả năng quan sát trên nhiều Region\rMột thực tiễn tốt nhất là cấu hình AWS CloudTrail để lưu lại toàn bộ hoạt động AWS API liên quan trong tài khoản của bạn nhằm phục vụ mục đích kiểm toán. Khi bạn sử dụng nhiều Region hoặc nhiều tài khoản, các log CloudTrail này nên được tập hợp về một bucket Amazon S3 duy nhất để thuận tiện cho việc phân tích. Để ngăn chặn việc sử dụng sai mục đích, các log tập trung này cần được coi là dữ liệu nhạy cảm hơn, chỉ cấp quyền truy cập cho các hệ thống và nhân sự chủ chốt.\nĐể theo dõi các phát hiện từ AWS Security Hub, bạn có thể tổng hợp và liên kết các phát hiện từ nhiều vị trí về một Region duy nhất. Đây là cách đơn giản để tạo một cái nhìn tập trung về các phát hiện của Security Hub trên nhiều tài khoản và nhiều Region. Sau khi thiết lập, các phát hiện sẽ liên tục được đồng bộ giữa các Region để giúp bạn luôn nắm được kết quả toàn cầu trên một bảng điều khiển duy nhất.\nChúng tôi đã kết hợp những tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trong các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin đăng nhập cơ sở dữ liệu nhạy cảm. Dữ liệu của chúng tôi, di chuyển tự do giữa các Region, được mã hóa bằng KMS multi-Region keys, và toàn bộ hoạt động truy cập AWS API được ghi lại bởi CloudTrail, sau đó tập trung vào một bucket S3 trung tâm mà chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Các dịch vụ bảo mật, danh tính và tuân thủ đa vùng\rXây dựng mạng toàn cầu\rĐối với các tài nguyên được triển khai trong các mạng ảo ở những Region khác nhau, Amazon Virtual Private Cloud (Amazon VPC) cho phép định tuyến riêng tư giữa các Region và tài khoản bằng VPC peering. Các tài nguyên này có thể giao tiếp với nhau bằng địa chỉ IP riêng mà không cần internet gateway, VPN, hoặc thiết bị mạng riêng biệt. Tính năng này hoạt động tốt cho các mạng nhỏ chỉ cần một vài kết nối peering. Tuy nhiên, định tuyến bắc cầu (transitive routing) không được hỗ trợ, và khi số lượng VPC peering tăng lên, cấu trúc mạng dạng mesh có thể trở nên khó quản lý và khắc phục sự cố.\nAWS Transit Gateway giúp giảm bớt những khó khăn này bằng cách tạo một hub trung chuyển mạng, kết nối các VPC và mạng tại chỗ (on-premises). Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Region khác thông qua Transit Gateway inter-Region peering, để tạo ra một mạng riêng tư phân tán toàn cầu cho tài nguyên của bạn.\nXây dựng một cách định tuyến đáng tin cậy và tiết kiệm chi phí để đưa người dùng đến các ứng dụng internet phân tán đòi hỏi những bản ghi Domain Name System (DNS) có độ sẵn sàng cao và khả năng mở rộng tốt. Amazon Route 53 chính là dịch vụ làm được điều đó.\nRoute 53 có nhiều chính sách định tuyến khác nhau. Ví dụ, bạn có thể định tuyến một yêu cầu đến bản ghi có độ trễ mạng thấp nhất, hoặc đưa người dùng ở một vị trí địa lý cụ thể đến endpoint ứng dụng cục bộ. Đối với kịch bản khắc phục thảm họa (DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp một giải pháp failover toàn diện với mức phụ thuộc tối thiểu. Các routing policy, safety check, và readiness check của Route 53 ARC giúp bạn thực hiện failover qua nhiều Region, AZ, và môi trường on-premises một cách đáng tin cậy.\nAmazon CloudFront – mạng phân phối nội dung (CDN) – là một dịch vụ toàn cầu, được xây dựng trên hơn 300 điểm hiện diện (PoP) khắp thế giới. Các ứng dụng có nhiều origin khả dụng (ví dụ như nhiều Region) có thể dùng CloudFront origin failover để tự động chuyển hướng sang origin dự phòng khi origin chính gặp sự cố. Khả năng của CloudFront không chỉ dừng lại ở việc phân phát nội dung, mà còn có thể chạy tính toán ở edge. CloudFront Functions giúp dễ dàng chạy các đoạn mã JavaScript nhẹ, trong khi AWS Lambda@Edge cho phép bạn chạy các hàm Node.js và Python gần hơn với người dùng ứng dụng, từ đó cải thiện hiệu năng và giảm độ trễ. Việc đưa compute ra edge giúp giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nĐược xây dựng trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm truy cập duy nhất cho các ứng dụng hướng internet. Bạn có thể linh hoạt thêm hoặc xóa origin trong khi hệ thống vẫn tự động định tuyến lưu lượng đến endpoint khu vực khỏe mạnh gần nhất. Nếu phát hiện lỗi, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến một endpoint khả dụng chỉ trong vài giây, mà không cần thay đổi địa chỉ IP tĩnh.\nHình 2 minh họa việc sử dụng Route 53 latency-based routing policy để định tuyến người dùng đến endpoint nhanh nhất, CloudFront để phân phát nội dung tĩnh như video và hình ảnh, và Transit Gateway để tạo một mạng riêng toàn cầu, giúp các thiết bị của chúng tôi có thể giao tiếp an toàn trên nhiều Region.\nHình 2. Kết nối AWS VPC và phân phối nội dung\rXây dựng và quản lý lớp tính toán (compute layer)\rMặc dù Amazon Elastic Compute Cloud (Amazon EC2) và các Amazon Elastic Block Store (Amazon EBS) volume liên kết chỉ tồn tại trong một AZ, Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot EBS giữa các Region. Điều này giúp nâng cao chiến lược khắc phục thảm họa (DR) bằng cách cung cấp một lựa chọn sao lưu và khôi phục lạnh (cold backup-and-restore) đơn giản cho các volume EBS. Nếu bạn cần sao lưu nhiều hơn chỉ các EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ (sẽ được đề cập trong phần 2).\nMột EC2 instance được xây dựng dựa trên một Amazon Machine Image (AMI). AMI xác định cấu hình của instance như lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một image chuẩn mới, EC2 Image Builder giúp đơn giản hóa quá trình xây dựng, kiểm thử, và triển khai AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region bổ sung, loại bỏ việc phải sao chép thủ công AMI nguồn sang các Region đích.\nCác ứng dụng dựa trên microservice sử dụng container sẽ hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) có thể đảm bảo điều này diễn ra nhất quán trên nhiều Region bằng cách sao chép image riêng tư ở cấp độ registry. Một ECR private registry có thể được cấu hình cho cả cross-Region hoặc cross-account replication, để đảm bảo image của bạn luôn sẵn sàng ở các Region thứ cấp khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi tài nguyên được cấp phát ở đâu có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt vấn đề này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instance, VPC, subnet, security group, và volume trong tất cả các Region đang hoạt động.\nChúng tôi kết hợp các tính năng compute layer này trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép AMI chuẩn mới nhất của chúng tôi sang nhiều Region để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép nó sang nhiều Region bằng Data Lifecycle Manager.\nHình 3. Sao chép AMI và ảnh chụp nhanh EBS giữa các Vùng (Regions)\rĐưa tất cả lại với nhau\rỞ cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\rTóm tắt\rKhi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\n*** Sẵn sàng để bắt đầu? *** Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\n*** Bạn đang tìm thêm nội dung về kiến trúc? *** AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng",
    "description": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share",
    "tags": [],
    "title": "Blog 11",
    "uri": "/en/3-translated_blogs/blog_11/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Week 11 Worklog",
    "uri": "/en/1-worklog/1.11-week_11/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Translated Blogs",
    "content": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share\nNhiều dịch vụ AWS có các tính năng giúp bạn xây dựng và quản lý kiến trúc đa vùng (multi-Region), nhưng việc xác định những khả năng này trong hơn 200 dịch vụ có thể là một thách thức lớn.\nTrong loạt blog gồm 3 phần này, chúng tôi sẽ chọn lọc từ hơn 200 dịch vụ đó và tập trung vào những dịch vụ có tính năng cụ thể hỗ trợ bạn xây dựng ứng dụng đa vùng. Trong Phần 1, chúng ta sẽ xây dựng nền tảng với các dịch vụ bảo mật, mạng, và tính toán của AWS. Ở Phần 2, chúng ta sẽ bổ sung các chiến lược dữ liệu và sao chép. Cuối cùng, trong Phần 3, chúng ta sẽ tìm hiểu về lớp ứng dụng và quản lý. Khi đi qua từng phần, chúng ta sẽ dần xây dựng một ứng dụng mẫu để minh họa cách kết hợp các dịch vụ này nhằm tạo ra một ứng dụng đa vùng.\nNhững điều cần cân nhắc trước khi bắt đầu\rCác AWS Region được xây dựng với nhiều Availability Zone (AZ) tách biệt và cách ly về mặt vật lý. Cách tiếp cận này cho phép bạn tạo ra các workload có độ sẵn sàng cao, tuân thủ nguyên tắc Well-Architected, trải rộng trên nhiều AZ để đạt được khả năng chịu lỗi tốt hơn. Điều này đáp ứng được mục tiêu khả dụng cho hầu hết các ứng dụng, nhưng vẫn có một số lý do chung khiến bạn có thể muốn mở rộng ra ngoài một Region duy nhất:\nMở rộng ra khán giả toàn cầu: khi ứng dụng phát triển và lượng người dùng trở nên phân tán về mặt địa lý, có thể sẽ cần giảm độ trễ cho các khu vực khác nhau trên thế giới.\nGiảm RPO (Recovery Point Objective) và RTO (Recovery Time Objective): như một phần của kế hoạch khắc phục thảm họa (Disaster Recovery – DR) đa vùng.\nLuật pháp và quy định địa phương: có thể có những yêu cầu nghiêm ngặt về lưu trú dữ liệu (data residency) và quyền riêng tư mà bạn buộc phải tuân thủ.\nNếu bạn đang xây dựng một ứng dụng đa vùng mới, bạn nên cân nhắc tập trung vào các dịch vụ AWS có sẵn chức năng hỗ trợ. Với những ứng dụng hiện có, cần phải xem xét kỹ hơn để xác định kiến trúc nào có khả năng mở rộng nhất nhằm đáp ứng sự phát triển. Các phần tiếp theo sẽ xem xét những dịch vụ này, đồng thời nêu bật các trường hợp sử dụng và thực tiễn tốt nhất.\nQuản lý danh tính và truy cập trên nhiều Region\rXây dựng nền tảng bảo mật bắt đầu từ việc thiết lập các quy tắc xác thực (authentication) và phân quyền (authorization) phù hợp. Hệ thống xử lý các yêu cầu này phải có khả năng chịu lỗi cao để xác minh và cấp quyền nhanh chóng, đáng tin cậy. AWS Identity and Access Management (IAM) đáp ứng điều này bằng cách cung cấp một cơ chế đáng tin cậy để bạn quản lý quyền truy cập vào các dịch vụ và tài nguyên AWS. IAM có khả năng sẵn sàng trên nhiều Region một cách tự động, mà bạn không cần phải cấu hình gì thêm.\nĐể hỗ trợ quản lý người dùng Windows, thiết bị và ứng dụng trong một mạng đa vùng, bạn có thể thiết lập AWS Directory Service for Microsoft Active Directory Enterprise Edition, dịch vụ này sẽ tự động sao chép dữ liệu thư mục giữa các Region. Điều này giúp giảm độ trễ khi tra cứu thư mục bằng cách sử dụng thư mục gần nhất, đồng thời tăng tính bền vững bằng cách trải rộng trên nhiều Region. Lưu ý rằng điều này cũng kéo theo “số phận chung” giữa các domain controller trong kiến trúc đa vùng, vì các thay đổi group policy sẽ được lan truyền đến tất cả các máy chủ thành viên.\nCác ứng dụng cần lưu trữ, luân chuyển và kiểm toán bí mật một cách an toàn, chẳng hạn như mật khẩu cơ sở dữ liệu, nên sử dụng AWS Secrets Manager. Dịch vụ này mã hóa các bí mật bằng khóa của AWS Key Management Service (AWS KMS) và có thể sao chép các bí mật sang Region thứ cấp để đảm bảo ứng dụng có thể nhanh chóng lấy được bí mật từ Region gần nhất.\nMã hóa trên nhiều Region\rAWS KMS có thể được sử dụng để mã hóa dữ liệu khi lưu trữ (data at rest) và được dùng rộng rãi cho việc mã hóa trên các dịch vụ AWS. Theo mặc định, các khóa chỉ giới hạn trong một Region. Những dịch vụ AWS như Amazon Simple Storage Service (Amazon S3) cross-Region replication và Amazon Aurora Global Database (sẽ được đề cập trong phần 2) giúp đơn giản hóa quá trình mã hóa và giải mã bằng các khóa khác nhau ở từng Region.\nĐối với các phần khác trong ứng dụng đa vùng của bạn phụ thuộc vào khóa KMS, bạn có thể thiết lập AWS KMS multi-Region keys để sao chép cả key material và key ID sang Region thứ hai. Điều này loại bỏ nhu cầu giải mã rồi mã hóa lại dữ liệu với một khóa khác ở từng Region. Ví dụ, multi-Region keys có thể được dùng để giảm độ phức tạp trong các hoạt động mã hóa của ứng dụng đa vùng cho dữ liệu được lưu trữ trên nhiều Region.\nKiểm toán và khả năng quan sát trên nhiều Region\rMột thực tiễn tốt nhất là cấu hình AWS CloudTrail để lưu lại toàn bộ hoạt động AWS API liên quan trong tài khoản của bạn nhằm phục vụ mục đích kiểm toán. Khi bạn sử dụng nhiều Region hoặc nhiều tài khoản, các log CloudTrail này nên được tập hợp về một bucket Amazon S3 duy nhất để thuận tiện cho việc phân tích. Để ngăn chặn việc sử dụng sai mục đích, các log tập trung này cần được coi là dữ liệu nhạy cảm hơn, chỉ cấp quyền truy cập cho các hệ thống và nhân sự chủ chốt.\nĐể theo dõi các phát hiện từ AWS Security Hub, bạn có thể tổng hợp và liên kết các phát hiện từ nhiều vị trí về một Region duy nhất. Đây là cách đơn giản để tạo một cái nhìn tập trung về các phát hiện của Security Hub trên nhiều tài khoản và nhiều Region. Sau khi thiết lập, các phát hiện sẽ liên tục được đồng bộ giữa các Region để giúp bạn luôn nắm được kết quả toàn cầu trên một bảng điều khiển duy nhất.\nChúng tôi đã kết hợp những tính năng này trong Hình 1. Chúng tôi sử dụng IAM để cấp quyền truy cập chi tiết đến các dịch vụ và tài nguyên AWS, Directory Service for Microsoft AD để xác thực người dùng trong các ứng dụng Microsoft, và Secrets Manager để lưu trữ thông tin đăng nhập cơ sở dữ liệu nhạy cảm. Dữ liệu của chúng tôi, di chuyển tự do giữa các Region, được mã hóa bằng KMS multi-Region keys, và toàn bộ hoạt động truy cập AWS API được ghi lại bởi CloudTrail, sau đó tập trung vào một bucket S3 trung tâm mà chỉ nhóm bảo mật của chúng tôi mới có quyền truy cập.\nHình 1. Các dịch vụ bảo mật, danh tính và tuân thủ đa vùng\rXây dựng mạng toàn cầu\rĐối với các tài nguyên được triển khai trong các mạng ảo ở những Region khác nhau, Amazon Virtual Private Cloud (Amazon VPC) cho phép định tuyến riêng tư giữa các Region và tài khoản bằng VPC peering. Các tài nguyên này có thể giao tiếp với nhau bằng địa chỉ IP riêng mà không cần internet gateway, VPN, hoặc thiết bị mạng riêng biệt. Tính năng này hoạt động tốt cho các mạng nhỏ chỉ cần một vài kết nối peering. Tuy nhiên, định tuyến bắc cầu (transitive routing) không được hỗ trợ, và khi số lượng VPC peering tăng lên, cấu trúc mạng dạng mesh có thể trở nên khó quản lý và khắc phục sự cố.\nAWS Transit Gateway giúp giảm bớt những khó khăn này bằng cách tạo một hub trung chuyển mạng, kết nối các VPC và mạng tại chỗ (on-premises). Khả năng định tuyến của Transit Gateway có thể mở rộng sang các Region khác thông qua Transit Gateway inter-Region peering, để tạo ra một mạng riêng tư phân tán toàn cầu cho tài nguyên của bạn.\nXây dựng một cách định tuyến đáng tin cậy và tiết kiệm chi phí để đưa người dùng đến các ứng dụng internet phân tán đòi hỏi những bản ghi Domain Name System (DNS) có độ sẵn sàng cao và khả năng mở rộng tốt. Amazon Route 53 chính là dịch vụ làm được điều đó.\nRoute 53 có nhiều chính sách định tuyến khác nhau. Ví dụ, bạn có thể định tuyến một yêu cầu đến bản ghi có độ trễ mạng thấp nhất, hoặc đưa người dùng ở một vị trí địa lý cụ thể đến endpoint ứng dụng cục bộ. Đối với kịch bản khắc phục thảm họa (DR), Route 53 Application Recovery Controller (Route 53 ARC) cung cấp một giải pháp failover toàn diện với mức phụ thuộc tối thiểu. Các routing policy, safety check, và readiness check của Route 53 ARC giúp bạn thực hiện failover qua nhiều Region, AZ, và môi trường on-premises một cách đáng tin cậy.\nAmazon CloudFront – mạng phân phối nội dung (CDN) – là một dịch vụ toàn cầu, được xây dựng trên hơn 300 điểm hiện diện (PoP) khắp thế giới. Các ứng dụng có nhiều origin khả dụng (ví dụ như nhiều Region) có thể dùng CloudFront origin failover để tự động chuyển hướng sang origin dự phòng khi origin chính gặp sự cố. Khả năng của CloudFront không chỉ dừng lại ở việc phân phát nội dung, mà còn có thể chạy tính toán ở edge. CloudFront Functions giúp dễ dàng chạy các đoạn mã JavaScript nhẹ, trong khi AWS Lambda@Edge cho phép bạn chạy các hàm Node.js và Python gần hơn với người dùng ứng dụng, từ đó cải thiện hiệu năng và giảm độ trễ. Việc đưa compute ra edge giúp giảm tải cho origin và mang lại phản hồi nhanh hơn cho người dùng toàn cầu.\nĐược xây dựng trên mạng lưới toàn cầu của AWS, AWS Global Accelerator cung cấp hai địa chỉ IP anycast tĩnh để làm điểm truy cập duy nhất cho các ứng dụng hướng internet. Bạn có thể linh hoạt thêm hoặc xóa origin trong khi hệ thống vẫn tự động định tuyến lưu lượng đến endpoint khu vực khỏe mạnh gần nhất. Nếu phát hiện lỗi, Global Accelerator sẽ tự động chuyển hướng lưu lượng đến một endpoint khả dụng chỉ trong vài giây, mà không cần thay đổi địa chỉ IP tĩnh.\nHình 2 minh họa việc sử dụng Route 53 latency-based routing policy để định tuyến người dùng đến endpoint nhanh nhất, CloudFront để phân phát nội dung tĩnh như video và hình ảnh, và Transit Gateway để tạo một mạng riêng toàn cầu, giúp các thiết bị của chúng tôi có thể giao tiếp an toàn trên nhiều Region.\nHình 2. Kết nối AWS VPC và phân phối nội dung\rXây dựng và quản lý lớp tính toán (compute layer)\rMặc dù Amazon Elastic Compute Cloud (Amazon EC2) và các Amazon Elastic Block Store (Amazon EBS) volume liên kết chỉ tồn tại trong một AZ, Amazon Data Lifecycle Manager có thể tự động hóa quá trình tạo và sao chép snapshot EBS giữa các Region. Điều này giúp nâng cao chiến lược khắc phục thảm họa (DR) bằng cách cung cấp một lựa chọn sao lưu và khôi phục lạnh (cold backup-and-restore) đơn giản cho các volume EBS. Nếu bạn cần sao lưu nhiều hơn chỉ các EBS volume, AWS Backup cung cấp một nơi tập trung để thực hiện việc này trên nhiều dịch vụ (sẽ được đề cập trong phần 2).\nMột EC2 instance được xây dựng dựa trên một Amazon Machine Image (AMI). AMI xác định cấu hình của instance như lưu trữ, quyền khởi chạy, và ánh xạ thiết bị. Khi cần tạo và phát hành một image chuẩn mới, EC2 Image Builder giúp đơn giản hóa quá trình xây dựng, kiểm thử, và triển khai AMI mới. Nó cũng hỗ trợ sao chép AMI sang các Region bổ sung, loại bỏ việc phải sao chép thủ công AMI nguồn sang các Region đích.\nCác ứng dụng dựa trên microservice sử dụng container sẽ hưởng lợi từ thời gian khởi động nhanh hơn. Amazon Elastic Container Registry (Amazon ECR) có thể đảm bảo điều này diễn ra nhất quán trên nhiều Region bằng cách sao chép image riêng tư ở cấp độ registry. Một ECR private registry có thể được cấu hình cho cả cross-Region hoặc cross-account replication, để đảm bảo image của bạn luôn sẵn sàng ở các Region thứ cấp khi cần.\nKhi kiến trúc mở rộng ra nhiều Region, việc theo dõi tài nguyên được cấp phát ở đâu có thể trở nên khó khăn. Amazon EC2 Global View giúp giảm bớt vấn đề này bằng cách cung cấp một bảng điều khiển tập trung, hiển thị các tài nguyên EC2 như instance, VPC, subnet, security group, và volume trong tất cả các Region đang hoạt động.\nChúng tôi kết hợp các tính năng compute layer này trong Hình 3 bằng cách sử dụng EC2 Image Builder để sao chép AMI chuẩn mới nhất của chúng tôi sang nhiều Region để triển khai. Chúng tôi cũng sao lưu mỗi EBS volume trong 3 ngày và sao chép nó sang nhiều Region bằng Data Lifecycle Manager.\nHình 3. Sao chép AMI và ảnh chụp nhanh EBS giữa các Vùng (Regions)\rĐưa tất cả lại với nhau\rỞ cuối mỗi phần của loạt bài blog này, chúng tôi sẽ xây dựng một ứng dụng mẫu dựa trên các dịch vụ đã đề cập. Điều này cho thấy cách bạn có thể kết hợp các dịch vụ để xây dựng một ứng dụng đa Vùng (multi-Region) với AWS. Chúng tôi không sử dụng tất cả dịch vụ được nhắc đến, chỉ chọn những dịch vụ phù hợp với trường hợp sử dụng.\nChúng tôi xây dựng ví dụ này để mở rộng đến phạm vi toàn cầu. Ứng dụng yêu cầu tính sẵn sàng cao giữa các Vùng, và ưu tiên hiệu năng hơn là tính nhất quán tuyệt đối. Chúng tôi đã chọn các dịch vụ sau (trong bài viết này) để đạt được mục tiêu:\nRoute 53 với chính sách định tuyến theo độ trễ (latency routing) để đưa người dùng đến vùng triển khai có độ trễ thấp nhất.\nCloudFront được thiết lập để phân phối nội dung tĩnh. Region 1 là nguồn gốc chính, nhưng chúng tôi đã cấu hình dự phòng nguồn gốc (origin failover) sang Region 2 trong trường hợp có sự cố.\nỨng dụng phụ thuộc vào một số API của bên thứ ba, vì vậy Secrets Manager với khả năng sao chép đa Vùng đã được thiết lập để lưu trữ thông tin khóa API nhạy cảm.\nCloudTrail logs được tập trung tại Region 1 để dễ dàng phân tích và kiểm toán.\nSecurity Hub tại Region 1 được chọn làm nơi tập hợp các phát hiện từ tất cả các Vùng.\nĐây là ứng dụng dựa trên container, chúng tôi dựa vào Amazon ECR replication tại mỗi vị trí để nhanh chóng tải về các image mới nhất tại chỗ.\nĐể liên lạc qua IP riêng giữa các Vùng, một Transit Gateway được thiết lập tại mỗi Vùng với kết nối liên Vùng. VPC peering cũng có thể hoạt động, nhưng vì dự kiến mở rộng ra nhiều Vùng hơn trong tương lai nên chúng tôi chọn Transit Gateway như giải pháp lâu dài.\nIAM được dùng để cấp quyền quản lý tài nguyên AWS.\nHình 4. Xây dựng ứng dụng với các dịch vụ AWS đa Vùng, sử dụng những dịch vụ đã đề cập trong Phần 1\rTóm tắt\rKhi thiết kế một ứng dụng đa Vùng (multi-Region), việc xây dựng một nền tảng vững chắc là vô cùng quan trọng. Nền tảng này sẽ giúp bạn phát triển ứng dụng nhanh chóng theo cách an toàn, đáng tin cậy và linh hoạt. Nhiều dịch vụ AWS đã tích hợp sẵn các tính năng hỗ trợ bạn xây dựng kiến trúc đa Vùng.\nTùy vào lý do mở rộng ra ngoài một Vùng duy nhất mà kiến trúc của bạn sẽ khác nhau. Trong bài viết này, chúng tôi đã đề cập đến các tính năng cụ thể của những dịch vụ AWS về bảo mật, mạng và tính toán (compute) — với khả năng tích hợp sẵn để giảm bớt khối lượng công việc nặng nề và lặp lại.\nTrong các bài viết tiếp theo, chúng tôi sẽ tiếp tục đề cập đến các dịch vụ về dữ liệu, ứng dụng và quản lý.\n*** Sẵn sàng để bắt đầu? *** Chúng tôi đã chọn một số AWS Solutions và AWS Blogs để hỗ trợ bạn!\n*** Bạn đang tìm thêm nội dung về kiến trúc? *** AWS Architecture Center cung cấp sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được kiểm chứng, những thực tiễn tốt nhất theo Well-Architected, các mẫu (patterns), biểu tượng và nhiều hơn nữa!\nLink bài viết gốc: (https://aws.amazon.com/blogs/architecture/creating-a-multi-region-application-with-aws-services-part-1-compute-and-security/)\nCác bài viết khác trong chuỗi này:\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 2: Dữ Liệu và Sao Chép\nXây dựng Ứng Dụng Đa Vùng với Các Dịch vụ AWS – Phần 3: Quản lý và Giám sát Ứng dụng",
    "description": "Xây dựng Ứng dụng Đa Vùng với Các Dịch vụ AWS – Phần 1: Tính toán, Mạng và Bảo mật\rTác giả: Joe Chapman và Sebastian Leks - 08/12/2021\nChủ đề: Amazon CloudFront, Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon Route 53, Amazon Simple Storage Service (S3), Amazon VPC, Architecture, AWS CloudTrail, AWS Global Accelerator, AWS Identity and Access Management (IAM), AWS Secrets Manager, AWS Security Hub, AWS Transit Gateway, AWS Well-Architected Permalink Share",
    "tags": [],
    "title": "Blog 12",
    "uri": "/en/3-translated_blogs/blog_12/index.html"
  },
  {
    "breadcrumb": "Internship Report \u003e Worklog",
    "content": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "description": "Chapter X\rSome Chapter title\rLorem Ipsum.",
    "tags": [],
    "title": "Week 12 Worklog",
    "uri": "/en/1-worklog/1.12-week_12/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/en/categories/index.html"
  },
  {
    "breadcrumb": "Internship Report",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/en/tags/index.html"
  }
]
