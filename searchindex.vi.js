var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "BÁO CÁO THỰC TẬP\rThông tin sinh viên:\rHọ và tên: Phan Cảnh Tuấn Đạt Số điện thoại: 0867829257\nEmail: pcanhtuandat@gmail.com\nTrường: Đại học Sài Gòn\nNgành: Công nghệ Thông tin\nLớp: DCT1226\nCông ty thực tập: Amazon Web Services Vietnam Co., Ltd.\nVị trí thực tập: Thực tập sinh FCJ Cloud\nThời gian thực tập: Từ 12/08/2025 đến 12/11/2025\nNội dung báo cáo\r1. Nhật ký công việc\n2. Đề xuất\n3. Bài viết dịch\n4. Sự kiện đã tham gia\n5. Hội thảo\n6. Tự đánh giá\n7. Chia sẻ và phản hồi",
    "description": "BÁO CÁO THỰC TẬP\rThông tin sinh viên:\rHọ và tên: Phan Cảnh Tuấn Đạt Số điện thoại: 0867829257\nEmail: pcanhtuandat@gmail.com\nTrường: Đại học Sài Gòn\nNgành: Công nghệ Thông tin\nLớp: DCT1226\nCông ty thực tập: Amazon Web Services Vietnam Co., Ltd.\nVị trí thực tập: Thực tập sinh FCJ Cloud\nThời gian thực tập: Từ 12/08/2025 đến 12/11/2025",
    "tags": [],
    "title": "Báo Cáo Thực Tập",
    "uri": "/vi/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\rTác giả: Gaurav Acharya, Jay Horne – 30/7/2025\nChủ đề: Advanced (300),Amazon FSx for NetApp ONTAP, Technical How-to\nNhững khách hàng on-premises đang sử dụng các mảng lưu trữ NetApp trong trung tâm dữ liệu của riêng họ thường áp dụng các quy tắc kiểm soát truy cập mạng và tường lửa nghiêm ngặt để bảo vệ dữ liệu của mình, tuy nhiên, kiểu bảo mật này thường đưa Network Address Translation (NAT) vào đường truyền giữa các mảng lưu trữ. ONTAP, dù được triển khai tại chỗ hay trên đám mây, đều yêu cầu các cụm lưu trữ được cấu hình với địa chỉ IP tĩnh, và giao thức SnapMirror™ được dùng để sao chép dữ liệu giữa chúng không hỗ trợ NAT. Điều này khiến việc kết nối giữa FSx for NetApp ONTAP và các phiên bản NetApp tại chỗ nằm sau tường lửa có NAT trở nên không thể. Người dùng trong những môi trường như vậy không thể dễ dàng di chuyển dữ liệu giữa hệ thống tại chỗ và Amazon FSx for NetApp ONTAP. Lý tưởng nhất, họ sẽ chọn kết nối thông qua SnapMirror qua internet công cộng, nhưng điều này là không thể trong cấu hình mặc định.\nNetApp SnapMirror™ là một tính năng thường được sử dụng cho khôi phục sau thảm họa (DR), sao lưu và sao chép dữ liệu trong hệ thống lưu trữ NetApp ONTAP, cả tại chỗ lẫn trên đám mây. Amazon FSx for NetApp ONTAP bao gồm SnapMirror như một phần của dịch vụ được quản lý toàn diện trong AWS. Tuy nhiên, vì NetApp SnapMirror không hỗ trợ NAT, và các địa chỉ IP này được xác minh đối chiếu với các hệ thống tệp được ghép cặp, nên cần triển khai một thiết bị NAT dựa trên Amazon Elastic Compute Cloud (Amazon EC2) với các Elastic IPs, để đảm bảo các tiêu đề lớp 3 (L3 headers) trùng khớp giữa mỗi hệ thống tệp và internet.\nTrong bài viết này, chúng tôi thảo luận về một kiến trúc và thiết kế nhằm hợp lý hóa và mở rộng quy mô cho thách thức di chuyển dữ liệu này trong môi trường AWS. Một lựa chọn khác có thể là thiết lập các đường hầm VPN riêng lẻ giữa trung tâm dữ liệu và AWS. Tuy nhiên, cách này sẽ rất khó quản lý khi mở rộng quy mô. Nguyên nhân khiến NetApp SnapMirror không hỗ trợ NAT là vì các siêu dữ liệu được trao đổi trong quá trình ghép cặp — chẳng hạn như các địa chỉ Logical Interface (LIF) — được xác minh đối chiếu với các hệ thống tệp đang được ghép cặp. Nếu chúng không khớp, kết nối sẽ thất bại. Từ thông tin này, ta có thể nói rằng NAT không phá vỡ SnapMirror, mà chính việc thay đổi địa chỉ IP mới là nguyên nhân. Vậy, nếu chúng ta có thể thực hiện NAT theo cách mà SnapMirror vẫn có thể xác minh các địa chỉ IP đó thì sao? Chúng ta chỉ cần đảm bảo rằng các tiêu đề lớp 3 (L3 Headers) trong các gói IP trùng khớp, và cách linh hoạt nhất để làm điều đó là sử dụng một lớp NAT thứ hai.\nTổng quan giải pháp\rĐể làm cho các headers lớp 3 (L3 headers) trùng khớp, chúng ta cần một thiết bị NAT nằm giữa mỗi hệ thống tệp và internet. Thiết bị này có thể là một máy chủ Linux, tường lửa, bộ định tuyến hoặc bất kỳ thiết bị nào trong trung tâm dữ liệu có khả năng thực hiện NAT và đáp ứng đủ băng thông cần thiết. Trong bài viết này, chúng tôi triển khai một phiên bản EC2 được tối ưu hóa cho mạng dựa trên kiến trúc Graviton trong Amazon Virtual Private Cloud (Amazon VPC). Chúng tôi sử dụng phiên bản c7gn.medium, có thông lượng mạng đạt 3.5 GB/s. Kích thước phiên bản này có thể được mở rộng tùy theo nhu cầu băng thông của bạn. Vì yêu cầu về CPU và bộ nhớ là rất nhỏ, lựa chọn này mang lại hiệu suất mạng tốt nhất so với chi phí tại thời điểm viết bài.\nĐiều kiện tiên quyết\rCác điều kiện sau là cần thiết để hoàn thành giải pháp này:\nMột thiết bị NAT mà SnapMirror có thể đi qua tại mỗi hệ thống tệp (filer). Một subnet riêng biệt cho từng hệ thống tệp. Hình 1. Sơ đồ kiến trúc AWS minh họa hai VPC được kết nối thông qua một cổng NAT tự quản lý dựa trên Linux.\rVí dụ\rCấu hình ví dụ được triển khai từ AWS đến AWS để đảm bảo tính trực quan, như minh họa trong hình trên, nhưng một trong hai phía đều có thể được thay thế bằng bất kỳ thiết bị NAT nào thực hiện chức năng tương tự. Tương tự, ví dụ này dựa trên hệ thống tệp FSx for ONTAP trong một Single-Availability Zone (AZ). Nếu bạn đang sử dụng hệ thống tệp Multi-AZ, chúng tôi khuyến nghị triển khai hai phiên bản Amazon EC2 trong từng Availability Zone (AZ) của hệ thống tệp Multi-AZ và định tuyến lưu lượng thông qua phiên bản nằm trong từng AZ đó.\nEIPs\rTrong ví dụ của chúng tôi, chúng tôi sử dụng một địa chỉ EIP cho mỗi giao diện liên cụm (inter-cluster interface) của FSx for ONTAP. Ban đầu, chúng tôi sẽ yêu cầu bốn địa chỉ EIP chưa được gán cho bất kỳ tài nguyên nào. Việc phân bổ cổng có thể cho phép sử dụng ít địa chỉ IP hơn, nhưng điều đó nằm ngoài phạm vi của ví dụ này.\nSecurity Group\rViệc gán trực tiếp các địa chỉ EIP cho Amazon EC2 mà không có bất kỳ giới hạn nào là một thực hành bảo mật kém. Do đó, chúng tôi đã tạo một nhóm bảo mật (security group) trong mỗi VPC và cho phép toàn bộ lưu lượng đến từ bốn địa chỉ EIP này. Về mặt kỹ thuật, chỉ cần mở các cổng TCP 10000, 11104, 11105 và ICMP là đủ, nhưng bộ định tuyến của chúng tôi chỉ chuyển tiếp các cổng này. Phần sau đây tóm tắt cấu hình mạng mẫu cho hai triển khai FSx for ONTAP. Các địa chỉ IP được liệt kê chỉ nhằm mục đích minh họa — các giá trị thực tế trong môi trường của bạn sẽ khác tùy theo cấu hình mạng. Side A: VPC: 10.1.0.0/16FSx ONTAP inter-cluster endpoint 1: 10.1.0.137FSx ONTAP inter-cluster endpoint 2: 10.1.0.125inter_1 EIP: 18.190.143.162inter_2 EIP: 3.128.12.212 Side B: VPC: 10.2.0.0/16FSx ONTAP inter-cluster endpoint 1: 10.2.0.155FSx ONTAP inter-cluster endpoint 2: 10.2.0.110inter_1 EIP: 3.135.134.67inter_2 EIP: 3.146.166.253\nAmazon EC2\rĐể xử lý các NAT, hãy triển khai một phiên bản EC2 chạy RedHat 9, kèm theo nhóm bảo mật mà chúng ta đã tạo trước đó. RedHat không phải là bắt buộc, và bất kỳ bản phân phối Linux nào hỗ trợ nftables đều có thể hoạt động cho bài thực hành này. Đối với mỗi phiên bản EC2, chúng ta cần gắn kết hai địa chỉ EIP trong số các địa chỉ đã tạo. Mỗi địa chỉ EIP này phải được liên kết với một địa chỉ IP riêng (private IP) khác nhau. Cuối cùng, chúng ta phải tắt kiểm tra nguồn/đích (source/destination check) trên giao diện mạng. Điều này cho phép Amazon EC2 gửi các gói tin có địa chỉ IP nguồn không thuộc quyền sở hữu của nó.\nHình 2. Ảnh chụp màn hình của trang tổng quan mạng (network summary page) của một phiên bản EC2, trong đó địa chỉ IP riêng (private IP) và địa chỉ IP công cộng (public IP) được tô sáng (highlighted).\rnftables\rTrên mỗi phiên bản Linux này, chúng ta cần thêm một số quy tắc nftables để xử lý các kết nối. Điều này tạo ra một ánh xạ 1:1 giữa các giao diện của cụm FSx for ONTAP và một địa chỉ EIP. Đối với môi trường ví dụ của chúng ta, cấu hình nftables cho Side B sẽ như sau.\nTùy chọn 1: Chỉnh sửa trực tiếp tệp nftables.\rtable ip nat { chain prerouting { type nat hook prerouting priority dstnat; policy accept; tcp dport 11104 ip daddr 10.1.0.135 dnat to 10.1.0.125 tcp dport 11105 ip daddr 10.1.0.135 dnat to 10.1.0.125 tcp dport 10000 ip daddr 10.1.0.135 dnat to 10.1.0.125 icmp type { echo-reply, echo-request } ip daddr 10.1.0.135 dnat to 10.1.0.125 tcp dport 11104 ip daddr 10.1.0.123 dnat to 10.1.0.137 tcp dport 11105 ip daddr 10.1.0.123 dnat to 10.1.0.137 tcp dport 10000 ip daddr 10.1.0.123 dnat to 10.1.0.137 icmp type { echo-reply, echo-request } ip daddr 10.1.0.123 dnat to 10.1.0.137 ip daddr 10.2.0.110 dnat to 3.146.166.253 icmp type { echo-reply, echo-request } ip daddr 10.2.0.110 dnat to 3.146.166.253 ip daddr 10.2.0.155 dnat to 3.135.134.67 icmp type { echo-reply, echo-request } ip daddr 10.2.0.155 dnat to 3.135.134.67 } chain postrouting { type nat hook postrouting priority srcnat; policy accept; ip saddr 10.1.0.125 snat to 10.1.0.135 icmp type { echo-reply, echo-request } ip saddr 10.1.0.125 snat to 10.1.0.135 ip saddr 10.1.0.137 snat to 10.1.0.123 icmp type { echo-reply, echo-request } ip saddr 10.1.0.137 snat to 10.1.0.123 tcp dport 11104 ip saddr 3.146.166.253 snat to 10.2.0.110 tcp dport 11105 ip saddr 3.146.166.253 snat to 10.2.0.110 tcp dport 10000 ip saddr 3.146.166.253 snat to 10.2.0.110 icmp type { echo-reply, echo-request } ip saddr 3.146.166.253 snat to 10.2.0.110 tcp dport 11104 ip saddr 3.135.134.67 snat to 10.2.0.155 tcp dport 11105 ip saddr 3.135.134.67 snat to 10.2.0.155 tcp dport 10000 ip saddr 3.135.134.67 snat to 10.2.0.155 icmp type { echo-reply, echo-request } ip saddr 3.135.134.67 snat to 10.2.0.155 } }\rTùy chọn 2: Script cấu hình nftables CLI\r#!/bin/bash # Install nftables and enable ip forwarding in the kernel dnf install -y echo 1 \u003e /proc/sys/net/ipv4/ip_forward echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf # Create the pre-routing and postrouting chains in nftables. nft add table ip nat nft -- add chain ip nat prerouting { type nat hook prerouting priority -100 \\; } nft add chain ip nat postrouting { type nat hook postrouting priority 100 \\; } # Unmap any incoming packets from the internet to the local fsx interface # Map packets destined to 3.146.166.253(10.2.0.70) -\u003e 10.2.0.110 nft add rule ip nat prerouting tcp dport 11104 ip daddr 10.2.0.70 dnat to 10.2.0.110 nft add rule ip nat prerouting tcp dport 11105 ip daddr 10.2.0.70 dnat to 10.2.0.110 nft add rule ip nat prerouting tcp dport 10000 ip daddr 10.2.0.70 dnat to 10.2.0.110 nft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.2.0.70 dnat to 10.2.0.110 # Map packets destined to 3.135.134.67(10.2.0.186) -\u003e 10.2.0.155 nft add rule ip nat prerouting tcp dport 11104 ip daddr 10.2.0.186 dnat to 10.2.0.155 nft add rule ip nat prerouting tcp dport 11105 ip daddr 10.2.0.186 dnat to 10.2.0.155 nft add rule ip nat prerouting tcp dport 10000 ip daddr 10.2.0.186 dnat to 10.2.0.155 nft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.2.0.186 dnat to 10.2.0.155 # Map any outgoing packets from the local fsx interface to its respective public IP # 10.2.0.110 -\u003e 3.146.166.253(10.2.0.70) nft add rule ip nat postrouting ip saddr 10.2.0.110 snat to 10.2.0.70 nft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 10.2.0.110 snat to 10.2.0.70 # 10.2.0.155 -\u003e 3.135.134.67(10.2.0.186) nft add rule ip nat postrouting ip saddr 10.2.0.155 snat to 10.2.0.186 nft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 10.2.0.155 snat to 10.2.0.186 # Unmap any incoming packets for the remote EIPs to the originating FSX internal IP # 3.128.12.212 -\u003e 10.1.0.125 nft add rule ip nat postrouting tcp dport 11104 ip saddr 3.128.12.212 snat to 10.1.0.125 nft add rule ip nat postrouting tcp dport 11105 ip saddr 3.128.12.212 snat to 10.1.0.125 nft add rule ip nat postrouting tcp dport 10000 ip saddr 3.128.12.212 snat to 10.1.0.125 nft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 3.128.12.212 snat to 10.1.0.125 # 18.190.143.162 -\u003e 10.1.0.137 nft add rule ip nat postrouting tcp dport 11104 ip saddr 18.190.143.162 snat to 10.1.0.137 nft add rule ip nat postrouting tcp dport 11105 ip saddr 18.190.143.162 snat to 10.1.0.137 nft add rule ip nat postrouting tcp dport 10000 ip saddr 18.190.143.162 snat to 10.1.0.137 nft add rule ip nat postrouting icmp type { echo-request, echo-reply } ip saddr 18.190.143.162 snat to 10.1.0.137 # Map any outgoing packets destined to a remote fsx interface to their respective public IP # 10.1.0.125 -\u003e 3.128.12.212 nft add rule ip nat prerouting ip daddr 10.1.0.125 dnat to 3.128.12.212 nft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.1.0.125 dnat to 3.128.12.212 # 10.1.0.137 -\u003e 18.190.143.162 nft add rule ip nat prerouting ip daddr 10.1.0.137 dnat to 18.190.143.162 nft add rule ip nat prerouting icmp type { echo-request, echo-reply } ip daddr 10.1.0.137 dnat to 18.190.143.162 # Persist the config nft list ruleset \u003e /etc/sysconfig/nftables.conf\rBảng định tuyến\rKhi cả hai bộ định tuyến đã được cấu hình, chúng ta cần đảm bảo rằng lưu lượng SnapMirror sẽ đi qua chúng. Để thực hiện điều này, chúng ta cập nhật bảng định tuyến (route table) được liên kết với FSx for ONTAP để gửi lưu lượng từ VPC ở xa đến giao diện mạng (network interface) của các phiên bản EC2. Ví dụ, ở Side B, chúng ta thêm một tuyến (route) trỏ 10.1.0.0/16 đến Elastic Network Interface của phiên bản EC2. Ở Side A, chúng ta sẽ làm ngược lại: trỏ 10.2.0.0/16 đến EC2 instance tương ứng.\nHình 3. Bảng định tuyến (Route table) được liên kết với FSx for ONTAP.\rFSx cho ONTAP security group\rLà bước thiết lập cuối cùng, chúng ta cần cho phép mạng VPC từ xa được kết nối đến các giao diện của FSx for ONTAP. Để làm điều này, chúng ta đã thêm dải địa chỉ 10.0.0.0/8 vào nhóm bảo mật (security group) trên cả hai phiên bản FSx for ONTAP.\nKết nối ngang hàng giữa các hệ thống tệp\rKhi các kết nối mạng đã được thiết lập, việc còn lại là kết nối ngang hàng (peer) giữa các hệ thống tệp FSx for ONTAP. Trước tiên, chúng ta đăng nhập vào Side A và bắt đầu yêu cầu peering.\nSau đó, chúng ta đăng nhập vào Side B và thực thi cùng một lệnh, nhưng không sử dụng tùy chọn generate passphrase và dùng các địa chỉ IP từ Side A. Thao tác này được thực hiện từ phía Side B của hệ thống tệp FSx for ONTAP.\nTừ đây, các SVM (Storage Virtual Machine) có thể được kết nối ngang hàng (peered) và một mối quan hệ SnapMirror có thể được tạo ra.\nDọn dẹp\rViệc chạy các phiên bản EC2 và hệ thống tệp FSx for ONTAP sẽ phát sinh chi phí. Hãy nhớ xóa và chấm dứt (terminate) các tài nguyên này nếu chúng không còn cần thiết. Để xóa một hệ thống tệp, hãy làm theo hướng dẫn trong tài liệu hướng dẫn người dùng FSx for NetApp ONTAP. Để chấm dứt các phiên bản EC2, hãy truy cập phần Terminate Your Instance trong tài liệu hướng dẫn người dùng Amazon EC2.\nLink bài viết gốc: (https://aws.amazon.com/blogs/storage/highly-scalable-solution-design-to-replicate-data-using-amazon-fsx-for-netapp-ontap-and-snapmirror/)",
    "description": "Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\rTác giả: Gaurav Acharya, Jay Horne – 30/7/2025\nChủ đề: Advanced (300),Amazon FSx for NetApp ONTAP, Technical How-to\nNhững khách hàng on-premises đang sử dụng các mảng lưu trữ NetApp trong trung tâm dữ liệu của riêng họ thường áp dụng các quy tắc kiểm soát truy cập mạng và tường lửa nghiêm ngặt để bảo vệ dữ liệu của mình, tuy nhiên, kiểu bảo mật này thường đưa Network Address Translation (NAT) vào đường truyền giữa các mảng lưu trữ. ONTAP, dù được triển khai tại chỗ hay trên đám mây, đều yêu cầu các cụm lưu trữ được cấu hình với địa chỉ IP tĩnh, và giao thức SnapMirror™ được dùng để sao chép dữ liệu giữa chúng không hỗ trợ NAT. Điều này khiến việc kết nối giữa FSx for NetApp ONTAP và các phiên bản NetApp tại chỗ nằm sau tường lửa có NAT trở nên không thể. Người dùng trong những môi trường như vậy không thể dễ dàng di chuyển dữ liệu giữa hệ thống tại chỗ và Amazon FSx for NetApp ONTAP. Lý tưởng nhất, họ sẽ chọn kết nối thông qua SnapMirror qua internet công cộng, nhưng điều này là không thể trong cấu hình mặc định.",
    "tags": [],
    "title": "Blog 1",
    "uri": "/vi/3-translated_blogs/blog_1/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Events Participated",
    "content": "Summary Report: “Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025”\rEvent Objectives\rProvide information about the Internship program FCAJ Introduce support \u0026 admin team Speakers\rMr. Nguyen Gia Hưng – Head of Solutions Architect - Viet Nam \u0026 Cambodia | Champion Authorized Instructor Mr. Nguyen Dong Thanh Hiep – Principal Cloud Engineer | AWS First Cloud Journey | AWS Community Builders Mr. Danh Hoang Hieu Nghi – AI Engineer at Renova Cloud | 2x AWS Certified | AWS First Cloud AI Journey Key Highlights\rIntroduce the FCAJ program\rThe history of the program The reasons for why this program was established The overall aim of the program The learning materials Speakers share their stories\rNetworking and discussions\rThe workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned\rKnow more about the overall view of the cloud industry How to study and work smartly in a fast pace world Be more determined with the career path Some event photos\rOverall, the event provided detailed information about the program as well as give me an opportunity to make friends with passionate peers.",
    "description": "Summary Report: “Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025”\rEvent Objectives\rProvide information about the Internship program FCAJ Introduce support \u0026 admin team Speakers\rMr. Nguyen Gia Hưng – Head of Solutions Architect - Viet Nam \u0026 Cambodia | Champion Authorized Instructor Mr. Nguyen Dong Thanh Hiep – Principal Cloud Engineer | AWS First Cloud Journey | AWS Community Builders Mr. Danh Hoang Hieu Nghi – AI Engineer at Renova Cloud | 2x AWS Certified | AWS First Cloud AI Journey Key Highlights\rIntroduce the FCAJ program\rThe history of the program The reasons for why this program was established The overall aim of the program The learning materials Speakers share their stories\rNetworking and discussions\rThe workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned\rKnow more about the overall view of the cloud industry How to study and work smartly in a fast pace world Be more determined with the career path Some event photos\rOverall, the event provided detailed information about the program as well as give me an opportunity to make friends with passionate peers.",
    "tags": [],
    "title": "Event 1",
    "uri": "/vi/4-events_participated/4.1-event-1/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow",
    "content": "Mô hình kiến trúc\rDomain: Route 53 (DNS) + ACM (SSL Certificate).\nCDN: CloudFront (Global Edge Network).\nStorage (Primary): S3 Singapore (ap-southeast-1).\nStorage (Failover): S3 N. Virginia (us-east-1).\nReplication: Tự động copy code từ Sing -\u003e Virginia.\nSecurity: OAC (Origin Access Control) - Private Bucket.\nMỤC LỤC\rPrerequisites\nS3 and Replication\nRoute 53 and ACM\nClouFront and Failover\nS3 Policy\nDNS Record\nDeploy and Test",
    "description": "Mô hình kiến trúc\rDomain: Route 53 (DNS) + ACM (SSL Certificate).\nCDN: CloudFront (Global Edge Network).\nStorage (Primary): S3 Singapore (ap-southeast-1).\nStorage (Failover): S3 N. Virginia (us-east-1).\nReplication: Tự động copy code từ Sing -\u003e Virginia.\nSecurity: OAC (Origin Access Control) - Private Bucket.\nMỤC LỤC\rPrerequisites",
    "tags": [],
    "title": "Frontend Deploy",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Week 1: Làm quen với Hugo và các dịch vụ cơ AWS cơ bản\nWeek 2: Doing task A…\nWeek 3: Doing task B…\nWeek 4: Doing task C…\nWeek 5: Doing task D…\nWeek 6: Doing task E…\nWeek 7: Doing task F…\nWeek 8: Doing task G…\nWeek 9: Doing task H…\nWeek 10: Doing task I…\nWeek 11: Doing task J…\nWeek 12: Doing task K…",
    "description": "Week 1: Làm quen với Hugo và các dịch vụ cơ AWS cơ bản\nWeek 2: Doing task A…\nWeek 3: Doing task B…\nWeek 4: Doing task C…\nWeek 5: Doing task D…\nWeek 6: Doing task E…\nWeek 7: Doing task F…\nWeek 8: Doing task G…\nWeek 9: Doing task H…\nWeek 10: Doing task I…\nWeek 11: Doing task J…\nWeek 12: Doing task K…",
    "tags": [],
    "title": "Nhật ký công việc",
    "uri": "/vi/1-worklog/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Mục tiêu tuần 1\rTìm hiểu các quy định Kết nối với các thành viên FCJ khác Hiểu và thực hành các dịch vụ AWS cơ bản Các công việc cần thực hiện trong tuần\rNgày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Làm quen với các thành viên FCJ 09/09/2025 09/09/2025 - Đọc và ghi chú các quy định của đơn vị thực tập - Học và thực hành tạo website tĩnh bằng Hugo - Tạo tài khoản AWS. Thực hành tạo Nhóm người dùng và Người dùng (IAM user) 2 - Học và thực hành tạo Ngân sách (Mẫu \u0026 Tùy chỉnh: Chi phí, Sử dụng, Gói tiết kiệm, Đặt chỗ) 10/09/2025 10/09/2025 - Cập nhật nhật ký công việc 3 - Tìm hiểu về các gói hỗ trợ, các loại yêu cầu hỗ trợ, cách tạo yêu cầu hỗ trợ 11/09/2025 11/09/2025 4 - Dịch một bài blog 12/09/2025 12/09/2025 - Cập nhật nhật ký công việc (UI, blog đã dịch) 5 - Học lý thuyết về VPC (Subnet, Route Table, Internet Gateway, NAT Gateway) 13/09/2025 13/09/2025 - Cập nhật nhật ký công việc 6 - Dịch bài blog thứ 2 14/09/2025 14/09/2025 - Cập nhật nhật ký công việc",
    "description": "Mục tiêu tuần 1\rTìm hiểu các quy định Kết nối với các thành viên FCJ khác Hiểu và thực hành các dịch vụ AWS cơ bản Các công việc cần thực hiện trong tuần\rNgày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Làm quen với các thành viên FCJ 09/09/2025 09/09/2025 - Đọc và ghi chú các quy định của đơn vị thực tập - Học và thực hành tạo website tĩnh bằng Hugo - Tạo tài khoản AWS. Thực hành tạo Nhóm người dùng và Người dùng (IAM user) 2 - Học và thực hành tạo Ngân sách (Mẫu \u0026 Tùy chỉnh: Chi phí, Sử dụng, Gói tiết kiệm, Đặt chỗ) 10/09/2025 10/09/2025 - Cập nhật nhật ký công việc 3 - Tìm hiểu về các gói hỗ trợ, các loại yêu cầu hỗ trợ, cách tạo yêu cầu hỗ trợ 11/09/2025 11/09/2025 4 - Dịch một bài blog 12/09/2025 12/09/2025 - Cập nhật nhật ký công việc (UI, blog đã dịch) 5 - Học lý thuyết về VPC (Subnet, Route Table, Internet Gateway, NAT Gateway) 13/09/2025 13/09/2025 - Cập nhật nhật ký công việc 6 - Dịch bài blog thứ 2 14/09/2025 14/09/2025 - Cập nhật nhật ký công việc",
    "tags": [],
    "title": "Nhật ký công việc Tuần 1",
    "uri": "/vi/1-worklog/1.1-week_1/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "Cần chuẩn bị:\rTên miền đã đăng ký (VD: sgutodolist.com)\nĐối với tài khoản Free Tier thì không được hỗ trợ tính năng đăng ký tên miền của dịch vụ Route 53, vì vậy project này đăng ký tên miền một nhà cung cấp tên miền khác và host tên miền ở Route Tài khoản AWS\nReactJS project đã build thành công\nAWS CLI (optional, để test)\nNode.js \u0026 npm đã cài đặt\nKiến thức cần có:\rHiểu cơ bản về S3, CloudFront, Route 53\nBiết sử dụng AWS Console\nBiết build ReactJS project",
    "description": "Cần chuẩn bị:\rTên miền đã đăng ký (VD: sgutodolist.com)\nĐối với tài khoản Free Tier thì không được hỗ trợ tính năng đăng ký tên miền của dịch vụ Route 53, vì vậy project này đăng ký tên miền một nhà cung cấp tên miền khác và host tên miền ở Route Tài khoản AWS",
    "tags": [],
    "title": "Prerequisites",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.1-prerequisites/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop",
    "content": "Giới Thiệu Dự Án\rSGU TodoList là một ứng dụng quản lý công việc (Task Management) được xây dựng theo kiến trúc Microservices trên nền tảng AWS Cloud. Dự án được thiết kế ban đầu với mục tiêu triển khai theo mô hình Multi-Region SaaS để đảm bảo high availability và disaster recovery. Tuy nhiên, do giới hạn về ngân sách và tài khoản AWS Free Tier, nhóm đã tối ưu hóa kiến trúc về Single-Region Deployment với cơ chế Cross-Region Failover cho frontend.",
    "description": "Giới Thiệu Dự Án\rSGU TodoList là một ứng dụng quản lý công việc (Task Management) được xây dựng theo kiến trúc Microservices trên nền tảng AWS Cloud. Dự án được thiết kế ban đầu với mục tiêu triển khai theo mô hình Multi-Region SaaS để đảm bảo high availability và disaster recovery. Tuy nhiên, do giới hạn về ngân sách và tài khoản AWS Free Tier, nhóm đã tối ưu hóa kiến trúc về Single-Region Deployment với cơ chế Cross-Region Failover cho frontend.",
    "tags": [],
    "title": "Workshop Overview",
    "uri": "/vi/5-workshop/5.1-workshop_overview/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\rTác giả: Gabe Kafity – 29/7/2025\nChủ đề: Best Practices, High Performance Computing\nTrong ngành hàng không vũ trụ đang phát triển nhanh chóng ngày nay, khả năng đổi mới nhanh chóng và hiệu quả không chỉ là một lợi thế – mà đó là một điều cần thiết. Khi các công nghệ như UAVs (Unmanned Aerial Vehicle) tự hành, các chùm vệ tinh (satellite constellations), tên lửa tái sử dụng và thực tế tăng cường/ảo (augmented/virtual reality) tiến bộ, khả năng đổi mới nhanh chóng mang lại cho các tổ chức hàng không vũ trụ lợi thế cạnh tranh. High Performance Computing (HPC) rất quan trọng đối với đổi mới hàng không vũ trụ và đã trở thành nền tảng của sự tiến bộ trong ngành hàng không vũ trụ. Bất kể quy mô, tuổi đời hay tốc độ lặp lại (iteration speed) của một tổ chức, Amazon Web Services (AWS) luôn sẵn sàng giúp thúc đẩy các sứ mệnh hàng không vũ trụ của họ tiến lên.\nTrong bài đăng này, chúng ta sẽ khám phá lý do tại sao, cách thức và những gì khách hàng hàng không vũ trụ thường làm với HPC trong AWS.\nHiện Trạng của HPC\rCơ sở hạ tầng HPC on-premises truyền thống thường đòi hỏi đầu tư vốn đáng kể và có thể mất hàng tháng, hoặc thậm chí hàng năm, để mua sắm và triển khai. Sau khi được triển khai, các cluster thường chạy ở mức hoặc gần 100% tỷ lệ sử dụng (utilization). Tỷ lệ sử dụng cơ sở hạ tầng cao này dẫn đến thời gian chờ đợi lâu cho các HPC job mới đi vào hàng đợi (queue). Các nhà khoa học nghiên cứu và kỹ sư phải chờ đợi (thường là hàng tuần) để job của họ đi qua hàng đợi và chạy, trước khi họ có thể phân tích kết quả và lặp lại sự đổi mới của họ. Ngoài ra, chu kỳ khấu hao (depreciation cycle) của cơ sở hạ tầng HPC on-premises thường là 5-8 năm. Điều này có nghĩa là trong khi cơ sở hạ tầng HPC ngày càng tốt hơn mỗi năm, các cluster on-premises bị mắc kẹt với việc sử dụng cơ sở hạ tầng kém hiệu quả hơn cho đến khi đến lúc làm mới phần cứng (hardware refresh), lúc đó chu kỳ cơ sở hạ tầng cũ (legacy infrastructure) lại bắt đầu lại.\nNgược lại, AWS cung cấp cho các tổ chức quyền truy cập tức thì vào các tài nguyên tính toán gần như không giới hạn, cho phép họ tăng tốc đổi mới trong khi kiểm soát chi phí. Việc triển khai diễn ra chỉ trong vài phút và khách hàng chỉ trả tiền cho những gì họ sử dụng. Tận dụng các khả năng của cloud, các HPC cluster trong AWS mở rộng quy mô (scale out) để đáp ứng nhu cầu, xử lý job thành công và thu hẹp quy mô (scale back in) khi hàng đợi trống. Tính đàn hồi (elasticity) này làm giảm đáng kể thời gian chờ đợi cho các kỹ sư và nhà khoa học, trong khi chỉ phải trả tiền cho các tài nguyên khi chúng đang chạy. Ngoài ra, AWS cải thiện cơ sở hạ tầng HPC của chúng tôi với tốc độ của phần mềm. Điều này có nghĩa là thay vì chờ đợi nhiều năm để làm mới phần cứng nhằm hiện đại hóa cơ sở hạ tầng HPC, khách hàng của AWS liên tục có quyền truy cập vào cơ sở hạ tầng HPC mới nhất, hiệu suất/giá cả tốt nhất từ Amazon và các đối tác của chúng tôi (NVIDIA, Intel, AMD, v.v.).\nHình 1: Đối lập giữa việc chạy các HPC workload on-premises (trái) so với trong AWS (phải). Bên trái bị giới hạn bởi dung lượng trung tâm dữ liệu cố định, nơi thời gian chờ đợi trong hàng đợi dài và cơ sở hạ tầng nhanh chóng trở nên lỗi thời. Bên phải có dung lượng đàn hồi (elastic capacity) có thể mở rộng theo nhu cầu, rút ngắn thời gian chờ đợi trong hàng đợi trong khi chạy trên cơ sở hạ tầng hiện đại hơn.\rCác HPC Workload Chủ chốt trong Hàng không Vũ trụ\rComputational Fluid Dynamics (CFD)\nCác tổ chức hàng không vũ trụ đang tận dụng các tài nguyên tính toán mạnh mẽ của AWS để thực hiện các mô phỏng CFD phức tạp nhằm tối ưu hóa thiết kế máy bay và phân tích hệ thống đẩy (propulsion systems). Sử dụng các dịch vụ HPC của AWS, các tổ chức có thể chạy các workload như Siemens STAR-CCM+, Ansys Fluent hoặc mô phỏng OpenFOAM với hàng nghìn core, giảm thời gian mô phỏng từ hàng tuần xuống hàng giờ.\nPhân tích Cấu trúc (Structural Analysis)\nNhu cầu của thiết kế hàng không vũ trụ hiện đại đòi hỏi phân tích cấu trúc chuyên sâu đối với những thứ như độ bền sản phẩm, độ rung và âm học (acoustics). Cho dù đó là thử nghiệm vật liệu composite mới hay thực hiện phân tích độ mỏi (fatigue analysis) trên các thành phần quan trọng, khả năng HPC của AWS cho phép khách hàng chạy nhiều mô phỏng đồng thời bằng cách sử dụng phần mềm như Dassault Systèmes Abaqus hoặc Simcenter Nastran, đẩy nhanh quá trình lặp lại thiết kế (design iteration process).\nLập kế hoạch Sứ mệnh và Hoạt động Không gian (Mission Planning and Space Operations)\nKhi ngành hàng không vũ trụ phát triển và đổi mới, các tổ chức đang sử dụng các dịch vụ HPC của AWS để mô phỏng cơ học quỹ đạo phức tạp (orbital mechanics), tối ưu hóa việc triển khai các chùm vệ tinh (satellite constellation deployments) và quản lý các cửa sổ phóng (launch windows) một cách hiệu quả. Các mô phỏng này đòi hỏi số lượng lớn các compute cluster, cơ sở hạ tầng mạng và lưu trữ thế hệ tiếp theo, có thể dễ dàng triển khai và tự động mở rộng quy mô dựa trên nhu cầu.\nHình 2: Ví dụ về các hình ảnh trực quan (visualizations) của các HPC workload dành cho khách hàng hàng không vũ trụ.\rMỗi loại workload mô phỏng đều có các yêu cầu riêng về loại cơ sở hạ tầng mà nó chạy trên. AWS cho phép khách hàng tối ưu hóa cấu hình cơ sở hạ tầng, cluster và hàng đợi của họ để chạy hiệu quả workload mô hình hóa hoặc mô phỏng đang thực hiện.\nBộ Công Cụ HPC của AWS\rHigh performance computing đòi hỏi cơ sở hạ tầng hiệu quả ở mọi lớp của stack. Điều này bao gồm các công cụ tính toán (compute), lưu trữ (storage), mạng (networking) và điều phối (orchestration) cho phép các tổ chức hàng không vũ trụ đổi mới nhanh chóng. Trong phần này, chúng ta sẽ xem xét một số công cụ mà khách hàng hàng không vũ trụ sử dụng trên AWS cho các HPC workload.\nAmazon Elastic Compute Cloud (Amazon EC2) cung cấp nền tảng tính toán rộng nhất và sâu nhất, với hơn 850 instance. Amazon EC2 có nhiều loại instance type hiệu suất cao được tối ưu hóa cho Accelerated Computing và HPC. AWS Nitro System được giới thiệu vào năm 2017 và được xây dựng dựa trên sự kết hợp giữa phần cứng, phần mềm và firmware được xây dựng có mục đích. Nó cung cấp cơ sở hạ tầng ảo hóa cơ bản cho các EC2 instance. Theo truyền thống, các hypervisor bảo vệ phần cứng vật lý và BIOS, ảo hóa CPU, lưu trữ, mạng và cung cấp một bộ khả năng quản lý phong phú. Với Nitro System, chúng tôi tách rời các chức năng đó, chuyển chúng sang phần cứng và phần mềm chuyên dụng, đồng thời giảm chi phí bằng cách cung cấp thực tế tất cả các tài nguyên của một server cho các instance của bạn. Điều này làm giảm thiểu chi phí ảo hóa (virtualization overhead).\nHình 3: Nitro System làm giảm thiểu chi phí hypervisor overhead để các instance của khách hàng có thể chạy ở mức ~100% dung lượng bare metal. Vùng màu nhạt hơn cho thấy các hoạt động kỹ thuật mà Nitro đảm nhiệm, trong khi vùng màu đậm hơn cho thấy các instance của khách hàng chạy trên Nitro.\rDịch vụ được quản lý (managed service) mới nhất của AWS giúp đơn giản hóa HPC trên AWS là AWS Parallel Computing Service (AWS PCS). AWS PCS giúp khách hàng dễ dàng chạy và mở rộng quy mô các HPC workload cũng như xây dựng các mô hình khoa học và kỹ thuật trên AWS bằng cách sử dụng Slurm làm trình quản lý workload. Dịch vụ được quản lý này cho phép bạn xây dựng các HPC cluster hoàn chỉnh tích hợp các tài nguyên tính toán (compute), lưu trữ (storage), mạng (networking) và hình ảnh trực quan (visualization), và mở rộng quy mô liền mạch từ 0 đến hàng nghìn instance. Thay vào đó, khách hàng có thể sử dụng AWS ParallelCluster, đây là một công cụ quản lý cluster mã nguồn mở (open-source), giàu tính năng, giúp dễ dàng cấu hình, triển khai và quản lý các HPC cluster trên AWS. Công cụ này được sử dụng thông qua các mẫu cơ sở hạ tầng dưới dạng mã (infrastructure as code templates), và có giao diện đồ họa dựa trên web tùy chọn. AWS ParallelCluster không phải là một dịch vụ được quản lý (managed service) và do đó yêu cầu khách hàng phải tự triển khai.\nAWS Batch giúp bạn chạy các batch computing workload trên AWS Cloud. Batch computing là một cách phổ biến để các nhà phát triển, nhà khoa học và kỹ sư truy cập vào một lượng lớn tài nguyên tính toán. AWS Batch loại bỏ công việc nặng nhọc không tạo ra sự khác biệt trong việc cấu hình và quản lý cơ sở hạ tầng cần thiết, giống như phần mềm batch computing truyền thống. Dịch vụ này có thể cấp phát tài nguyên hiệu quả để phản hồi các job đã gửi nhằm loại bỏ các hạn chế về dung lượng (capacity constraints), giảm chi phí tính toán và cung cấp kết quả nhanh chóng.\nCho đến nay, chúng ta đã thảo luận về các tài nguyên tính toán và công cụ điều phối (orchestration tooling) cho phép các HPC workload chạy trên AWS. Có những thành phần khác quan trọng đối với cơ sở hạ tầng HPC, chẳng hạn như mạng kết nối các compute node và lưu trữ hiệu suất cao (high-performance storage). Trước tiên, hãy xem xét về mạng.\nElastic Fabric Adapter (EFA) là một giao diện mạng cho các Amazon EC2 instance cho phép khách hàng chạy các ứng dụng đòi hỏi mức độ giao tiếp giữa các node (inter-node communications) cao trên quy mô lớn trên AWS. Giao diện phần cứng bỏ qua hệ điều hành (OS bypass hardware interface) được xây dựng tùy chỉnh của nó giúp tăng cường hiệu suất giao tiếp giữa các instance (inter-instance communications), điều này rất quan trọng để mở rộng quy mô các HPC workload có độ trễ thấp (low latency).\nHình 4: Cho thấy network infrastructure stack của EFA, trực quan hóa cách kernel được bỏ qua để tăng tốc hiệu suất.\rAWS cung cấp nhiều dịch vụ lưu trữ, chẳng hạn như Amazon Simple Storage Service (Amazon S3), Amazon Elastic Block Storage (Amazon EBS), cùng nhiều dịch vụ khác. Tất cả các dịch vụ lưu trữ này có thể được sử dụng khi xây dựng các HPC cluster trong AWS. Tuy nhiên, nhiều HPC workload được hưởng lợi rất nhiều từ bộ lưu trữ chuyên biệt, chẳng hạn như Lustre – một hệ thống tệp phân tán, song song, mã nguồn mở được thiết kế cho HPC và lưu trữ dữ liệu quy mô lớn. Amazon đã giải quyết nhu cầu này cho các HPC và AI/ML workload bằng cách cung cấp Amazon FSx for Lustre.\nAmazon FSx for Lustre là dịch vụ lưu trữ chia sẻ được quản lý hoàn toàn (fully managed shared storage service), được xây dựng trên hệ thống tệp song song, hiệu suất cao phổ biến nhất thế giới. Nó cho phép khách hàng tăng tốc các compute workload với bộ lưu trữ chia sẻ cung cấp độ trễ dưới mili giây (sub-millisecond latencies), thông lượng (throughput) lên đến hàng trăm GB/s, và hàng triệu IOPS, tất cả đều được quản lý hoàn toàn và có thể triển khai trong vài phút, mà không gặp khó khăn trong việc thiết lập và quản trị.\nMột Ngày của một HPC Job trên AWS\rGiờ đây chúng ta đã hiểu rõ hơn về các trường hợp sử dụng HPC và các dịch vụ mà khách hàng hàng không vũ trụ đang tận dụng trên AWS, hãy tổng hợp tất cả lại thành một quy trình làm việc (workflow) chức năng. Sơ đồ dưới đây minh họa một khách hàng đang chạy các HPC workload trong môi trường hybrid cloud của họ, giữa trung tâm dữ liệu on-premises và AWS. Người dùng cuối từ bên trong ranh giới mạng của khách hàng kết nối với Login Nodes thông qua SSH. Từ Login Nodes, các HPC job được gửi đi và thêm vào hàng đợi job. Điều này kích hoạt việc phân bổ các compute node, nơi các EC2 instance được mở rộng quy mô để đáp ứng nhu cầu hàng đợi và chạy các job. Các EC2 này có khả năng kết nối với các AWS services, chạy cho đến khi HPC job hoàn thành, và sau đó tự động thu hẹp quy mô trở lại (scale back down).\nHình 5: Ví dụ về quy trình làm việc triển khai các HPC job tận dụng AWS Parallel Computing Service.\rChúng ta đã đề cập đến một số trường hợp sử dụng, dịch vụ và quy trình làm việc mà khách hàng hàng không vũ trụ tận dụng trên AWS. Bước hợp lý tiếp theo là nghe từ chính khách hàng\nCác Câu Chuyện Thành Công trong Hàng không Vũ trụ từ Thực tế\rHypersonix Launch Systems đã giảm 92% thời gian CFD simulation pipeline của họ, từ 3 tháng xuống còn 1 tuần, bằng cách di chuyển sang AWS. Họ đã chạy các STAR-CCM+ workload on-premises, trong một HPC cluster bị sử dụng quá mức và lỗi thời. Thời gian chờ đợi trong hàng đợi kéo dài khiến các nhà nghiên cứu và kỹ sư của họ thường xuyên phải ngồi không. AWS đã trả lại thời gian cho các đội ngũ kỹ thuật này, để họ có thể đổi mới và đưa sản phẩm ra thị trường nhanh hơn. “Tôi tin rằng chúng tôi có thể nổi bật so với các công ty lớn hơn vì chúng tôi có khả năng và tài nguyên cloud mà chúng tôi cần trên AWS.”, Tiến sĩ Stephen Hall, Trưởng phòng Mô phỏng Cấu trúc Nhiệt CFD Tiên tiến tại Hypersonix Launch Systems, cho biết.\nBoom Supersonic sử dụng AWS để tăng tốc thiết kế và xây dựng máy bay siêu thanh của họ. Họ có thể chạy hàng nghìn mô phỏng tiên tiến đồng thời trên AWS, dẫn đến năng suất tăng ước tính gấp 6 lần so với môi trường on-prem của họ. Boom đã sử dụng hơn 53 triệu compute hours trên AWS để hoàn thành máy bay chở khách Overture của họ. “AWS, nhà cung cấp cloud hàng đầu thế giới, sẽ giúp chúng tôi liên tục tinh chỉnh các thiết kế của mình.”, Blake Scholl, Người sáng lập và CEO của Boom Supersonic, cho biết.\nĐể biết thêm thông tin về các câu chuyện thành công của khách hàng, vui lòng truy cập: (https://aws.amazon.com/solutions/case-studies/)\nKết Luận\rHPC dựa trên Cloud đang cách mạng hóa cách các tổ chức hàng không vũ trụ đổi mới. AWS cung cấp khả năng mở rộng (scalability), hiệu suất và bảo mật cần thiết cho các HPC workload hàng không vũ trụ khắt khe nhất. Khi ngành công nghiệp tiếp tục phát triển, cam kết của chúng tôi trong việc hỗ trợ đổi mới hàng không vũ trụ vẫn mạnh mẽ hơn bao giờ hết.\nLink bài viết gốc: (https://aws.amazon.com/blogs/hpc/accelerating-aerospace-innovation-high-performance-computing-hpc-on-amazon-web-services-aws/)",
    "description": "Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\rTác giả: Gabe Kafity – 29/7/2025\nChủ đề: Best Practices, High Performance Computing\nTrong ngành hàng không vũ trụ đang phát triển nhanh chóng ngày nay, khả năng đổi mới nhanh chóng và hiệu quả không chỉ là một lợi thế – mà đó là một điều cần thiết. Khi các công nghệ như UAVs (Unmanned Aerial Vehicle) tự hành, các chùm vệ tinh (satellite constellations), tên lửa tái sử dụng và thực tế tăng cường/ảo (augmented/virtual reality) tiến bộ, khả năng đổi mới nhanh chóng mang lại cho các tổ chức hàng không vũ trụ lợi thế cạnh tranh. High Performance Computing (HPC) rất quan trọng đối với đổi mới hàng không vũ trụ và đã trở thành nền tảng của sự tiến bộ trong ngành hàng không vũ trụ. Bất kể quy mô, tuổi đời hay tốc độ lặp lại (iteration speed) của một tổ chức, Amazon Web Services (AWS) luôn sẵn sàng giúp thúc đẩy các sứ mệnh hàng không vũ trụ của họ tiến lên.",
    "tags": [],
    "title": "Blog 2",
    "uri": "/vi/3-translated_blogs/blog_2/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Events Participated",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Event 2",
    "uri": "/vi/4-events_participated/4.2-event-2/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop",
    "content": "HI THIS IS WORKSHOP OVERVIEW",
    "description": "HI THIS IS WORKSHOP OVERVIEW",
    "tags": [],
    "title": "Prerequisite",
    "uri": "/vi/5-workshop/5.2-prerequisite/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Multi-Region SaaS Task Management Platform\rA Global AWS Solution for Low-Latency, Resilient Collaboration\r1. Executive Summary\rThe Multi-Region SaaS Task Management Platform is designed to deliver a Trello/Asana-like experience with low latency, high availability, and regional scalability across Asia-Pacific.\nBuilt with Spring Boot microservices on EC2 Auto Scaling Groups and RDS MySQL Multi-Region setup, the platform ensures real-time collaboration, task/board management, and cross-region resilience.\nBy leveraging AWS global infrastructure, the system provides:\nLow-latency access through RDS Read Replicas and regional compute High availability via multi-AZ deployment and cross-region failover Global content delivery using S3 Multi-Region Access Points and CloudFront Cost-optimized architecture suitable for Free Tier constraints The result is a platform where users in Southeast Asia and Australia collaborate seamlessly — even during regional outages — while maintaining operational efficiency and cost predictability.\n2. Problem Statement\r2.1. What’s the Problem?\rTraditional SaaS task management platforms typically operate within a single AWS region, which can lead to several limitations:\nHigh Latency: Users located far from the primary region experience slow response times and poor user experience Single Point of Failure: Regional outages can cause complete service disruption Limited Scalability: Geographic expansion requires significant infrastructure changes Poor Disaster Recovery: No automated failover mechanisms for business continuity 2.2. The Solution\rThis project introduces a multi-region architecture using AWS global services.\nKey highlights:\nRDS MySQL with Cross-Region Read Replicas – Primary writer in Singapore (ap-southeast-1) with read replica in Sydney (ap-southeast-2) EC2 Auto Scaling Groups per region for scalable, resilient compute Route 53 latency-based routing for intelligent traffic distribution to the nearest region S3 Multi-Region Access Points + Cross-Region Replication (CRR) for global file delivery Regional caching with ElastiCache Redis for session management and hot data Application Load Balancers for high availability and health checks This architecture achieves resilience, performance, and scalability while optimizing for cost-effectiveness within AWS Free Tier constraints.\n2.3. Benefits and ROI\rReduced latency for users across Southeast Asia and Australia (20-30ms between regions) High availability with multi-AZ deployment and automated failover Cost-efficient design optimized for Free Tier and small-scale production Scalable foundation ready for enterprise growth and additional regions Business continuity with cross-region disaster recovery capabilities 3. Solution Architecture\rFigure 1. Architecture solution\r3.1. Architecture Overview\rPrimary Region: ap-southeast-1 (Singapore)\nRDS MySQL Writer (db.t3.micro) with Multi-AZ EC2 Auto Scaling Group (t3.micro instances) ElastiCache Redis (t3.micro) for session caching Application Load Balancer S3 bucket for primary storage VPC with public/private subnets, NAT Gateway, Internet Gateway Secondary Region: ap-southeast-2 (Sydney)\nRDS Read Replica (db.t3.micro) EC2 Auto Scaling Group (t3.micro instances) ElastiCache Redis (t3.micro) for session caching Application Load Balancer S3 bucket (replica via CRR) VPC with public/private subnets, NAT Gateway, Internet Gateway Global Services:\nRoute 53 for DNS and latency-based routing S3 Multi-Region Access Points CloudFront CDN for static asset delivery API Gateway (optional) for API management 3.2. Microservices Architecture\rThe platform consists of the following Spring Boot microservices:\nAuth Service - User authentication, JWT token management Board Service - Board creation, management, permissions Task Service - Task CRUD operations, assignments, status updates Notification Service - Real-time notifications, event handling User Service - User profile management, preferences Each service is:\nContainerized using Docker Deployed on EC2 instances via Auto Scaling Groups Load-balanced via Application Load Balancer Connected to RDS MySQL (writes to primary, reads from local replica) Caching frequently accessed data in ElastiCache Redis 3.3. AWS Services Used\rCategory Services Purpose Compute EC2 Auto Scaling Groups Scalable microservices hosting across regions Database Amazon RDS (MySQL/PostgreSQL) Relational database with Multi-AZ and Read Replicas Caching ElastiCache Redis Session management \u0026 hot data caching per region Storage Amazon S3 + Multi-Region Access Points Object storage with cross-region replication Networking VPC, Internet Gateway, NAT Gateway, ALB Global DNS routing and API management DNS \u0026 Routing Amazon Route 53, API Gateway Build, deploy, and replicate container images Security Security Groups, IAM Network security and access control Observability CloudWatch Logging, metrics, monitoring \u0026 alarms 4. Service Roles Overview\rAWS Service Role in Architecture Route 53 DNS routing users to nearest region based on latency with health check failover API Gateway API management layer with throttling, request validation and regional endpoints VPC Isolated virtual network (10.0.0.0/16 for ap-southeast-1, 10.1.0.0/16 for ap-southeast-2) Public Subnet Hosts Application Load Balancer with internet access via Internet Gateway Private Subnet Hosts EC2 instances, RDS, and ElastiCache without direct internet access Internet Gateway Enables public subnet resources (ALB) to communicate with the internet NAT Gateway Allows private subnet resources (EC2, RDS) to access internet securely for updates Application Load Balancer Distributes incoming traffic across EC2 instances with health checks and SSL termination EC2 Auto Scaling Groups Automatically scales Spring Boot microservices (t3.micro) based on CPU/traffic demand ElastiCache for Redis In-memory caching for sessions, API responses, and frequently accessed data per region Amazon RDS Primary database writer in Singapore with async read replica in Sydney S3 Buckets Object storage for user files, attachments, and static assets per region S3 Multi-Region Access Points Unified global endpoint for accessing S3 objects with automatic routing to nearest region S3 Cross-Region Replication Automatically replicates objects from Singapore S3 bucket to Sydney for redundancy Security Groups Stateful firewall rules controlling inbound/outbound traffic for EC2, RDS, ALB, ElastiCache IAM Roles Secure service-to-service authentication without hardcoded credentials CloudWatch Centralized monitoring, logging, custom metrics, dashboards and alarms 5. Service Flow\r5.1. User Request Flow\rRead Operations (90% of traffic):\nUser in Singapore accesses app.taskmanager.com Route 53 resolves to ap-southeast-1 (Singapore) based on latency CloudFront serves static assets (CSS, JS, images) from edge location API request → ALB (ap-southeast-1) → EC2 Auto Scaling Group Spring Boot service checks ElastiCache Redis for cached data Cache HIT → Return immediately (latency \u003c 5ms) Cache MISS → Query RDS MySQL Writer (local read, latency 5-10ms) Response returned to user User in Sydney/Australia:\nRoute 53 resolves to ap-southeast-2 (Sydney) based on latency CloudFront serves static assets from Sydney edge location API request → ALB (ap-southeast-2) → EC2 Auto Scaling Group Spring Boot service checks local ElastiCache Redis Cache HIT → Return immediately Cache MISS → Query RDS Read Replica (local read, latency 5-10ms) Response returned to user Write Operations (10% of traffic):\nUser in Singapore:\nWrite request → ALB (ap-southeast-1) → EC2 → RDS Writer Data committed to primary database (latency 10-20ms) Async replication to Sydney Read Replica (5-30 seconds lag) ElastiCache invalidated/updated in both regions via pub/sub Success response to user User in Sydney:\nWrite request → ALB (ap-southeast-2) → EC2 Spring Boot forwards write to ap-southeast-1 RDS Writer Cross-region write (latency 50-100ms, acceptable for writes) Async replication back to Sydney Read Replica Cache invalidation via EventBridge + Lambda Success response to user 5.2. Developer CI/CD Flow\rDevelopment \u0026 Deployment Workflow:\nDeveloper commits code to Git repository Build Spring Boot application (JAR or Docker image) Upload artifacts to S3 bucket in ap-southeast-1 S3 Cross-Region Replication automatically copies to ap-southeast-2 Update EC2 Auto Scaling Group launch template with new AMI/image Perform rolling deployment: Launch new EC2 instances with updated code ALB performs health checks Gradually shift traffic from old to new instances Terminate old instances after successful deployment CloudWatch monitors deployment metrics and application health Rollback mechanism: Keep previous version in S3 for quick revert Note: CI/CD services like CodePipeline can be added later for full automation. For initial implementation, focus on manual deployment process.\n5.3. Data \u0026 HA/DR Flow\rData Replication Strategy:\nData Type Replication Method Latency Purpose Transactional Data RDS async replication 5-30 seconds User data, boards, tasks, comments Session Data ElastiCache Redis (per region) N/A (regional) User sessions, temporary auth tokens Static Assets S3 Cross-Region Replication Minutes Images, attachments, frontend files Application Code S3 CRR for artifacts Minutes Spring Boot JARs, Docker images Failover Scenarios:\nScenario 1: EC2 Instance Failure\nALB health check detects unhealthy EC2 instance ALB stops routing traffic to failed instance Auto Scaling Group launches replacement instance New instance passes health check and receives traffic Duration: 2-3 minutes | Impact: None (other instances handle load)\nScenario 2: Availability Zone Failure\nAll EC2 instances in one AZ fail ALB routes all traffic to healthy AZ (if Multi-AZ configured) Auto Scaling Group launches replacement capacity RDS Multi-AZ automatically fails over to standby (if configured) Duration: 5-10 minutes | Impact: Possible brief latency spike\nScenario 3: Regional Failure (Singapore)\nRoute 53 health checks detect region failure DNS failover automatically routes to ap-southeast-2 (Sydney) Manual RDS promotion: Promote Sydney Read Replica to Writer Update application configuration to point to new writer endpoint All traffic now served from Sydney region Duration: 15-30 minutes | Impact: Read-only mode until promotion\n6. Budget Estimation\rMinimal Setup (Recommended for Free Tier)\nAWS Service Cost (per month) Notes EC2 (t3.micro) $0.00 750 hours Free Tier, 4 instances × 12h/day = 720h/month RDS MySQL (db.t3.micro) $15.00 Writer only, 744 hours - exceeds Free Tier RDS Read Replica (db.t3.micro) $15.00 Sydney region, 744 hours S3 Standard $2.00 10 GB storage, cross-region replication Route 53 $1.00 1 hosted zone, basic queries CloudWatch $3.00 Basic metrics, 3-day log retention Data Transfer $5.00 Cross-region + internet egress VPC $0.00 VPC itself is free, NAT Gateway excluded Total $41.00 $492/year 7. Risk Assessment\rRisk Matrix\nRisk Impact Probability Priority RDS Replication Lag Medium Medium High Cross-Region Write Latency Medium High Medium NAT Gateway SPOF High Low Medium Cost Overruns High High Critical Free Tier Exhaustion Medium High High Manual Failover Complexity High Medium High Security Vulnerabilities High Medium Critical Data Consistency Issues High Low Medium Mitigation Strategies\nNetwork \u0026 Infrastructure:\nRDS Replication: Monitor replication lag with CloudWatch alarms (\u003c60s threshold). Implement application-level checks for critical writes. NAT Gateway: Deploy in multiple Availability Zones. Consider VPC endpoints for S3/CloudWatch to reduce NAT dependency. Auto Scaling: Pre-warm instances during known traffic peaks. Optimize Spring Boot startup time.\nCost Management:\nAWS Budgets: Set up alerts at 80%, 90%, 100% of monthly budget. Resource Scheduling: Stop non-essential resources during off-hours (weeknights, weekends). Right-sizing: Start small (t3.micro), scale up only when metrics justify it. Free Tier Monitoring: Track usage daily via Cost Explorer to stay within 750-hour limits.\nSecurity:\nSecurity Groups: Follow least-privilege principle, review quarterly. CloudTrail: Enable logging for all API calls, retain for 90 days minimum. Regular Audits: Weekly log reviews, monthly security assessments. Secrets Management: Use environment variables, rotate credentials regularly.\nContingency Plans Scenario 1: Regional Failure (Singapore)\nRoute 53 automatically redirects traffic to Sydney (5-10 minutes). Manually promote Sydney RDS Read Replica to Writer (10-20 minutes). Update application configuration to use new database endpoint. Total RTO: ~30 minutes, RPO: \u003c1 minute.\nScenario 2: Budget Exceeded\nIdentify cost spike via AWS Cost Explorer. Stop non-essential resources (dev/test EC2, unused snapshots). Reduce Auto Scaling maximum capacity temporarily. Optimize database queries to reduce RDS load. Consider reverting to manual deployment if CI/CD costs spike.\nScenario 3: Replication Lag \u003e5 Minutes\nTemporarily direct critical reads to primary database. Investigate cause (high write volume, network issues, large transactions). Implement aggressive caching to reduce database load. Consider scaling up RDS instance class if CPU-bound.\n8. Expected Outcomes\r8.1. Technical Improvements\rPerformance Gains:\nLatency Reduction: 80% improvement for Sydney users (from 200ms to 20ms for reads). Availability: 99.5%+ uptime vs 95% with single-region architecture. Scalability: Support 1,000+ concurrent users with current infrastructure. Response Time: \u003c50ms for cached data, \u003c100ms for database queries. Operational Capabilities:\nReal-time monitoring and alerting via CloudWatch dashboards. Automated scaling based on traffic patterns (2-10 instances per region). Cross-region disaster recovery with \u003c30 minute RTO. Cost-optimized infrastructure using AWS Free Tier benefits.\nArchitecture Foundation:\nMulti-region pattern replicable to other geographic areas (US, Europe). Microservices architecture ready for containerization (ECS/EKS). Scalable from 100 to 100,000+ users by upgrading instance sizes. Production-ready security with VPC isolation, encryption, IAM roles.\n8.2. Long-term Value\rSkills Development:\nHands-on experience with AWS core services (EC2, RDS, VPC, Route 53, S3). Understanding of multi-region architecture patterns and trade-offs. DevOps practices: Infrastructure as Code, CI/CD, monitoring, incident response. Cost optimization and cloud financial management expertise. Portfolio Project:\nDemonstrates cloud architecture expertise to potential employers. Shows end-to-end project delivery: planning, implementation, testing, documentation. Proves ability to work within constraints (budget, time, technology). Real-world production-ready system (not just tutorial follow-along). Business Foundation:\nReusable architecture for future SaaS applications. 1-year operational data for analytics and AI/ML projects. Foundation for enterprise features (SSO, audit logging, multi-tenancy). Potential monetization path (charge per user/tenant). Career Impact:\nAWS certification preparation (Cloud Practitioner, Solutions Architect, SysOps). Interview talking points for cloud/DevOps positions. Open-source contribution opportunity (template for multi-region apps). Foundation for technical blog posts and conference talks.",
    "description": "Multi-Region SaaS Task Management Platform\rA Global AWS Solution for Low-Latency, Resilient Collaboration\r1. Executive Summary\rThe Multi-Region SaaS Task Management Platform is designed to deliver a Trello/Asana-like experience with low latency, high availability, and regional scalability across Asia-Pacific.",
    "tags": [],
    "title": "Proposal",
    "uri": "/vi/2-proposal/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 1: CHUẨN BỊ STORAGE (S3 \u0026 REPLICATION)\rTạo nơi chứa resources, và một cơ chế tự động đồng bộ.\nBước 1.1: Tạo Bucket Chính (Singapore)\rVào S3 Console \u003e Chọn Region Asia Pacific (Singapore).\nClick Create bucket.\nBucket name: sgutodolist-frontend-sg.\nObject Ownership: ACLs disabled (Recommended).\nBlock Public Access: ✅ Block all public access (Chúng ta dùng OAC nên bucket phải kín).\nBucket Versioning: ✅ Enable (Bắt buộc để chạy Replication).\nDefault encryption: Server-side encryption with Amazon S3 managed keys (SSE-S3).\nClick Create bucket.\nBước 1.2: Tạo Bucket Phụ (Virginia)\rĐổi Region sang US East (N. Virginia).\nClick Create bucket.\nBucket name: sgutodolist-frontend-us.\nBlock Public Access: ✅ Block all public access.\nBucket Versioning: ✅ Enable.\nClick Create bucket.\nSau bước 1.1 \u0026 1.2, ta có 2 S3 buckets\nBước 1.3: Cấu hình Replication (Tự động Sync)\rQuay lại bucket Singapore (sgutodolist-frontend-sg).\nTab Management \u003e Mục Replication rules \u003e Click Create replication rule.\nRule name: SyncToUS.\nStatus: Enabled.\nSource bucket: Apply to all objects in the bucket.\nDestination: Choose a bucket in this account \u003e Chọn sgutodolist-frontend-us (nhớ chọn region us-east-1 để tìm thấy).\nIAM Role: Chọn Create new role (AWS tự tạo quyền cho bạn).\nClick Save. Khi hỏi “Replicate existing objects?”, chọn No (vì bucket đang rỗng).\n⬅ BƯỚC 1: Prerequisites BƯỚC 3: Route 53 and ACM ➡",
    "description": "GIAI ĐOẠN 1: CHUẨN BỊ STORAGE (S3 \u0026 REPLICATION)\rTạo nơi chứa resources, và một cơ chế tự động đồng bộ.\nBước 1.1: Tạo Bucket Chính (Singapore)\rVào S3 Console \u003e Chọn Region Asia Pacific (Singapore).",
    "tags": [],
    "title": "S3 and Replication",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.2-s3-and-replication/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 2 Objectives\rStudy Module 1: practicing VPC and EC2 Learn and practice configuring VPC, EC2, and related features Assign tasks for the team project Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Learn about VPC and its features 15/09/2025 15/09/2025 VPC, YouTube Lesson 2 Practice creating VPC, Subnets, and Internet Gateway 16/09/2025 16/09/2025 Create VPC, Create Subnets, Create Internet Gateway Update worklog 3 Practice creating Route Tables and Security Groups 17/09/2025 17/09/2025 Create Route Table, Create Security Groups Decide project scope and assign tasks 4 Learn about deploying Amazon EC2 instances 18/09/2025 18/09/2025 Deploying Amazon EC2 Instances, YouTube Tutorial Practice creating EC2 instances, checking connection, and creating NAT Gateway Create EC2 Instance, Check Connection, Create NAT Gateway 5 Practice using Reachability Analyzer 19/09/2025 19/09/2025 Reachability Analyzer Team meeting to decide project proposal Update worklog",
    "description": "Week 2 Objectives\rStudy Module 1: practicing VPC and EC2 Learn and practice configuring VPC, EC2, and related features Assign tasks for the team project Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Learn about VPC and its features 15/09/2025 15/09/2025 VPC, YouTube Lesson 2 Practice creating VPC, Subnets, and Internet Gateway 16/09/2025 16/09/2025 Create VPC, Create Subnets, Create Internet Gateway Update worklog 3 Practice creating Route Tables and Security Groups 17/09/2025 17/09/2025 Create Route Table, Create Security Groups Decide project scope and assign tasks 4 Learn about deploying Amazon EC2 instances 18/09/2025 18/09/2025 Deploying Amazon EC2 Instances, YouTube Tutorial Practice creating EC2 instances, checking connection, and creating NAT Gateway Create EC2 Instance, Check Connection, Create NAT Gateway 5 Practice using Reachability Analyzer 19/09/2025 19/09/2025 Reachability Analyzer Team meeting to decide project proposal Update worklog",
    "tags": [],
    "title": "Week 2 Worklog",
    "uri": "/vi/1-worklog/1.2-week_2/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Khắc phục sự cố môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\rTác giả: Adarsh Suresh, Chandu Utlapalli Ngày: 29/07/2025\nChủ đề: Amazon Q Developer, AWS Elastic Beanstalk, Technical How-to\nGiới thiệu\rCác nhà phát triển làm việc với AWS thường đánh giá cao AWS Elastic Beanstalk nhờ khả năng đơn giản hóa việc triển khai và vận hành các ứng dụng web mà không cần phải quản lý trực tiếp cơ sở hạ tầng nền tảng. Chỉ cần tải mã nguồn ứng dụng lên, Elastic Beanstalk sẽ tự động xử lý các tác vụ như cấp phát tài nguyên, cân bằng tải, tự động mở rộng và giám sát hệ thống, cho phép các nhóm tập trung hoàn toàn vào việc phát triển ứng dụng.\nVới sự ra mắt phiên bản CLI agent được tăng cường của Amazon Q Developer, cách tiếp cận trong quy trình phát triển và vận hành phần mềm đã có nhiều thay đổi tích cực. Amazon Q CLI không chỉ hỗ trợ viết code mà còn mở rộng sang các tác vụ vận hành, giúp các nhóm DevOps xử lý sự cố nhanh hơn và hiệu quả hơn.\nBên cạnh phát triển phần mềm, các nhà phát triển và đội ngũ DevOps thường dành nhiều thời gian cho các công việc vận hành như triển khai, kiểm thử ứng dụng trên nhiều môi trường và đặc biệt là khắc phục các lỗi liên quan đến triển khai hoặc tình trạng sức khỏe của hệ thống. Các tính năng dựa trên agent thông minh (agentic features) của Amazon Q CLI có thể đơn giản hóa đáng kể các tác vụ này bằng cách hỗ trợ phân tích, chẩn đoán và đề xuất giải pháp một cách tự động.\nKhi một môi trường Elastic Beanstalk hiển thị tình trạng sức khỏe suy giảm hoặc gặp lỗi triển khai, Amazon Q CLI có thể đóng vai trò như một trợ lý kỹ thuật. Thay vì phải truy cập nhiều trang trên AWS Console và phân tích logs thủ công, nhà phát triển chỉ cần mô tả vấn đề thông qua một cuộc trò chuyện. Q CLI có thể giúp:\nPhân tích logs của instance\nKiểm tra cấu hình môi trường\nXác định các cấu hình sai trong ứng dụng\nTrích xuất thông báo lỗi liên quan\nĐề xuất các bước khắc phục phù hợp dựa trên các mẫu lỗi phổ biến\nNgoài ra, khi xử lý các vấn đề về tình trạng sức khỏe, Q CLI có thể kiểm tra trạng thái môi trường, mức sử dụng tài nguyên và các sự kiện gần đây để xác định các nguyên nhân như:\nThiếu bộ nhớ (out-of-memory)\nVấn đề kết nối\nLỗi dependency\nLỗi lặp lại trong application logs\nMột trong những điểm mạnh nổi bật của Q CLI là khả năng kết nối thông tin giữa nhiều dịch vụ AWS. Ví dụ, nếu nguyên nhân sự cố đến từ cấu hình Amazon VPC hoặc quyền truy cập Amazon S3, Q CLI có thể phát hiện và đưa ra giải pháp tổng thể thay vì chỉ khắc phục từng phần riêng lẻ.\nNhờ đó, các tác vụ điều tra vốn có thể mất hàng giờ nay có thể được hoàn thành chỉ trong vài phút, giúp duy trì môi trường Elastic Beanstalk ổn định và giảm đáng kể thời gian downtime.\nHướng dẫn giải pháp\rĐiều kiện tiên quyết\rĐể có thể thực hiện các bước minh họa trong bài viết, bạn cần đáp ứng các yêu cầu sau:\n1. Một tài khoản AWS có quyền truy cập Elastic Beanstalk 2. Hiểu biết cơ bản về các khái niệm Elastic Beanstalk (applications, environments, deployments) 3. AWS CLI đã được cài đặt và cấu hình với các quyền phù hợp 4. Amazon Q Developer CLI đã được cài đặt và thiết lập 5. EB CLI đã được cài đặt (không bắt buộc) 6. Ít nhất một môi trường Elastic Beanstalk web server đã được tạo sẵn để thực hành khắc phục sự cố\nLưu ý: Các kịch bản trong bài viết được kiểm tra với Amazon Q Developer CLI sử dụng Pro tier, do tier này cung cấp giới hạn yêu cầu cao hơn. Tuy nhiên, Pro tier không bắt buộc để hiểu và áp dụng các ví dụ được trình bày.\nKhắc phục sự cố tình trạng môi trường\rXét một môi trường Elastic Beanstalk chạy Node.js 22 trên Amazon Linux 2023, trong đó một phiên bản ứng dụng mới vừa được triển khai. Sau khi triển khai, môi trường hiển thị tình trạng sức khỏe ở mức Warning, với thông báo sự kiện sau:\n100% of requests failing with HTTP 5xx errors Hình 1. Bảng điều khiển Elastic Beanstalk hiển thị trạng thái sức khỏe ở mức Cảnh báo\rThông báo này có thể xuất phát từ nhiều nguyên nhân khác nhau, bao gồm: Lỗi trong ứng dụng Node.js Cấu hình reverse proxy không chính xác Sự cố sử dụng tài nguyên Các vấn đề khác liên quan đến hạ tầng hoặc dependency Để điều tra thêm, chúng ta có thể sử dụng Amazon Q CLI. Bắt đầu một cuộc trò chuyện mới bằng cách chạy: ```bash q chat\rSau đó đặt câu hỏi:\nWhy is my beanstalk environment nodejs-app in us-east-1 unhealthy?\rCheck the logs if required, and recommend steps to resolve the issue.\nAmazon Q CLI sẽ tự động thu thập thông tin liên quan từ logs, cấu hình môi trường và các sự kiện gần đây, sau đó đưa ra phân tích cũng như đề xuất các bước khắc phục cụ thể.\nQ CLI phân tích logs và đề xuất hướng khắc phục sự cố môi trường Elastic Beanstalk",
    "description": "Khắc phục sự cố môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\rTác giả: Adarsh Suresh, Chandu Utlapalli Ngày: 29/07/2025\nChủ đề: Amazon Q Developer, AWS Elastic Beanstalk, Technical How-to\nGiới thiệu\rCác nhà phát triển làm việc với AWS thường đánh giá cao AWS Elastic Beanstalk nhờ khả năng đơn giản hóa việc triển khai và vận hành các ứng dụng web mà không cần phải quản lý trực tiếp cơ sở hạ tầng nền tảng. Chỉ cần tải mã nguồn ứng dụng lên, Elastic Beanstalk sẽ tự động xử lý các tác vụ như cấp phát tài nguyên, cân bằng tải, tự động mở rộng và giám sát hệ thống, cho phép các nhóm tập trung hoàn toàn vào việc phát triển ứng dụng.",
    "tags": [],
    "title": "Blog 3",
    "uri": "/vi/3-translated_blogs/blog_3/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop",
    "content": "Content\r5.3.1. Frontend Deploy\n5.3.2. Backend Deploy",
    "description": "Content\r5.3.1. Frontend Deploy\n5.3.2. Backend Deploy",
    "tags": [],
    "title": "Deploy Flow",
    "uri": "/vi/5-workshop/5.3-deploy_flow/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 2: CHUẨN BỊ TÊN MIỀN \u0026 BẢO MẬT (ROUTE 53 \u0026 ACM)\rTrước khi tạo CloudFront, ta cần chuẩn bị Chứng chỉ bảo mật (SSL) và DNS.\nBước 2.1: Tạo Hosted Zone (Nếu chưa có)\rVào Route 53 \u003e Hosted zones.\nNếu chưa có domain sgutodolist.com trong list:\nClick Create hosted zone.\nDomain name: sgutodolist.com.\nType: Public hosted zone.\nClick Create.\nCập nhật Nameservers bên nhà cung cấp tên miền vì project sử dụng tên miền mua ở nhà cung cấp khác Khi nhấp vào Hosted zone vừa tạo, ta sẽ thấy được 4 name servers có dạng ns-1538.awsdns-00.co.uk. ns-1374.awsdns-43.org. ns-172.awsdns-21.com. ns-547.awsdns-04.net.\rDùng 4 name servers đó để cập nhật từ trang quản lý domain mà ta thuê của nhà cung cấp khác Bước 2.2: Xin cấp chứng chỉ SSL (ACM) - Quan trọng!\r⚠️ LƯU Ý: Chứng chỉ cho CloudFront BẮT BUỘC phải nằm ở region US East (N. Virginia).\nChuyển Region console về US East (N. Virginia).\nVào AWS Certificate Manager (ACM) \u003e Request certificate.\nChọn Request a public certificate \u003e Next.\nDomain names:\nsgutodolist.com\n*.sgutodolist.com (Để dùng cho cả www).\nValidation method: DNS validation (Recommended).\nClick Request.\nTrong danh sách Certificates, bấm vào ID vừa tạo (Status: Pending validation).\nMục Domains, bấm nút Create records in Route 53.\nClick Create records.\nĐợi vài phút đến khi Status chuyển sang Issued (Màu xanh).",
    "description": "GIAI ĐOẠN 2: CHUẨN BỊ TÊN MIỀN \u0026 BẢO MẬT (ROUTE 53 \u0026 ACM)\rTrước khi tạo CloudFront, ta cần chuẩn bị Chứng chỉ bảo mật (SSL) và DNS.\nBước 2.1: Tạo Hosted Zone (Nếu chưa có)\rVào Route 53 \u003e Hosted zones.",
    "tags": [],
    "title": "Route 53 and ACM",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.3-route-53-and-acm/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Blog 1: Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\nBlog 2: Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\nBlog 3: Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\nBlog 4: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên\nBlog 5: Ra Mắt Strands Agents 1.0: Việc điều phối Multi-Agent cho môi trường production đã được đơn giản hóa\nBlog 6: Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\nBlog 7: Những hiểu biết sâu sắc và bài học kinh nghiệm từ Amazon Q trong tích hợp trình thu thập thông tin web Connect\nBlog 8: Xây dựng hệ thống đa tenant resilient với hàng đợi công bằng Amazon SQS\nBlog 9: Amazon Braket ra mắt bộ xử lý lượng tử siêu dẫn 54-qubit IQM Emerald\nWeek 10: Empower đã mở rộng quy mô đảm bảo chất lượng trung tâm liên hệ như thế nào với Amazon Connect và Amazon Bedrock\nWeek 11: Làm thế nào để quản lý Bot AI bằng AWS WAF và tăng cường bảo mật\nWeek 12: Hỗ trợ tùy chỉnh trên quy mô lớn: Biến một KB (Cơ sở kiến thức) Salesforce hợp nhất thành các tác tử AI tập trung vào LOB (Ngành kinh doanh)",
    "description": "Blog 1: Một giải pháp có khả năng mở rộng cao cho việc sao chép dữ liệu, sử dụng Amazon FSx for NetApp ONTAP và NetApp SnapMirror.\nBlog 2: Tăng tốc Đổi mới Hàng không Vũ trụ: High Performance Computing (HPC) trên Amazon Web Services (AWS)\nBlog 3: Khắc phục sự cố Môi trường Elastic Beanstalk bằng Amazon Q Developer CLI\nBlog 4: Triển khai liên tục dựa trên phương pháp GitOps với ArgoCD và EKS bằng cách sử dụng ngôn ngữ tự nhiên",
    "tags": [],
    "title": "Translated Blogs",
    "uri": "/vi/3-translated_blogs/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 3 Objectives\rStudy Module 2 in the First Cloud Journey Bootcamp – 2025 playlist Learn and get familiar with Route 53, CloudFormation, and their related features Design the database and set up Backend \u0026 Frontend Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Learn about Route 53 and its features 22/09/2025 22/09/2025 Route 53 2 Practice creating Key Pair, CloudFormation Template, and configuring Security Group 23/09/2025 23/09/2025 Create Key Pair, CloudFormation Template 3 Practice creating Key Pair, CloudFormation Template, and configuring Security Group 24/09/2025 24/09/2025 Create Key Pair, CloudFormation Template, Security Group Team meeting to discuss Database Design, Backend, and Frontend 4 Practice connecting to RDGW via RDP 25/09/2025 25/09/2025 Connecting to RDGW, YouTube Tutorial Design solution architecture Team meeting to discuss workshop project 5 Practice deploying Microsoft Active Directory 26/09/2025 26/09/2025 Deploy Microsoft AD Practice configuring DNS Configure DNS Update worklog",
    "description": "Week 3 Objectives\rStudy Module 2 in the First Cloud Journey Bootcamp – 2025 playlist Learn and get familiar with Route 53, CloudFormation, and their related features Design the database and set up Backend \u0026 Frontend Update worklog structure Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Learn about Route 53 and its features 22/09/2025 22/09/2025 Route 53 2 Practice creating Key Pair, CloudFormation Template, and configuring Security Group 23/09/2025 23/09/2025 Create Key Pair, CloudFormation Template 3 Practice creating Key Pair, CloudFormation Template, and configuring Security Group 24/09/2025 24/09/2025 Create Key Pair, CloudFormation Template, Security Group Team meeting to discuss Database Design, Backend, and Frontend 4 Practice connecting to RDGW via RDP 25/09/2025 25/09/2025 Connecting to RDGW, YouTube Tutorial Design solution architecture Team meeting to discuss workshop project 5 Practice deploying Microsoft Active Directory 26/09/2025 26/09/2025 Deploy Microsoft AD Practice configuring DNS Configure DNS Update worklog",
    "tags": [],
    "title": "Week 3 Worklog",
    "uri": "/vi/1-worklog/1.3-week_3/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Triển khai liên tục theo GitOps với ArgoCD và EKS bằng ngôn ngữ tự nhiên\rTác giả: Jagdish Komakula, Aditya Ambati, Anand Krishna Varanasi Ngày: 17/07/2025\nDanh mục: Amazon Elastic Kubernetes Service (EKS), Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to\nGiới thiệu\rArgoCD là một công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernetes theo mô hình khai báo, trong đó Git đóng vai trò là nguồn chân lý duy nhất (single source of truth). ArgoCD cung cấp nhiều tính năng mạnh mẽ như:\nĐồng bộ hóa tự động\nKhả năng khôi phục (rollback)\nPhát hiện sai lệch cấu hình\nChiến lược triển khai nâng cao\nTích hợp RBAC\nHỗ trợ đa cụm (multi-cluster)\nNhờ đó, ArgoCD trở thành lựa chọn phổ biến cho việc triển khai ứng dụng trên Kubernetes. Tuy nhiên, khi tổ chức mở rộng quy mô, nhiều thách thức vận hành bắt đầu xuất hiện.\nĐiểm khó khăn khi sử dụng ArgoCD theo cách truyền thống\rRào cản kỹ thuật cao Giao diện UI và CLI của ArgoCD yêu cầu người dùng hiểu rõ YAML, kiến trúc Kubernetes và các mối quan hệ giữa tài nguyên. Điều này làm hạn chế khả năng tiếp cận GitOps với các bên liên quan không chuyên về kỹ thuật và tăng phụ thuộc vào đội ngũ DevOps.\nQuản lý đa cụm phức tạp Các mô hình như hub-spoke, per-cluster hoặc grouped làm tăng độ phức tạp trong vận hành, khi phải quản lý nhiều instance ArgoCD và duy trì cấu hình nhất quán.\nThiếu tích hợp tác vụ tiền/hậu triển khai ArgoCD không hỗ trợ sẵn các bước như quét image hoặc kiểm thử tải, buộc các nhóm phải sử dụng công cụ ngoài hoặc script tùy chỉnh, gây phân mảnh quy trình.\nChuyển đổi môi trường kém linh hoạt Việc promotion ứng dụng từ Dev → Test → Prod thường phải làm thủ công hoặc qua script, làm chậm quá trình phát hành.\nQuản lý RBAC và khả năng hiển thị khó khăn Trong môi trường đa cụm, việc quản lý quyền truy cập và giám sát có thể dẫn đến rủi ro bảo mật tiềm ẩn.\nCách ArgoCD MCP Server và Amazon Q CLI giải quyết vấn đề\rViệc tích hợp ArgoCD MCP Server với Amazon Q CLI mang lại trải nghiệm GitOps hoàn toàn mới thông qua ngôn ngữ tự nhiên.\nNhững lợi ích chính:\nCho phép người dùng quản lý ứng dụng ArgoCD bằng câu lệnh hội thoại thay vì CLI hoặc YAML.\nDân chủ hóa GitOps cho các vai trò như QA, Product Manager hay Support Engineer.\nĐơn giản hóa quản lý đa cụm và đa môi trường.\nMCP Server đảm nhiệm xác thực, quản lý session và xử lý lỗi.\nAmazon Q cung cấp gợi ý theo ngữ cảnh và phản hồi chi tiết.\nHỗ trợ tự động hóa và gỡ lỗi bằng AI, đóng vai trò như một DevOps ảo.\nVí dụ câu lệnh:\n“Những ứng dụng nào đang out-of-sync ở production?”\n“Đồng bộ ứng dụng api-service.”\nSo sánh ArgoCD truyền thống và ArgoCD MCP + Amazon Q CLI\r| Tiêu chí | ArgoCD truyền thống | MCP Server + Amazon Q CLI |\n|——–|——————-|————————–|\n| Giao diện | UI/CLI kỹ thuật | Ngôn ngữ tự nhiên |\n| Người dùng không kỹ thuật | Hạn chế | Dễ tiếp cận |\n| Quản lý đa cụm | Phức tạp | Được trừu tượng hóa |\n| Tiền/Hậu triển khai | Dùng công cụ ngoài | Dễ gọi qua AI |\n| Promotion môi trường | Thủ công | Hội thoại |\n| Khắc phục sự cố | Phụ thuộc kỹ thuật | Có AI hỗ trợ |\n| Tự động hóa | Script | AI/Agent |\nCác thao tác hỗ trợ bằng ngôn ngữ tự nhiên\rThông qua tích hợp Amazon Q CLI, bạn có thể:\nQuản lý ứng dụng ArgoCD\nĐồng bộ và theo dõi trạng thái\nTrực quan hóa cây tài nguyên\nGiám sát sức khỏe tài nguyên\nTheo dõi sự kiện\nTruy xuất log\nThực hiện hành động trên tài nguyên Kubernetes\nThiết lập môi trường\rĐiều kiện tiên quyết\rTài khoản AWS\nAWS CLI ≥ 2.13.0\nNode.js ≥ 18.0.0\nnpm ≥ 9.0.0\nAmazon Q CLI ≥ 1.0.0 ```bash\nnpm install -g @aws/amazon-q-cli\nCụm EKS (≥ 1.27) với ArgoCD ≥ 2.8\nKết nối với EKS\naws eks update-kubeconfig --name \u003ccluster_name\u003e --region \u003cregion\u003e --role-arn \u003ciam_role_arn\u003e\rkubectl get pods -n argocd\rkubectl port-forward svc/blueprints-addon-argocd-server -n argocd 8080:443\rTích hợp Amazon Q CLI với ArgoCD MCP\n{ \"mcpServers\": { \"argocd-mcp-stdio\": { \"type\": \"stdio\", \"command\": \"npx\", \"args\": [\"argocd-mcp@latest\", \"stdio\"], \"env\": { \"ARGOCD_BASE_URL\": \"\u003cARGOCD_BASE_URL\u003e\", \"ARGOCD_API_TOKEN\": \"\u003cARGOCD_API_TOKEN\u003e\", \"NODE_TLS_REJECT_UNAUTHORIZED\": \"0\" } } } }\rTổng kết\nViệc tích hợp Amazon Q CLI với ArgoCD thông qua MCP Server đánh dấu một bước tiến quan trọng trong quản lý Kubernetes. Giải pháp này chuyển đổi các thao tác phức tạp thành tương tác hội thoại tự nhiên, giúp:\nGiảm gánh nặng kỹ thuật\nTăng tốc triển khai\nMở rộng GitOps cho toàn bộ tổ chức\nThay vì ghi nhớ lệnh và xử lý YAML, các nhóm giờ đây có thể quản lý hạ tầng cloud thông qua đối thoại, giúp hành trình cloud-native trở nên dễ tiếp cận và hiệu quả hơn.",
    "description": "Triển khai liên tục theo GitOps với ArgoCD và EKS bằng ngôn ngữ tự nhiên\rTác giả: Jagdish Komakula, Aditya Ambati, Anand Krishna Varanasi Ngày: 17/07/2025\nDanh mục: Amazon Elastic Kubernetes Service (EKS), Amazon Q, Amazon Q Developer, Developer Tools, Technical How-to\nGiới thiệu\rArgoCD là một công cụ GitOps hàng đầu giúp các nhóm quản lý việc triển khai Kubernetes theo mô hình khai báo, trong đó Git đóng vai trò là nguồn chân lý duy nhất (single source of truth). ArgoCD cung cấp nhiều tính năng mạnh mẽ như:",
    "tags": [],
    "title": "Blog 4",
    "uri": "/vi/3-translated_blogs/blog_4/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop",
    "content": "HEHEHEHE THIS IS WORKSHOP CLEANUP",
    "description": "HEHEHEHE THIS IS WORKSHOP CLEANUP",
    "tags": [],
    "title": "Clean Up",
    "uri": "/vi/5-workshop/5.4-clean_up/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 3: CẤU HÌNH CLOUDFRONT (CDN \u0026 FAILOVER)\rBƯỚC 3.1: Tạo Distribution\rStep 1: Get started\rDistribution name: sgutodolist-frontend-cloudfront\nDistribution type: Giữ nguyên Single website or app.\nDomain:\nTại ô Route 53 managed domain, nhập: sgutodolist.com.\n(Nếu có ô Alternate domain names, nhập thêm www.sgutodolist.com nếu giao diện cho phép, nếu không ta sẽ thêm sau).\nBấm Next.\nStep 2: Specify origin\rOrigin type: Chọn Amazon S3.\nOrigin:\nBấm vào ô tìm kiếm, chọn bucket Singapore: sgutodolist-frontend-sg.... Allow private S3 bucket access to CloudFront:\nChọn: Allow private S3 bucket access to CloudFront - Recommended. Cache settings: Giữ nguyên “Use recommended cache settings…”.\nBấm Next.\nStep 3: Enable security\rWeb Application Firewall (WAF):\nChọn ô bên phải: Do not enable security protections (để tiết kiệm chi phí). Bấm Next.\nStep 4: Get TLS certificate\rTLS certificate:\nChọn chứng chỉ ACM đã tạo: sgutodolist.com (...). Bấm Next.\nStep 5: Review and create\rKéo xuống dưới cùng và bấm nút màu cam Create distribution. BƯỚC 3.1 (Bổ sung): Cấu hình sau khi tạo (Bắt buộc)\rOrigin access control: bước này làm sau khi tạo Distribution thành công, vào tab Origin của Distribution vừa tạo, click vào origin và nhấn edit\n- Click **Create new OAC**. - Name: `S3-OAC-HA`. - Signing behavior: **Sign requests**. - Click **Create**. Tiếp đó:\n1. Copy Policy (Quan trọng):\nClick vào Distribution vừa tạo\nVào tab Origin của Distribution vừa tạo\nClick vào origin trong danh sách Origins và nhấn nút Edit\nBấm nút Copy policy ở Origin access control. Sang tab S3 Console \u003e Bucket Singapore \u003e Permissions \u003e Bucket Policy \u003e Paste vào \u003e Save. 2. Thêm Default Root Object (Sửa lỗi màn hình trắng):\nTrong màn hình chi tiết Distribution vừa tạo, chọn tab General (Tab đầu tiên).\nKéo xuống mục Settings, bấm nút Edit (nằm bên phải mục Settings).\nTìm ô Default root object.\nNhập: index.html.\n(Tiện thể kiểm tra mục Alternate domain names (CNAMEs): Đảm bảo đã có cả sgutodolist.com và www.sgutodolist.com. Nếu thiếu thì Add item thêm vào).\nKéo xuống bấm Save changes.\nBước 3.2: Thêm Origin Phụ (Virginia)\rVào Distribution vừa tạo \u003e Tab Origins.\nClick Create origin.\nOrigin domain: Chọn bucket Virginia (sgutodolist-frontend-us.s3...).\nOrigin access: Chọn lại cái S3-OAC-HA đã tạo lúc nãy.\nName: Failover-US.\nClick Create origin.\nBước 3.3: Tạo Origin Group (Kích hoạt High Availability)\rVẫn ở tab Origins \u003e Click Create origin group.\nName: HighAvailability-Group.\nOrigins:\nAdd Primary-SG (Lên trên - Ưu tiên 1).\nAdd Failover-US (Xuống dưới - Ưu tiên 2).\nFailover criteria: Tích chọn: 500, 502, 503, 504.\nClick Create origin group.\nTa sẽ có 2 origins và 1 origin group: Bước 3.4: Cập nhật Behavior\rTab Behaviors \u003e Chọn Default (*) \u003e Edit.\nOrigin and origin groups: Đổi từ Primary-SG sang HighAvailability-Group.\nClick Save changes.\nBước 3.5: Cấu hình SPA Routing (Xử lý lỗi 404 React)\rTab Error pages \u003e Create custom error response.\nRule 1 (Cho OAC):\nHTTP error code: 403.\nCustomize error response: Yes.\nResponse page path: /index.html.\nHTTP response code: 200.\nRule 2 (Cho React Router):\nTạo thêm 1 cái tương tự cho mã 404. (Path vẫn là /index.html, code 200).",
    "description": "GIAI ĐOẠN 3: CẤU HÌNH CLOUDFRONT (CDN \u0026 FAILOVER)\rBƯỚC 3.1: Tạo Distribution\rStep 1: Get started\rDistribution name: sgutodolist-frontend-cloudfront",
    "tags": [],
    "title": "ClouFront and Failover",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.4-cloufront-and-failover/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1\rEvent Name: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nDate \u0026 Time: 8:30 AM Saturday, September 6, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nDescription: A kick-off event for FCAJ members to meet up and be familiar with the support \u0026 admin team, as well as get to know about the program\nOutcomes: Gained a clear understanding about the FCAJ program and know about the support team and admin team members\nEvent 2",
    "description": "During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1\rEvent Name: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nDate \u0026 Time: 8:30 AM Saturday, September 6, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City",
    "tags": [],
    "title": "Events Participated",
    "uri": "/vi/4-events_participated/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 4 Objectives\rBegin coding the backend authentication service and frontend Discuss and list the APIs required for the TaskFlow Service Learn and practice S3 Explore API Gateway Translate technical blogs Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss architecture and backend/frontend configuration 29/09/2025 29/09/2025 Translate blog Translated Blog 1 Research and list APIs needed for the TaskFlow Service 2 Learn and practice Amazon S3 service 30/09/2025 30/09/2025 https://www.youtube.com/watch?v=3vSrTeWroSs\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=86 Code backend Authentication Service 3 Code backend Authentication Service 01/10/2025 01/10/2025 Initialize frontend project (React setup, env config, routing, folder structure, Git) 4 Learn and practice API Gateway service 02/10/2025 02/10/2025 https://www.youtube.com/watch?v=pgpWyn_6zlA, https://www.youtube.com/watch?v=YjOjDtprDSo Code backend Authentication Service Set up UI/CSS libraries (Tailwind, MUI), define global styles, build base components Translate blogs Translated Blog 2, Translated Blog 3 5 Code backend Authentication Service 03/10/2025 03/10/2025 Set up UI/CSS libraries and reusable components Code frontend: Header, Footer, Sidebar, Landing Page (basic responsive) Translate blogs Translated Blog 4, Translated Blog 5",
    "description": "Week 4 Objectives\rBegin coding the backend authentication service and frontend Discuss and list the APIs required for the TaskFlow Service Learn and practice S3 Explore API Gateway Translate technical blogs Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss architecture and backend/frontend configuration 29/09/2025 29/09/2025 Translate blog Translated Blog 1 Research and list APIs needed for the TaskFlow Service 2 Learn and practice Amazon S3 service 30/09/2025 30/09/2025 https://www.youtube.com/watch?v=3vSrTeWroSs\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=86 Code backend Authentication Service 3 Code backend Authentication Service 01/10/2025 01/10/2025 Initialize frontend project (React setup, env config, routing, folder structure, Git) 4 Learn and practice API Gateway service 02/10/2025 02/10/2025 https://www.youtube.com/watch?v=pgpWyn_6zlA, https://www.youtube.com/watch?v=YjOjDtprDSo Code backend Authentication Service Set up UI/CSS libraries (Tailwind, MUI), define global styles, build base components Translate blogs Translated Blog 2, Translated Blog 3 5 Code backend Authentication Service 03/10/2025 03/10/2025 Set up UI/CSS libraries and reusable components Code frontend: Header, Footer, Sidebar, Landing Page (basic responsive) Translate blogs Translated Blog 4, Translated Blog 5",
    "tags": [],
    "title": "Week 4 Worklog",
    "uri": "/vi/1-worklog/1.4-week_4/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Ra mắt Strands Agents 1.0: Đơn giản hóa điều phối Multi-Agent cho môi trường production\rRyan Coleman, Belle Guttman Ngày: 15/07/2025 Chủ đề: Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source\nHôm nay, chúng tôi vui mừng giới thiệu Strands Agents SDK phiên bản 1.0, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production.\nStrands Agents là một SDK mã nguồn mở theo hướng model-driven, cho phép bạn xây dựng và vận hành các agent AI chỉ với vài dòng code. SDK này có thể mở rộng từ những agent đơn lẻ đơn giản cho đến các hệ thống multi-agent phức tạp, đồng thời hỗ trợ đầy đủ từ môi trường phát triển cục bộ đến triển khai production.\nKể từ khi ra mắt bản preview vào tháng 5/2025, Strands đã đạt:\nHơn 2.000 sao GitHub\nHơn 150.000 lượt tải trên PyPI\nPhiên bản Strands Agents 1.0 mang mức độ đơn giản tương tự cho các hệ thống multi-agent, thông qua:\nBốn primitive chính cho multi-agent orchestration Hỗ trợ Agent-to-Agent (A2A) protocol Quản lý session bền vững cho production Cải thiện hỗ trợ bất đồng bộ (async) toàn diện Mở rộng hỗ trợ nhiều nhà cung cấp mô hình AI\nCác ví dụ code hoàn chỉnh có tại https://strandsagents.com.\nĐơn giản hóa mô hình Multi-Agent\rHệ thống multi-agent cho phép các agent chuyên biệt phối hợp với nhau để giải quyết những bài toán phức tạp mà một agent đơn lẻ không thể xử lý hiệu quả. Strands 1.0 giới thiệu bốn primitive trực quan, giúp điều phối nhiều agent trở nên tự nhiên và dễ mở rộng.\n1. Agents-as-Tools: Ủy quyền theo cấp bậc\rMô hình agents-as-tools cho phép biến các agent chuyên biệt thành công cụ để agent điều phối gọi tới. Agent điều phối giữ quyền kiểm soát tổng thể, đồng thời chủ động tham vấn các “chuyên gia” khi cần — tương tự cách làm việc trong các nhóm con người.\nfrom strands import Agent, tool from strands_tools import calculator, file_write, python_repl, journal @tool def web_search(query: str) -\u003e str: return \"Dummy web search results here!\" research_analyst_agent = Agent( system_prompt=\"You are a research specialist\", tools=[web_search, calculator, file_write, python_repl] ) travel_advisor_agent = Agent( system_prompt=\"You are a travel expert\", tools=[web_search, journal] ) @tool def research_analyst(query: str) -\u003e str: return str(research_analyst_agent(query)) @tool def travel_advisor(query: str) -\u003e str: return str(travel_advisor_agent(query)) executive_assistant = Agent( tools=[research_analyst, travel_advisor] )\r2. Handoffs: Chuyển giao quyền kiểm soát rõ ràng\nHandoffs cho phép agent chủ động chuyển trách nhiệm sang con người khi gặp yêu cầu vượt ngoài phạm vi xử lý, trong khi vẫn giữ nguyên toàn bộ ngữ cảnh hội thoại.\nfrom strands import Agent from strands_tools import handoff_to_user agent = Agent( system_prompt=\"Ask users for more info when needed\", tools=[handoff_to_user] )\rCơ chế này rất phù hợp với các hệ thống hỗ trợ khách hàng, nơi agent đóng vai trò tuyến đầu và con người xử lý các trường hợp đặc biệt.\n3. Swarms: Nhóm agent tự tổ chức\nSwarms cho phép nhiều agent phối hợp động thông qua bộ nhớ dùng chung. Các agent có thể tự tổ chức, bổ trợ lẫn nhau để cho ra kết quả tổng hợp tốt nhất.\nfrom strands import Agent from strands.multiagent import Swarm researcher = Agent(name=\"researcher\") analyst = Agent(name=\"analyst\") writer = Agent(name=\"writer\") market_research_team = Swarm([researcher, analyst, writer]) result = market_research_team(\"Create a report on AI history\")\r4. Graphs: Quy trình xác định và kiểm soát\nGraphs cho phép định nghĩa rõ ràng luồng xử lý, điều kiện rẽ nhánh và các điểm kiểm soát chất lượng, phù hợp cho các workflow có quy tắc nghiệp vụ nghiêm ngặt.\nfrom strands.multiagent import GraphBuilder builder = GraphBuilder() builder.set_entry_point(\"analyze\") graph = builder.build()\rCác mô hình này có thể kết hợp linh hoạt: agents-as-tools trong swarms, swarms trong graphs, hoặc graphs điều phối swarms.\nHệ thống Multi-Agent với A2A\nStrands 1.0 hỗ trợ đầy đủ Agent-to-Agent (A2A) — một tiêu chuẩn mở cho phép các agent từ nhiều nền tảng khác nhau giao tiếp với nhau qua mạng.\nMỗi agent có Agent Card mô tả khả năng\nTự động khám phá và tích hợp agent bên thứ ba\nPhù hợp cho hệ sinh thái agent phân tán\nfrom strands.multiagent.a2a import A2AServer a2a_agent = A2AServer(agent=local_agent, port=9000) a2a_agent.serve()\rSẵn sàng cho môi trường production\nMặc dù đã được sử dụng nội bộ trong các dịch vụ như Amazon Q Developer và AWS Glue, Strands 1.0 được hoàn thiện dựa trên phản hồi từ hàng trăm khách hàng toàn cầu.\nQuản lý session bền vững\nSessionManager cho phép lưu trữ và khôi phục trạng thái agent từ các backend như:\nFile system\nAmazon S3\nĐiều này đảm bảo agent duy trì đầy đủ ngữ cảnh ngay cả khi restart hoặc scale hệ thống.\nHỗ trợ bất đồng bộ và streaming\nStrands 1.0 hỗ trợ async native trên toàn bộ stack, cho phép:\nThực thi song song nhiều agent\nStreaming phản hồi theo thời gian thực\nHủy tác vụ khi người dùng rời khỏi giao diện\nasync for event in agent.stream_async(message): ...\rHỗ trợ đa dạng mô hình AI\nStrands cho phép sử dụng nhiều mô hình khác nhau cho từng agent, bao gồm:\nAmazon Bedrock\nOpenAI\nAnthropic\nMeta\nCohere\nMistral\nStability\nWriter\nViệc hoán đổi mô hình không yêu cầu thay đổi logic hoặc công cụ.\nKết luận\nStrands Agents 1.0 đưa kiến trúc multi-agent từ giai đoạn thử nghiệm lên production-ready. Với khả năng mở rộng linh hoạt, hỗ trợ tiêu chuẩn mở như A2A và cộng đồng đóng góp mạnh mẽ, Strands đang trở thành một trong những nền tảng đơn giản và hiệu quả nhất để xây dựng hệ thống agent AI hiện đại.\nBắt đầu ngay hôm nay tại https://strandsagents.com",
    "description": "Ra mắt Strands Agents 1.0: Đơn giản hóa điều phối Multi-Agent cho môi trường production\rRyan Coleman, Belle Guttman Ngày: 15/07/2025 Chủ đề: Amazon Machine Learning, Announcements, Artificial Intelligence, Open Source\nHôm nay, chúng tôi vui mừng giới thiệu Strands Agents SDK phiên bản 1.0, đánh dấu một cột mốc quan trọng trong hành trình giúp việc xây dựng các agent AI trở nên đơn giản, đáng tin cậy và sẵn sàng cho môi trường production.",
    "tags": [],
    "title": "Blog 5",
    "uri": "/vi/3-translated_blogs/blog_5/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop",
    "content": "1. Hugo Commands\r2. Git Commands\r2.1 Check repository status\ngit status\r2.2 List branches (local)\ngit branch\r2.3 List all branches (local + remote)\ngit branch -a\r2.4 Switch to another branch\ngit checkout \u003cbranch-name\u003e\rExample: git checkout developer\n2.5 Create and switch to a new branch\ngit checkout -b \u003cbranch-name\u003e\rExample: git checkout -b feature/login\n2.6 Pull latest updates from remote\ngit pull\r2.7 Fetch updates without merging\ngit fetch\r2.8 Add files to staging\ngit add \u003cfile\u003e\rAdd all changes: git add .\n2.9 Commit changes\ngit commit -m \"your message\"\r2.10 Push changes to remote\ngit push\rPush a new branch for the first time:\ngit push -u origin \u003cbranch-name\u003e\r2.11 View remote**\ngit remote -v\r2.12 Merge a branch into the current branch\ngit merge \u003cbranch-name\u003e\rExample:\ngit checkout main git merge developer\r2.13 Delete a branch Delete local branch:\ngit branch -d \u003cbranch-name\u003e\rDelete remote branch:\ngit push origin --delete \u003cbranch-name\u003e\r2.14 Undo changes Discard changes in a file:\ngit checkout -- \u003cfile\u003e\rReset everything to last commit:\ngit reset --hard\r3. Powershell commands\nCommand to automatically update file _index.md for all the weeks in a defined directory # Đường dẫn tới thư mục của Dương Bình Minh $targetDir = \"content/1-Worklog/1.3-DuongBinhMinh\" # Kiểm tra xem thư mục có tồn tại không if (-not (Test-Path $targetDir)) { Write-Host \"Lỗi: Không tìm thấy thư mục $targetDir\" -ForegroundColor Red break } # Lấy danh sách các folder con $folders = Get-ChildItem -Path $targetDir -Directory foreach ($folder in $folders) { if ($folder.Name -match \"Week_(\\d+)\") { $weekNum = $matches[1] $filePath = Join-Path $folder.FullName \"_index.md\" if (Test-Path $filePath) { # Đọc nội dung file $content = Get-Content -Path $filePath -Raw -Encoding UTF8 # Tạo nội dung pre mới $newPreLine = \"pre = `\" \u003cb\u003e 1.3.$weekNum. \u003c/b\u003e `\"\" # Thay thế dòng pre cũ $newContent = $content -replace '(?m)^pre\\s*=\\s*\".*\"', $newPreLine # Ghi đè lại file Set-Content -Path $filePath -Value $newContent -Encoding UTF8 # ĐÃ SỬA DÒNG NÀY: Dùng $($weekNum) để tránh lỗi cú pháp với dấu hai chấm Write-Host \"Đã sửa Week $($weekNum): $newPreLine\" -ForegroundColor Green } else { Write-Host \"Bỏ qua $folder.Name (Không tìm thấy _index.md)\" -ForegroundColor Yellow } } } Write-Host \"Hoàn tất cập nhật!\" -ForegroundColor Cyan\rCommand to automatically standardize folder names, convert ‘Leaf Bundles’ to ‘Branch Bundles’, update Frontmatter ‘pre’ values, and repair broken internal links for all users # --- CONFIGURATION --- $worklogPath = \"content/1-Worklog\" # --- HELPER FUNCTION: Fix index.md -\u003e _index.md --- Function Fix-IndexFileName ($dirPath) { $wrongFile = Join-Path $dirPath \"index.md\" $correctFile = Join-Path $dirPath \"_index.md\" if (Test-Path $wrongFile) { if (-not (Test-Path $correctFile)) { Rename-Item -Path $wrongFile -NewName \"_index.md\" Write-Host \" [File] Fixed index.md -\u003e _index.md\" -ForegroundColor Magenta } } } # --- START PROCESSING --- Write-Host \"=== STARTING HUGO DATA STANDARDIZATION ===\" -ForegroundColor Cyan # 1. Get all user directories (e.g., 1.1, 1.2, 1.3...) $userFolders = Get-ChildItem -Path $worklogPath -Directory foreach ($userFolder in $userFolders) { # Check if folder matches pattern \"1.x-Name\" if ($userFolder.Name -match \"^(\\d+\\.\\d+)-\") { $userPrefix = $matches[1] Write-Host \"`n--- Processing User: $($userFolder.Name) (Prefix: $userPrefix) ---\" -ForegroundColor Cyan # STEP 1: Fix the User's main _index.md Fix-IndexFileName $userFolder.FullName $parentIndexFile = Join-Path $userFolder.FullName \"_index.md\" if (Test-Path $parentIndexFile) { $pContent = Get-Content -Path $parentIndexFile -Raw -Encoding UTF8 # Fix Hugo shortcode syntax warning (\u003c \u003e to % %) # Tách chuỗi '{' + '{' để Hugo không hiểu nhầm là shortcode $pContent = $pContent -replace '\\{\\{\u003c\\s*relref', ('{' + '{% relref') $pContent = $pContent -replace '\u003e\\}\\}\\)', ('%' + '}})') # Repair broken links to match the current User Prefix $pContent = [Regex]::Replace($pContent, 'relref\\s*\"[^\"]*?Week_(\\d+)\"', { param($m) $w = $m.Groups[1].Value return 'relref \"' + \"$userPrefix.$w-Week_$w\" + '\"' }) Set-Content -Path $parentIndexFile -Value $pContent -Encoding UTF8 Write-Host \" [Link] Updated links in parent _index.md\" -ForegroundColor Green } # STEP 2: Process Sub-folders (Weeks) $weekFolders = Get-ChildItem -Path $userFolder.FullName -Directory | Where-Object { $_.Name -match \"Week_\" } foreach ($weekFolder in $weekFolders) { if ($weekFolder.Name -match \"Week_(\\d+)\") { $weekNum = $matches[1] # A. Standardize Folder Name (e.g., 1.3.1-Week_1) $correctFolderName = \"$userPrefix.$weekNum-Week_$weekNum\" $currentFolderPath = $weekFolder.FullName if ($weekFolder.Name -ne $correctFolderName) { try { Rename-Item -Path $currentFolderPath -NewName $correctFolderName -ErrorAction Stop $currentFolderPath = Join-Path $userFolder.FullName $correctFolderName Write-Host \" [Folder] Renamed to: $correctFolderName\" -ForegroundColor Yellow } catch { Write-Host \" [Error] Could not rename folder $($weekFolder.Name)\" -ForegroundColor Red continue } } # B. Fix Bundle Type inside the Week folder Fix-IndexFileName $currentFolderPath $childIndexFile = Join-Path $currentFolderPath \"_index.md\" if (Test-Path $childIndexFile) { $cContent = Get-Content -Path $childIndexFile -Raw -Encoding UTF8 # C. Update 'pre' in Frontmatter for Sidebar Navigation $newPre = \"pre = `\" \u003cb\u003e $userPrefix.$weekNum. \u003c/b\u003e `\"\" if ($cContent -match '(?m)^pre\\s*=') { $cContent = $cContent -replace '(?m)^pre\\s*=\\s*\".*\"', $newPre } else { $cContent = $cContent -replace '(?m)^weight\\s*=\\s*(\\d+)', \"weight = `$1`n$newPre\" } Set-Content -Path $childIndexFile -Value $cContent -Encoding UTF8 Write-Host \" [Pre] Updated frontmatter pre to: $userPrefix.$weekNum.\" -ForegroundColor Gray } } } } } Write-Host \"`n=== COMPLETED! PLEASE RUN: hugo server -D ===\" -ForegroundColor Green\rCommand to create multiple folders at a time $basePath = \"D:\\IT\\AWS-FCJ\\AWS-Workshop\\content\\5-Workshop\" $folders = @( \"5.1-Workshop_Overview\", \"5.2-Prerequisite\", \"5.3-Deploy_Flow\", \"5.4-Clean_Up\" ) foreach ($f in $folders) { $fullPath = Join-Path $basePath $f New-Item -ItemType Directory -Path $fullPath -Force | Out-Null New-Item -ItemType File -Path (Join-Path $fullPath \"_index.md\") -Force | Out-Null }\rCommand to create one folder at a time $basePath = \"D:\\IT\\AWS-FCJ\\AWS-Workshop\\content\\5-Workshop\" $folderName = \"5.1-Workshop_Overview\" # \u003c-- Change name here $fullPath = Join-Path $basePath $folderName New-Item -ItemType Directory -Path $fullPath -Force | Out-Null New-Item -ItemType File -Path (Join-Path $fullPath \"_index.md\") -Force | Out-Null\rCommand to read the whole project structure tree /f /a\rCommand to read a directory structure tree content/1-Worklog/1.1-PhanCanhTuanDat /F",
    "description": "1. Hugo Commands\r2. Git Commands\r2.1 Check repository status\ngit status\r2.2 List branches (local)\ngit branch\r2.3 List all branches (local + remote)\ngit branch -a\r2.4 Switch to another branch",
    "tags": [],
    "title": "Mystic Skills",
    "uri": "/vi/5-workshop/5.5-mystic-skills/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 4: CẤP QUYỀN S3 (POLICY)\rCloudFront cần “giấy phép” để lấy file từ 2 bucket kín của bạn.\nTrong CloudFront \u003e Tab Origins.\nChọn Origin Singapore \u003e Edit \u003e Copy policy.\nMở tab mới \u003e S3 Console \u003e Bucket sgutodolist-frontend-sg.\nTab Permissions \u003e Bucket Policy \u003e Edit \u003e Paste \u003e Save.\nLặp lại với Bucket Virginia:\nQuay lại CloudFront \u003e Chọn Origin Virginia \u003e Edit \u003e Copy policy.\nSang S3 sgutodolist-frontend-us \u003e Permissions \u003e Bucket Policy \u003e Paste \u003e Save.",
    "description": "GIAI ĐOẠN 4: CẤP QUYỀN S3 (POLICY)\rCloudFront cần “giấy phép” để lấy file từ 2 bucket kín của bạn.\nTrong CloudFront \u003e Tab Origins.\nChọn Origin Singapore \u003e Edit \u003e Copy policy.\nMở tab mới \u003e S3 Console \u003e Bucket sgutodolist-frontend-sg.\nTab Permissions \u003e Bucket Policy \u003e Edit \u003e Paste \u003e Save.",
    "tags": [],
    "title": "S3 Policy",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.5-s3-policy/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 5 Objectives\rContinue frontend and backend development Learn EC2 Auto Scaling Group Practice AWS CloudShell setups Translate blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 06/10/2025 06/10/2025 - Translate blogs Translated Blog 6, Translated Blog 7 - Code backend Authentication Service, User Service - Install state management library (Redux), define the initial State Model, integrate API services for Login/Register pages. 2 - Learn and practice EC2 Auto Scaling Group 07/10/2025 07/10/2025 Module-03-02 - EC2 Autoscaling - EFS/FSx - Lightsail - MGN, AWS EC2 Auto Scaling : Step By Step Tutorial - Code backend Authentication Service, User Service, Taskflow Service - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Translate blog Translated Blog 8, Translated Blog 9 3 - Code backend Authentication Service, User Service 08/10/2025 08/10/2025 - Learn and pratice Kafka for messaging - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Update worklog 4 - Code backend Authentication Service, User Service 09/10/2025 09/10/2025 - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Learn about Caching to apply cache for database - Translate blog Translated Blog 10, Translated Blog 11 5 - Learn and practice using CloudShell 10/10/2025 10/10/2025 AWS Certified Cloud Practitioner Certification Course (CLF-C02) - Translate blog Translated Blog 12",
    "description": "Week 5 Objectives\rContinue frontend and backend development Learn EC2 Auto Scaling Group Practice AWS CloudShell setups Translate blogs. Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 - Team meeting to discuss about the development process 06/10/2025 06/10/2025 - Translate blogs Translated Blog 6, Translated Blog 7 - Code backend Authentication Service, User Service - Install state management library (Redux), define the initial State Model, integrate API services for Login/Register pages. 2 - Learn and practice EC2 Auto Scaling Group 07/10/2025 07/10/2025 Module-03-02 - EC2 Autoscaling - EFS/FSx - Lightsail - MGN, AWS EC2 Auto Scaling : Step By Step Tutorial - Code backend Authentication Service, User Service, Taskflow Service - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Translate blog Translated Blog 8, Translated Blog 9 3 - Code backend Authentication Service, User Service 08/10/2025 08/10/2025 - Learn and pratice Kafka for messaging - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Update worklog 4 - Code backend Authentication Service, User Service 09/10/2025 09/10/2025 - Code frontend: Build UI for displaying main data lists (table, grid). Integrate Get List API and Pagination. - Learn about Caching to apply cache for database - Translate blog Translated Blog 10, Translated Blog 11 5 - Learn and practice using CloudShell 10/10/2025 10/10/2025 AWS Certified Cloud Practitioner Certification Course (CLF-C02) - Translate blog Translated Blog 12",
    "tags": [],
    "title": "Week 5 Worklog",
    "uri": "/vi/1-worklog/1.5-week_5/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Multi-Region SaaS Task Managemen Web Application\rOverview\rThis project is …..\nContent\r1. Workshop Overview\n2. Prerequisite\n3. Deploy Flow\n4. Clean Up\n5. Mystic Skills",
    "description": "Multi-Region SaaS Task Managemen Web Application\rOverview\rThis project is …..\nContent\r1. Workshop Overview\n2. Prerequisite\n3. Deploy Flow",
    "tags": [],
    "title": "Workshop",
    "uri": "/vi/5-workshop/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\rEric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)\nViệc phân tích lượng dữ liệu genomic và multiomic ngày càng gia tăng đòi hỏi các giải pháp tính toán hiệu quả, có khả năng mở rộng và tiết kiệm chi phí. Amazon Web Services (AWS) tiếp tục hỗ trợ các workload này thông qua các dịch vụ tính toán tăng tốc FPGA như các instance Amazon EC2 F2.\nGiải pháp phân tích thứ cấp DRAGEN (Dynamic Read Analysis for GENomics) của Illumina đã khẳng định vị thế là một trong những giải pháp phân tích thứ cấp hàng đầu cho dữ liệu sequencing thế hệ mới, cung cấp các thuật toán được tối ưu hóa cao cho phân tích genomic và triển khai tăng tốc phần cứng cho các pipeline phân tích toàn diện về genomics và multiomics, bao gồm DNA germline, DNA somatic, cũng như phân tích RNA ở mức bulk và single-cell, proteomics, spatial, và nhiều hơn nữa.\nDRAGEN chạy nguyên bản trên các instance EC2 F2 và cung cấp cho khách hàng một phương pháp nhanh chóng để phân tích tập dữ liệu sinh học của họ. Việc di chuyển sang F2 được đơn giản hóa vì cùng một DRAGEN AMI được sử dụng cho cả F1 và F2, và kết quả phân tích sẽ tương đương nhau. Trong bài viết này, chúng tôi sẽ thảo luận về các đặc tính hiệu năng của DRAGEN trên các môi trường tính toán AWS khác nhau, cũng như cách triển khai phiên bản DRAGEN v4.4 mới ra mắt gần đây trên các instance Amazon EC2 F2.\nTổng quan về các instance Amazon EC2 F2\rCác instance F2 là thế hệ thứ 2 của các instance EC2 được trang bị FPGA để tăng tốc phân tích dữ liệu genomic và multimedia trong môi trường cloud. Những instance này mang lại cải tiến đáng kể so với thế hệ trước — các instance F1 — với hiệu suất giá thành được cải thiện tốt hơn tới 60%. Dưới đây là các tính năng và thông số kỹ thuật chính của instance F2:\nCấu hình FPGA: Instance F2 được trang bị tối đa tám AMD Virtex UltraScale+ HBM VU47P FPGAs, mỗi FPGA tích hợp 16GB bộ nhớ băng thông cao (HBM – High-Bandwidth Memory).\nBộ xử lý: Được vận hành bởi bộ vi xử lý AMD EPYC thế hệ thứ 3 (Milan), instance F2 cung cấp tới 192 vCPU — gấp ba lần số lõi xử lý so với instance F1.\nBộ nhớ: Instance này hỗ trợ tới 2 TiB bộ nhớ hệ thống, gấp đôi dung lượng bộ nhớ của instance F1.\nLưu trữ: F2 đi kèm với tối đa 7.6 TiB bộ nhớ SSD NVMe, gấp đôi dung lượng lưu trữ của F1.\nNetworking: Tốc độ băng thông mạng lên tới 100 Gbps, cao gấp bốn lần so với băng thông mạng có sẵn trên instance F1.\nInstance Name FPGAs vCPUs Instance Memory NVMe Storage Network Bandwidth f1.2xlarge 1 8 122 470 Up to 10 Gbps f1.4xlarge 2 16 244 940 10 Gbps f2.6xlarge 1 24 256 950 10 Gbps F2.12xlarge 2 48 512 1900 25 Gbps f1.16xlarge 8 64 976 44x940 25 Gbps F2.48xlarge 8 192 2048 7600 100 Gbps Bảng 1: Bảng so sánh thông số kỹ thuật về compute, memory, storage, và networking giữa các instance F1 và F2.\nPhương pháp đánh giá hiệu năng\rIllumina khuyến nghị sử dụng f1.4xlarge khi dùng instance F1 và f2.6xlarge khi dùng instance F2. Để đánh giá hiệu năng trên các instance này, DRAGEN đã được cấu hình và chạy trên AWS theo hướng dẫn người dùng Illumina DRAGEN, và các liên kết tới genome reference file có thể tìm thấy trên trang web Illumina DRAGEN Product Files.\nPhân tích Whole Genome Sequencing (WGS) với độ phủ khoảng 35x sử dụng một mẫu có sẵn công khai. Mẫu HG002 từ dự án NIST Genome in a Bottle đã được sử dụng. Mẫu này được phân tích bằng DRAGEN v4.4 Germline pipeline theo hai cách khác nhau. Phân tích “cơ bản” chỉ bao gồm alignment cơ bản và small variant calling, nhằm tạo điều kiện so sánh với các pipeline tin sinh học phổ biến cho mẫu germline như BWA/GATK. Phân tích “đầy đủ” sử dụng tất cả các variant caller, bao gồm cả copy number và structural variants, cùng các tùy chọn bổ sung như gọi pharmacogenetic star allele và gọi HLA (Human Leukocyte Antigen), để tạo ra một bộ genome được phân tích đầy đủ. Trong cả hai trường hợp, tham chiếu đồ thị multigenome hg38 của DRAGEN được sử dụng cho phân tích WGS. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: fastq R1, fastq R2.\nPhân tích Tumor-Normal sử dụng một cặp mẫu đã được khảo sát trong một ấn phẩm về phân tích ung thư của DRAGEN trước đây. Hai mẫu này có độ phủ khoảng 110x (tumor) và 40x (normal). Các mẫu được phân tích bằng DRAGEN v4.4 Somatic pipeline, bao gồm alignment, small variant calling, cũng như phân tích CNV và SV. Phân tích Tumor-Normal sử dụng hg38 linear genome reference của DRAGEN. Các file dữ liệu fastq của mẫu có thể truy cập trên Amazon S3 qua các liên kết: Tumor fastq R1, Tumor fastq R2, Normal fastq R1, Normal fastq R2.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích WGS\rPhân tích WGS sử dụng DRAGEN v4.4 cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn cho ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích WGS cơ bản, bao gồm alignment và small variant calling. DRAGEN v4.4 chạy trên f2.6xlarge đạt tốc độ nhanh hơn 1,5 lần và chỉ tốn 40% chi phí compute EC2 so với f1.4xlarge.\nPhân tích WGS đầy đủ, bao gồm alignment, small variant calling, calling of CNVs, SVs, repeat expansions, và variant annotation. Phân tích DRAGEN trên f2.6xlarge đạt tốc độ nhanh gấp 2 lần và chỉ tốn 30% chi phí compute EC2 so với f1.4xlarge.\nHình 1: Instance f2.6xlarge nhanh hơn 1.5 lần trong Phân tích WGS cơ bản và nhanh hơn 2.1 lần trong Phân tích WGS đầy đủ so với f1.4xlarge.\nHình 2: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 40% chi phí trên f1.4xlarge cho Phân tích WGS cơ bản và bằng 30% chi phí trên f1.4xlarge cho Phân tích WGS đầy đủ.\nSo sánh hiệu năng về tốc độ và chi phí: Phân tích Tumor-Normal\rGiống như kết quả WGS, trong phân tích Tumor-Normal, DRAGEN v4.4 cũng cho thấy lợi thế đáng kể về hiệu suất chi phí trên các instance Amazon EC2 F2 so với F1, đồng thời vẫn tạo ra kết quả phân tích tương đương giữa hai thế hệ instance¹:\nPhân tích Tumor-Normal, bao gồm alignment, small variant calling và calling CNVs/SVs. Phân tích bằng DRAGEN trên f2.6xlarge đạt tốc độ nhanh hơn 1.7 lần và chỉ tốn 35% chi phí compute EC2 so với f1.4xlarge. Hình 3: Instance f2.6xlarge nhanh hơn 1.7 lần so với f1.4xlarge trong Phân tích Tumor-Normal.\nHình 4: Chi phí compute EC2 trên f2.6xlarge chỉ bằng 35% chi phí trên f1.4xlarge cho Phân tích Tumor-Normal WGS.\nCác lợi ích khác\rCác pipeline phân tích genomic truyền thống sử dụng BWA-MEM và GATK chạy trên CPU từng là tiêu chuẩn công nghiệp trong quá khứ, nhưng DRAGEN đã ngày càng được ưa chuộng nhờ những ưu thế vượt trội về tốc độ và độ chính xác. Nhiều công bố đã được bình duyệt đã so sánh tốc độ và độ chính xác của DRAGEN với các pipeline dựa trên BWA/GATK chạy trên CPU. Ví dụ, Ziegler et al. (2022) đã phát hiện ra rằng phân tích DRAGEN trên phần cứng FPGA nhanh hơn gấp hơn 8 lần và chính xác hơn so với các pipeline dựa trên BWA/GATK chạy trên CPU, trong khi Sedlazek et al. (2024) cũng ghi nhận DRAGEN cho hiệu suất và độ chính xác cao hơn so với các pipeline dựa trên BWA/GATK.\nViệc sử dụng DRAGEN trên các instance F, được tăng tốc bởi FPGA, còn mang lại lợi thế về tiêu thụ điện năng so với các giải pháp truyền thống dựa trên CPU và GPU. FPGA vốn dĩ tiết kiệm năng lượng hơn, tiêu thụ ít điện năng hơn nhưng vẫn đạt hiệu năng tính toán tương đương cho các workload này. Điều này đặc biệt quan trọng trong các tác vụ phân tích dữ liệu genomic, nơi khối lượng dữ liệu và thời gian xử lý có thể rất lớn.\nChẳng hạn, FPGA đạt được hiệu suất trên mỗi watt cao hơn so với CPU và GPU trong các tác vụ WGS của DRAGEN. Các bộ tăng tốc dựa trên FPGA có thể cung cấp thông lượng vượt trội với mức tiêu thụ điện năng thấp hơn. Điều này là nhờ khả năng tùy chỉnh linh hoạt của FPGA, cho phép cấu hình tối ưu hóa nhằm nâng cao hiệu quả năng lượng. Ngược lại, CPU và GPU, dù mạnh mẽ, thường tiêu tốn nhiều năng lượng hơn để thực hiện cùng một tác vụ, dẫn đến chi phí vận hành cao hơn và tác động môi trường lớn hơn.\nViệc tiêu thụ điện năng thấp hơn của các FPGA dẫn đến giảm các yêu cầu về làm mát, đây có thể là một yếu tố chi phí đáng kể trong các môi trường điện toán quy mô lớn. Ngoài ra, hiệu quả năng lượng của FPGA khiến chúng trở thành lựa chọn hấp dẫn cho các ứng dụng điện toán hiệu năng cao, nơi khả năng mở rộng và hiệu quả chi phí đóng vai trò then chốt.\nTóm lại, việc triển khai DRAGEN trên các instance thuộc họ ‘F’ của Amazon EC2 mang lại một giải pháp tiết kiệm năng lượng hơn cho phân tích dữ liệu genomic so với các phương pháp truyền thống dựa trên CPU hoặc GPU, đồng thời mang lại cả lợi ích về chi phí lẫn lợi ích môi trường.\nKhả năng triển khai và các tùy chọn triển khai trên cloud của instance F2\rCác instance Amazon EC2 F2 hiện đã có sẵn tại nhiều Region của AWS, bao gồm US East (N. Virginia), US West (Oregon), Europe (London) và Asia Pacific (Sydney), với kế hoạch mở rộng thêm sang nhiều Region khác trong tương lai. F2 cung cấp nhiều kích cỡ khác nhau như f2.6xlarge, f2.12xlarge và f2.48xlarge, nhằm đáp ứng đa dạng nhu cầu workload.\nKhi cấu hình lưu trữ và compute để chạy các workload DRAGEN trên các instance F của AWS, bạn cần lựa chọn các tùy chọn phù hợp để cân bằng giữa hiệu năng và chi phí. Hãy cân nhắc các tùy chọn lưu trữ như là Amazon EBS gp3 volumes được cấu hình theo RAID, Amazon FSx for Lustre cho thông lượng cao hơn và Amazon Elastic File System (EFS) cho lưu trữ liên tục. Ngoài ra, việc truyền trực tuyến các tệp BAM và dữ liệu tham chiếu từ Amazon Simple Storage Service (Amazon S3) hoặc sử dụng Mountpoint for Amazon S3 để mount bucket S3 vào hệ thống file cục bộ giúp truy cập dữ liệu một cách tiết kiệm chi phí và dễ dàng. Bằng cách lựa chọn và cấu hình cẩn thận các giải pháp lưu trữ này, bạn có thể đảm bảo hiệu năng tối ưu và hiệu quả chi phí cho các workload HPC của mình. Bên cạnh đó, bạn cũng nên cân nhắc sử dụng Illumina Connected Analytics (ICA) hoặc AWS Batch để quản lý workflow. Illumina cung cấp hướng dẫn chi tiết về cách triển khai DRAGEN trên AWS trong tài liệu hướng dẫn người dùng DRAGEN trực tuyến của họ.\nKết luận\rTóm lại, các instance Amazon EC2 F2 đánh dấu một bước tiến đáng kể trong lĩnh vực điện toán đám mây được cung cấp bởi FPGA, mang lại hiệu năng, bộ nhớ, dung lượng lưu trữ và khả năng kết nối mạng vượt trội so với thế hệ trước. Sự kết hợp giữa các pipeline toàn diện của DRAGEN và sức mạnh tính toán được nâng cấp của Amazon EC2 F2 cho phép xử lý nhanh hơn, hiệu quả hơn đối với các bộ dữ liệu phức tạp – từ whole genome sequencing đến phân tích single-cell RNA.\nHãy bắt đầu chuyển đổi sang F2 ngay hôm nay. Vui lòng liên hệ với đội ngũ tài khoản AWS của bạn hoặc Illumina để được hỗ trợ trong quá trình chuyển đổi sang Amazon EC2 F2 instances.\nĐể biết thêm thông tin về DRAGEN trên AWS, hãy tìm kiếm DRAGEN Complete Suite trên AWS Marketplace, xem blog DRAGEN v4.4, hoặc truy cập trang chủ Illumina Informatics Solutions.\nTài liệu tham khảo\rScheffler, K. et al. “Somatic small-variant calling methods in Illumina DRAGEN™ Secondary Analysis.” BioRxiv (2023). https://www.biorxiv.org/content/10.1101/2023.03.23.534011v2\nSedlazeck, F. J. et al. “Comprehensive genome analysis and variant detection at scale using DRAGEN.” Nature Biotechnology (2024). https://www.nature.com/articles/s41587-024-02382-1\nZiegler, A. et al. “Comparison of calling pipelines for whole genome sequencing: an empirical study demonstrating the importance of mapping and alignment.” Scientific Reports (2022). https://pubmed.ncbi.nlm.nih.gov/36513709/\nChú thích\rSự tương đương giữa F1 và F2 hard-filtered.vcf cùng các tệp kết quả khác dựa trên kết quả phân tích sử dụng DRAGEN 4.4.4 theo hướng dẫn sử dụng DRAGEN của Illumina. Lệnh vim diff cho thấy sự khác biệt duy nhất giữa hai tệp VCF là một mục hiển thị thời gian thực hiện phân tích. Khách hàng có thể tự thực hiện các phân tích tương tự để xác minh hoặc liên hệ với Illumina để biết thêm thông tin.",
    "description": "Kích hoạt phân tích dữ liệu Genomic và Multiomic nhanh chóng với Illumina DRAGEN™ v4.4 trên các instance Amazon EC2 F2\rEric Allen, Mark Azadpour, Deepthi Shankar, Olivia Choudhury, và Shyamal Mehtalia | 15/07/2025 | High Performance Computing, Life Sciences, Partner solutions\nBài viết này được đóng góp bởi Eric Allen (AWS), Olivia Choudhury (AWS), Mark Azadpour (AWS), Deepthi Shankar (Illumina), và Shyamal Mehtalia (Illumina)",
    "tags": [],
    "title": "Blog 6",
    "uri": "/vi/3-translated_blogs/blog_6/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 5: TRỎ DOMAIN CHÍNH THỨC (DNS RECORD)\rVào Route 53 \u003e Hosted zones \u003e sgutodolist.com.\nTạo Record cho Root domain:\nClick Create record.\nRecord name: (để trống).\nType: A.\nAlias: Yes (Gạt nút sang phải).\nRoute traffic to: Alias to CloudFront distribution.\nChoose distribution: Chọn cái CloudFront domain (ví dụ d123...cloudfront.net).\nClick Create records.\nTạo Record cho WWW:\nLàm tương tự, nhưng Record name điền www.",
    "description": "GIAI ĐOẠN 5: TRỎ DOMAIN CHÍNH THỨC (DNS RECORD)\rVào Route 53 \u003e Hosted zones \u003e sgutodolist.com.\nTạo Record cho Root domain:\nClick Create record.\nRecord name: (để trống).\nType: A.\nAlias: Yes (Gạt nút sang phải).\nRoute traffic to: Alias to CloudFront distribution.\nChoose distribution: Chọn cái CloudFront domain (ví dụ d123...cloudfront.net).",
    "tags": [],
    "title": "DNS Record",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.6-dns-record/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Trong thời gian thực tập tại AMAZON WEB SERVICES VIETNAM COMPANY LIMITED từ ngày 08/09/2025 đến 09/12/2025, tôi đã có cơ hội học hỏi, thực hành và áp dụng những kiến thức đã được học tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia phát triển Ứng dụng Web Quản lý Công việc (Task Management) theo mô hình SaaS đa vùng (Multi-region). Thông qua dự án này, tôi đã nâng cao kỹ năng về Backend Development, các dịch vụ AWS, cũng như kiến trúc Cloud.\nTrong lĩnh vực backend, tôi đã củng cố và phát triển khả năng:\nXây dựng RESTful APIs Làm việc với kiến trúc Microservices Sử dụng hiệu quả nhiều dịch vụ AWS khác nhau Bên cạnh đó, tôi cũng tích lũy được kinh nghiệm thực tế trong việc thiết kế các kiến trúc AWS có khả năng mở rộng, bảo mật và tối ưu chi phí, phù hợp với các dự án thực tế.\nVề tác phong làm việc, tôi luôn nỗ lực hoàn thành nhiệm vụ với chất lượng cao, tuân thủ quy định của nơi làm việc và chủ động phối hợp với các thành viên trong nhóm nhằm nâng cao hiệu suất chung.\nTrong suốt quá trình này, tôi cũng:\nNâng cao kỹ năng làm việc nhóm Phối hợp hiệu quả với các thành viên khác trong đội Mở rộng mạng lưới quan hệ nghề nghiệp thông qua việc kết nối với nhiều bạn bè và anh/chị đồng nghiệp Để phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Năng lực chuyên môn Áp dụng kiến thức backend, xây dựng REST API và viết mã dễ bảo trì 2 Kỹ năng Cloud (AWS) Khả năng làm việc với các dịch vụ AWS như EC2, ECS, Lambda, S3, IAM, CloudFront, v.v 3 Khả năng thiết kế hệ thống Hiểu biết về microservices, kiến trúc đa vùng, khả năng mở rộng và best practices 4 Khả năng học hỏi Thích nghi nhanh với công cụ, framework và các khái niệm cloud mới 5 Tinh thần chủ động và trách nhiệm Chủ động bắt đầu công việc, tự nghiên cứu giải pháp và chịu trách nhiệm với nhiệm vụ được giao 6 Chất lượng bàn giao công việc Độ chính xác, tính ổn định và mức độ hoàn thiện của các nhiệm vụ hoặc tính năng 7 Quản lý thời gian Sắp xếp khối lượng công việc, đảm bảo deadline và ưu tiên hợp lý 8 Kỷ luật nơi làm việc Đúng giờ, tuân thủ quy trình làm việc của nhóm và quy định của công ty 9 Tư duy phát triển Sẵn sàng tiếp nhận phản hồi, cải tiến và không ngừng hoàn thiện bản thân 10 Kỹ năng giao tiếp Trình bày rõ ràng tiến độ, tài liệu hóa công việc và trao đổi vấn đề hiệu quả 11 Khả năng làm việc nhóm Phối hợp với đồng đội, hỗ trợ người khác và đóng góp vào thành công chung 12 Thái độ chuyên nghiệp Cư xử tôn trọng, thái độ tích cực và giao tiếp chuyên nghiệp với đồng nghiệp 13 Kỹ năng giải quyết vấn đề Xác định nguyên nhân gốc rễ, đề xuất giải pháp và tư duy logic 14 Khả năng thích nghi Thích ứng với sự thay đổi, linh hoạt chuyển đổi công việc và duy trì hiệu suất 15 Tính sáng tạo \u0026 đổi mới Đề xuất ý tưởng mới, cải thiện quy trình làm việc hoặc đề xuất tối ưu 16 Mức độ đóng góp tổng thể Tác động đến kết quả dự án, độ tin cậy và hiệu suất trong suốt kỳ thực tập Định hướng cải thiện trong tương lai\rMở rộng và xây dựng mối quan hệ nhiều hơn với các anh/chị và đồng nghiệp Tìm hiểu sâu hơn các dịch vụ AWS để nâng cao mức độ hiểu biết Học hỏi và tiếp thu thêm kiến thức, kinh nghiệm từ các thành viên trong nhóm",
    "description": "Trong thời gian thực tập tại AMAZON WEB SERVICES VIETNAM COMPANY LIMITED từ ngày 08/09/2025 đến 09/12/2025, tôi đã có cơ hội học hỏi, thực hành và áp dụng những kiến thức đã được học tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia phát triển Ứng dụng Web Quản lý Công việc (Task Management) theo mô hình SaaS đa vùng (Multi-region). Thông qua dự án này, tôi đã nâng cao kỹ năng về Backend Development, các dịch vụ AWS, cũng như kiến trúc Cloud.",
    "tags": [],
    "title": "Tự đánh giá",
    "uri": "/vi/6-self-assesment/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Những hiểu biết sâu sắc và bài học kinh nghiệm từ Amazon Q trong tích hợp trình thu thập thông tin web Connect\rTác giả: Vikas Prasad \u0026 Ayush Mehta Ngày: 22/07/2025\nGiới thiệu\rCác nhân viên tổng đài (Human agents) là yếu tố then chốt trong mọi trung tâm chăm sóc khách hàng, và việc cung cấp cho họ các công cụ phù hợp để thành công là điều thiết yếu đối với mọi tổ chức. Khi được hỗ trợ tốt, các nhân viên không chỉ có trải nghiệm làm việc tốt hơn, mà còn giúp nâng cao trải nghiệm của khách hàng cuối cùng.\nĐể đáp ứng nhu cầu này, Amazon Connect giới thiệu Amazon Q in Connect — một trợ lý AI sinh nội dung (Generative AI assistant), cung cấp các phản hồi và hành động gợi ý theo thời gian thực, được cá nhân hóa giúp nhân viên tổng đài thực hiện công việc hiệu quả và nhanh chóng hơn.\nAmazon Q in Connect có thể tích hợp với nhiều cơ sở tri thức (knowledge base) khác nhau thông qua các phương thức tích hợp đa dạng. Bài viết này tập trung vào phương pháp tích hợp bằng Web Crawler, bao gồm những lưu ý quan trọng khi triển khai và các thực hành tốt nhất.\nVì sao cần tích hợp Web Crawler?\rNội dung thường bị phân tán trên nhiều website, buộc agent phải tra cứu nhiều nguồn khác nhau khi hỗ trợ khách hàng. Điều này làm chậm quá trình xử lý và ảnh hưởng đến chất lượng tương tác.\nKhi được cấu hình với Web Crawler, Amazon Q in Connect có thể:\nTự động thu thập và lập chỉ mục nội dung từ nhiều website, trang hỗ trợ Cung cấp cho agent thông tin nhanh chóng và chính xác Hiển thị liên kết nguồn để đối chiếu Loại bỏ việc cập nhật thủ công khi nội dung website thay đổi\nHình 1: Các giai đoạn tối ưu triển khai Web Crawler\n1. Giai đoạn Planning (Lập kế hoạch)\rTrước khi triển khai Web Crawler, bạn nên tham khảo tài liệu chính thức của Amazon Connect – Enable Amazon Q.\nBa nhóm câu hỏi nền tảng cần xác định:\n1.1. Chiến lược quản lý tri thức\rAi chịu trách nhiệm quản lý nội dung (Marketing / IT / CX)?\nQuy trình cập nhật nội dung như thế nào?\nCách đồng bộ nội dung với Amazon Connect\n1.2. Phân tích người dùng cuối\rAgent tuyến 1 hay hỗ trợ kỹ thuật chuyên sâu?\nMức độ chi tiết của nội dung cần crawl?\n1.3. Khả năng truy cập nội dung\rNội dung công khai hay cần xác thực?\nTuân thủ bảo mật \u0026 quyền riêng tư\n2. Giai đoạn Staged Implementation (Triển khai theo giai đoạn)\rTạo từng knowledge base riêng biệt\nKiểm thử độc lập các cấu hình URL\nThu thập phản hồi từ agent\nMở rộng phạm vi crawl theo từng bước\nCách tiếp cận này giúp:\nDễ troubleshoot\nKiểm soát chất lượng dữ liệu\nTối ưu hiệu suất\n3. Giai đoạn Optimization (Tối ưu hóa)\r3.1. Giới hạn dịch vụ\rMỗi crawler tối đa 25.000 file\nCần:\n- Ưu tiên nội dung quan trọng\n- Regex URL\n- Metadata filtering\n3.2. Tốc độ crawl\rBắt đầu crawl rate thấp\nTheo dõi server response\nTránh lỗi 504 Gateway Timeout\n3.3. Phạm vi crawl\rVí dụ seed URL:\n{ \"url\": \"https://example.com/products/\" } { \"url\": \"https://example.com/documentation/\" } 3.4. Chiến lược knowledge base Unified KB → nhiều sản phẩm Separate KBs → từng dòng sản phẩm Có thể dynamic switch bằng: AI Agent override Update Session API 4\\. Giai đoạn Implementation (Triển khai thực tế) 4.1. Execution Timeout Ưu tiên URL Tối ưu crawl pattern Chia nhỏ crawl job 4.2. URL Configuration UI: max 10 URLs API: max 100 URLs Dùng regex thay vì liệt kê thủ công Ví dụ: ```regex .*_domain\\.com/support/.*\\.pdf\rKết luận\nQuy trình tích hợp Web Crawler cho Amazon Q in Connect gồm 4 giai đoạn:\nPlanning\nStaged Implementation\nOptimization\nImplementation\nToàn bộ quy trình mang tính lặp (iterative), liên tục cải thiện dựa trên feedback và metric.\nCác lưu ý quan trọng:\nXác định nội dung ưu tiên cao\nĐặt seed URL hợp lý\nSử dụng regex để lọc chính xác\nTheo dõi qua Amazon CloudWatch Logs\nViệc áp dụng đúng chiến lược giúp Amazon Q in Connect trở thành công cụ tri thức mạnh mẽ, hỗ trợ agent hiệu quả và nâng cao trải nghiệm khách hàng.",
    "description": "Những hiểu biết sâu sắc và bài học kinh nghiệm từ Amazon Q trong tích hợp trình thu thập thông tin web Connect\rTác giả: Vikas Prasad \u0026 Ayush Mehta Ngày: 22/07/2025\nGiới thiệu\rCác nhân viên tổng đài (Human agents) là yếu tố then chốt trong mọi trung tâm chăm sóc khách hàng, và việc cung cấp cho họ các công cụ phù hợp để thành công là điều thiết yếu đối với mọi tổ chức. ",
    "tags": [],
    "title": "Blog 7",
    "uri": "/vi/3-translated_blogs/blog_7/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "Đánh giá tổng quan\r1. Môi trường làm việc\nMôi trường làm việc vô cùng thân thiện, cởi mở và hỗ trợ lẫn nhau. Các thành viên FCAJ luôn sẵn sàng giúp đỡ nhau mỗi khi có khó khăn phát sinh. Mọi người không chỉ trao đổi về công việc mà còn thoải mái chia sẻ về việc học tập, sở thích cá nhân và những câu chuyện thường ngày. Không gian làm việc được sắp xếp gọn gàng, thoải mái, tạo nên bầu không khí tích cực giúp tôi dễ dàng tập trung và duy trì sự hứng thú trong công việc.\n2. Sự hỗ trợ từ Mentor / Đội ngũ hỗ trợ\nCác mentor rất thân thiện, dễ tiếp cận và luôn đưa ra hướng dẫn chi tiết theo từng bước khi các thành viên FCAJ cần hỗ trợ. Cách giải thích của các anh/chị rõ ràng, dễ hiểu và đầy kiên nhẫn. Bên cạnh đó, đội ngũ hỗ trợ luôn đảm bảo các thông báo, tài liệu và thông tin liên quan đến công việc được truyền đạt kịp thời và đầy đủ trong suốt thời gian thực tập. Sự kết hợp giữa hỗ trợ kỹ thuật và hỗ trợ hành chính đã mang lại cho tôi một trải nghiệm suôn sẻ và vô cùng giá trị.\n3. Mức độ liên quan giữa công việc và chuyên ngành học\nNhững nhiệm vụ tôi được giao trong quá trình thực tập có mức độ liên quan cao đến chuyên ngành đang theo học và đóng vai trò quan trọng trong việc củng cố nền tảng kiến thức chuyên môn của tôi. Công việc giúp tôi vận dụng những kiến thức đã học tại trường vào thực tế, đồng thời tiếp thu thêm nhiều kiến thức mới hữu ích cho con đường sự nghiệp mà tôi đang hướng tới. Các nhiệm vụ đều mang tính thực tiễn và phù hợp với định hướng phát triển lâu dài của tôi.\n4. Cơ hội học tập và phát triển kỹ năng\nTrong suốt thời gian thực tập, tôi có cơ hội được tiếp xúc và làm việc trực tiếp với các dịch vụ cốt lõi của AWS như EC2, S3 và ECS. Tôi cũng được hỗ trợ bởi nhiều nguồn học tập chất lượng như AWS Skill Builder và các playlist học tập từ FCAJ. Ngoài ra, các anh/chị đi trước trong đội ngũ hỗ trợ và admin đã chia sẻ nhiều kinh nghiệm thực tế, định hướng nghề nghiệp và những lời khuyên hữu ích, giúp tôi hiểu rõ hơn những kỹ năng và kiến thức cần thiết để phát triển trong lĩnh vực công nghệ và điện toán đám mây.\n5. Văn hóa công ty và tinh thần đồng đội\nVăn hóa công ty rất cởi mở và tích cực, nơi mọi người giao tiếp thoải mái và luôn sẵn sàng hỗ trợ lẫn nhau. Các thành viên thường xuyên trò chuyện, chia sẻ câu chuyện và tạo nên một môi trường làm việc gần gũi, thân thiện. Đặc biệt, có những lúc các mentor còn mua trái cây để mọi người cùng ngồi lại ăn uống và trò chuyện — những hành động nhỏ nhưng mang lại cảm giác ấm áp, gắn kết và hòa đồng.\n6. Chính sách và quyền lợi của chương trình thực tập\nLợi ích lớn nhất mà chương trình thực tập mang lại chính là nền tảng kiến thức vững chắc, đặc biệt là sự hiểu biết về cách một môi trường cloud vận hành trong thực tế. Trải nghiệm này giúp tôi có cái nhìn thực tế hơn về ngành điện toán đám mây đang phát triển mạnh mẽ, đồng thời trang bị những kỹ năng quan trọng cho con đường sự nghiệp trong tương lai. Môi trường hỗ trợ tích cực, cơ hội được tham gia các dự án thực tế cùng với hệ thống tài liệu học tập bài bản đã khiến chương trình thực tập này trở nên vô cùng ý nghĩa và đáng giá.",
    "description": "Đánh giá tổng quan\r1. Môi trường làm việc\nMôi trường làm việc vô cùng thân thiện, cởi mở và hỗ trợ lẫn nhau. Các thành viên FCAJ luôn sẵn sàng giúp đỡ nhau mỗi khi có khó khăn phát sinh. Mọi người không chỉ trao đổi về công việc mà còn thoải mái chia sẻ về việc học tập, sở thích cá nhân và những câu chuyện thường ngày. Không gian làm việc được sắp xếp gọn gàng, thoải mái, tạo nên bầu không khí tích cực giúp tôi dễ dàng tập trung và duy trì sự hứng thú trong công việc.",
    "tags": [],
    "title": "Chia sẻ và Phản hồi",
    "uri": "/vi/7-sharing_and_feedback/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Workshop \u003e Deploy Flow \u003e Frontend Deploy",
    "content": "GIAI ĐOẠN 6: DEPLOY \u0026 KIỂM TRA\rBước 6.1: Build \u0026 Deploy\rTại máy tính local (trong folder project React):\n# 1. Build ra folder production npm run build # 2. Upload lên bucket CHÍNH (Singapore) # Lưu ý: Chỉ cần upload lên Sing, AWS sẽ tự copy sang US aws s3 sync build/ s3://sgutodolist-frontend-sg --delete # 3. Xóa cache CloudFront để user thấy code mới ngay aws cloudfront create-invalidation --distribution-id \u003cID_CUA_BAN\u003e --paths \"/*\"\rBước 6.2: Kiểm tra\rTruy cập https://sgutodolist.com.\nThử reload trang (F5) ở các đường dẫn con (ví dụ /tasks) xem có bị lỗi 404 không.\nKiểm tra Replication: Vào S3 Console bucket Virginia xem file đã tự động xuất hiện chưa (thường mất 15s - 1 phút).",
    "description": "GIAI ĐOẠN 6: DEPLOY \u0026 KIỂM TRA\rBước 6.1: Build \u0026 Deploy\rTại máy tính local (trong folder project React):\n# 1. Build ra folder production npm run build # 2. Upload lên bucket CHÍNH (Singapore) # Lưu ý: Chỉ cần upload lên Sing, AWS sẽ tự copy sang US aws s3 sync build/ s3://sgutodolist-frontend-sg --delete # 3. Xóa cache CloudFront để user thấy code mới ngay aws cloudfront create-invalidation --distribution-id \u003cID_CUA_BAN\u003e --paths \"/*\"\rBước 6.2: Kiểm tra\rTruy cập https://sgutodolist.com.",
    "tags": [],
    "title": "Deploy and Test",
    "uri": "/vi/5-workshop/5.3-deploy_flow/5.3.1-frontend-deploy/5.3.1.7-deploy-and-test/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 20/10/2025 20/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 2 Learn about Application Load Balancer (ALB) 21/10/2025 21/10/2025 https://www.youtube.com/watch?v=cuJTmBvFCS0, https://www.youtube.com/watch?v=ZGGpEwThhrM Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 3 Learn how to deploy the system on cloud resources 22/10/2025 22/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 4 Code backend User Service \u0026 Notification Service 23/10/2025 23/10/2025 Code frontend: Build modals, popups, drag-and-drop features; complete ~80% main business flow 5 Code backend User Service \u0026 Notification Service 24/10/2025 24/10/2025 Code frontend: Build modals, popups, drag-and-drop features Test deploying the Frontend on S3",
    "description": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 20/10/2025 20/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 2 Learn about Application Load Balancer (ALB) 21/10/2025 21/10/2025 https://www.youtube.com/watch?v=cuJTmBvFCS0, https://www.youtube.com/watch?v=ZGGpEwThhrM Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 3 Learn how to deploy the system on cloud resources 22/10/2025 22/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 4 Code backend User Service \u0026 Notification Service 23/10/2025 23/10/2025 Code frontend: Build modals, popups, drag-and-drop features; complete ~80% main business flow 5 Code backend User Service \u0026 Notification Service 24/10/2025 24/10/2025 Code frontend: Build modals, popups, drag-and-drop features Test deploying the Frontend on S3",
    "tags": [],
    "title": "Week 7 Worklog",
    "uri": "/vi/1-worklog/1.6-week_6/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 20/10/2025 20/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 2 Learn about Application Load Balancer (ALB) 21/10/2025 21/10/2025 https://www.youtube.com/watch?v=cuJTmBvFCS0, https://www.youtube.com/watch?v=ZGGpEwThhrM Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 3 Learn how to deploy the system on cloud resources 22/10/2025 22/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 4 Code backend User Service \u0026 Notification Service 23/10/2025 23/10/2025 Code frontend: Build modals, popups, drag-and-drop features; complete ~80% main business flow 5 Code backend User Service \u0026 Notification Service 24/10/2025 24/10/2025 Code frontend: Build modals, popups, drag-and-drop features Test deploying the Frontend on S3",
    "description": "Week 7 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 20/10/2025 20/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 2 Learn about Application Load Balancer (ALB) 21/10/2025 21/10/2025 https://www.youtube.com/watch?v=cuJTmBvFCS0, https://www.youtube.com/watch?v=ZGGpEwThhrM Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 3 Learn how to deploy the system on cloud resources 22/10/2025 22/10/2025 Code backend User Service \u0026 Notification Service Code frontend: Develop Detail Page, integrate Get By ID API, build advanced Search \u0026 Filter 4 Code backend User Service \u0026 Notification Service 23/10/2025 23/10/2025 Code frontend: Build modals, popups, drag-and-drop features; complete ~80% main business flow 5 Code backend User Service \u0026 Notification Service 24/10/2025 24/10/2025 Code frontend: Build modals, popups, drag-and-drop features Test deploying the Frontend on S3",
    "tags": [],
    "title": "Week 7 Worklog",
    "uri": "/vi/1-worklog/1.7-week_7/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Xây dựng hệ thống đa-tenant resilient với Amazon SQS Fair Queues\rTác giả: Maximilian Schellhorn \u0026 Dirk Fröhner\nNgày: 21/07/2025\nChuyên mục: Amazon Simple Queue Service (SQS), Announcements, Intermediate (200), Serverless, Technical How-to\nGiới thiệu\rAWS chính thức giới thiệu Amazon SQS Fair Queues — một tính năng mới giúp giảm thiểu hiện tượng noisy neighbor trong các hệ thống multi-tenant. Với fair queues, ứng dụng trở nên resilient hơn, dễ vận hành hơn, đồng thời giảm chi phí vận hành và cải thiện chất lượng dịch vụ cho khách hàng.\nTrong kiến trúc phân tán, message queue đóng vai trò nền tảng để xây dựng các hệ thống có khả năng chịu lỗi cao. Queue hoạt động như một lớp đệm (buffer) giữa các thành phần, cho phép xử lý bất đồng bộ và theo tốc độ riêng của từng service. Khi hệ thống gặp lượng truy cập tăng đột biến, queue giúp ngăn lỗi lan truyền bằng cách giữ lại các task và bảo vệ các service phía sau khỏi quá tải.\nAmazon SQS từ lâu đã là lựa chọn phổ biến để xây dựng ứng dụng có khả năng mở rộng, nhờ là một dịch vụ serverless được quản lý hoàn toàn, có thể xử lý hàng triệu message mỗi giây. Trong bài viết này, bạn sẽ tìm hiểu cách hoạt động của Amazon SQS Fair Queues và cách áp dụng chúng trong hệ thống thực tế.\nTổng quan về bài toán multi-tenant\rNhiều ứng dụng hiện đại áp dụng kiến trúc multi-tenant, trong đó một phiên bản ứng dụng phục vụ nhiều tenant khác nhau. Tenant có thể là khách hàng, ứng dụng client, hoặc một loại request cụ thể. Mô hình này giúp:\nTối ưu chi phí vận hành Đơn giản hóa bảo trì Tăng hiệu quả sử dụng tài nguyên dùng chung Tuy nhiên, kiến trúc multi-tenant đối mặt với vấn đề noisy neighbor — khi một tenant tiêu thụ quá nhiều tài nguyên và ảnh hưởng đến các tenant khác. Trong hệ thống dựa trên queue, tenant này có thể:\nGửi lượng message lớn Có message mất nhiều thời gian xử lý Điều này làm tăng dwell time (thời gian message nằm trong queue) cho tất cả tenant, gây suy giảm chất lượng dịch vụ và buộc hệ thống phải scale dư thừa hoặc xây dựng logic tùy chỉnh phức tạp.\nAmazon SQS Fair Queues giải quyết vấn đề này bằng cách đảm bảo các tenant “yên lặng” vẫn được phục vụ công bằng, mà không cần thay đổi logic xử lý message hiện có ở consumer.\nCách Amazon SQS Fair Queues hoạt động\rAmazon SQS liên tục theo dõi số lượng message in-flight (đã nhận nhưng chưa bị xóa) của từng tenant. Khi phát hiện mất cân bằng, hệ thống sẽ:\nNhận diện tenant gây ồn (noisy tenant) Ưu tiên phân phối message của các tenant yên lặng Duy trì tổng throughput của queue Trạng thái steady state\rKhi không có backlog, message được phân phối đều giữa các tenant. Dwell time thấp cho tất cả tenant.\nKhi xuất hiện noisy tenant\rTenant A gửi lượng lớn message, tạo backlog. Consumer chủ yếu xử lý message của tenant A, khiến dwell time của các tenant khác tăng lên.\nKhi kích hoạt Fair Queues\rSQS xác định tenant A là noisy neighbor và ưu tiên message của các tenant B, C, D. Dwell time của các tenant yên lặng được duy trì thấp, trong khi tenant gây ồn chấp nhận có thời gian chờ cao hơn mà không ảnh hưởng đến tenant khác.\nLưu ý:\nFair queues không giới hạn throughput theo tenant Consumer vẫn xử lý message từ noisy tenant khi còn tài nguyên Không giới hạn số lượng tenant Không ảnh hưởng độ trễ API Cách sử dụng Amazon SQS Fair Queues\r1. Kích hoạt Fair Queues bằng MessageGroupId\rĐể sử dụng Fair Queues:\nProducer gửi message kèm MessageGroupId (định danh tenant) Cấu hình CloudWatch để theo dõi metric Quan sát hành vi queue với workload khác nhau Amazon SQS sẽ tự động kích hoạt Fair Queues cho các SQS Standard Queue chứa MessageGroupId:\nKhông cần thay đổi code consumer Không giới hạn throughput Không tăng latency API 2. Theo dõi bằng Amazon CloudWatch Metrics\rAmazon SQS cung cấp các metric mới để theo dõi Fair Queues:\nApproximateNumberOfNoisyGroups ApproximateNumberOfMessagesVisibleInQuietGroups ApproximateAgeOfOldestMessageInQuietGroups ApproximateNumberOfMessagesNotVisibleInQuietGroups ApproximateNumberOfMessagesDelayedInQuietGroups Metric quan trọng nhất là:\nApproximateNumberOfNoisyGroups\n→ Giúp phát hiện tenant tiêu thụ tài nguyên quá mức và thiết lập cảnh báo.\nCác metric với hậu tố InQuietGroups cho phép theo dõi riêng các tenant không gây ồn, thay vì toàn queue.\nTheo dõi hiệu ứng công bằng\rSo sánh metric InQuietGroups với metric queue thông thường:\nBacklog toàn queue tăng khi có noisy tenant Metric của quiet groups vẫn giữ ở mức thấp Chứng tỏ tenant khác không bị ảnh hưởng Xác định tenant gây tải cao\rSử dụng Amazon CloudWatch Contributor Insights để:\nXác định top-N tenant tiêu thụ nhiều tài nguyên Theo dõi tổng số tenant Tránh chi phí metric cao do high-cardinality Contributor Insights tạo metric từ log ứng dụng, do đó ứng dụng cần log số lượng message và MessageGroupId.\nỨng dụng ví dụ\rAWS cung cấp một sample application để minh họa Amazon SQS Fair Queues:\nLoad generator mô phỏng traffic multi-tenant CloudWatch dashboard trực quan hóa các metric quan trọng Infrastructure as Code (IaC) đầy đủ Mã nguồn và hướng dẫn chạy: 👉 https://github.com/aws-samples/sqs-fair-queues\nKết luận\rAmazon SQS Fair Queues tự động giảm thiểu ảnh hưởng của noisy neighbor trong các hệ thống multi-tenant. Chỉ cần thêm định danh tenant vào message, Amazon SQS sẽ tự động:\nPhát hiện tenant gây ồn Bảo vệ tenant khác khỏi bị ảnh hưởng Duy trì throughput và độ trễ ổn định Tính năng này giúp xây dựng hệ thống resilient, dễ vận hành và tiết kiệm chi phí, đặc biệt phù hợp cho các kiến trúc serverless và event-driven.\nTài liệu tham khảo\rAmazon SQS Developer Guide Amazon SQS Fair Queues Documentation AWS Official Blog",
    "description": "Xây dựng hệ thống đa-tenant resilient với Amazon SQS Fair Queues\rTác giả: Maximilian Schellhorn \u0026 Dirk Fröhner\nNgày: 21/07/2025\nChuyên mục: Amazon Simple Queue Service (SQS), Announcements, Intermediate (200), Serverless, Technical How-to\nGiới thiệu\rAWS chính thức giới thiệu Amazon SQS Fair Queues — một tính năng mới giúp giảm thiểu hiện tượng noisy neighbor trong các hệ thống multi-tenant. Với fair queues, ứng dụng trở nên resilient hơn, dễ vận hành hơn, đồng thời giảm chi phí vận hành và cải thiện chất lượng dịch vụ cho khách hàng.",
    "tags": [],
    "title": "Blog 8",
    "uri": "/vi/3-translated_blogs/blog_8/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 8 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 27/10/2025 27/10/2025 Build the Notification interface, integrate APIs, and establish WebSocket connection Check the services code 2 Code frontend: Write Unit Tests \u0026 Integration Tests for main flows 28/10/2025 28/10/2025 Code backend User Service \u0026 Notification Service Learn and practice Application Load Balancer (ALB) 3 Code frontend: Write Unit Tests \u0026 Integration Tests for main flows 29/10/2025 29/10/2025 Code backend User Service \u0026 Notification Service Experiment deploying static resources on S3 4 Code frontend: Optimize loading performance (Code Splitting, Lazy Loading) 30/10/2025 30/10/2025 Code backend User Service \u0026 Notification Service 5 Code frontend: Improve Accessibility (A11Y) and error handling 31/10/2025 31/10/2025",
    "description": "Week 8 Objectives\rCode Backend User Service and Notification Service Code Frontend Explore the Application Load Balancer service Learn how to deploy the system on cloud resources Test deploying the Frontend on S3 Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 27/10/2025 27/10/2025 Build the Notification interface, integrate APIs, and establish WebSocket connection Check the services code 2 Code frontend: Write Unit Tests \u0026 Integration Tests for main flows 28/10/2025 28/10/2025 Code backend User Service \u0026 Notification Service Learn and practice Application Load Balancer (ALB) 3 Code frontend: Write Unit Tests \u0026 Integration Tests for main flows 29/10/2025 29/10/2025 Code backend User Service \u0026 Notification Service Experiment deploying static resources on S3 4 Code frontend: Optimize loading performance (Code Splitting, Lazy Loading) 30/10/2025 30/10/2025 Code backend User Service \u0026 Notification Service 5 Code frontend: Improve Accessibility (A11Y) and error handling 31/10/2025 31/10/2025",
    "tags": [],
    "title": "Week 8 Worklog",
    "uri": "/vi/1-worklog/1.8-week_8/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Amazon Braket ra mắt bộ xử lý lượng tử siêu dẫn 54-qubit IQM Emerald\rTác giả: Zia Mohammad, Charunethran Panchalam Govindarajan, Peter Komar, Stefan Seegerer Ngày: 21/07/2025 Chuyên mục: Amazon Braket – Quantum Technologies\nGiới thiệu\rAmazon Braket cho phép khách hàng thiết kế và chạy thuật toán lượng tử trên nhiều loại phần cứng lượng tử thông qua một giao diện thống nhất. Hôm nay, AWS mở rộng danh mục phần cứng trên Braket bằng việc chính thức cung cấp bộ xử lý lượng tử (QPU) mới nhất của IQM – IQM Emerald. Đây là một QPU siêu dẫn 54 qubit, cung cấp độ trung thực cổng cao hơn và kết nối lưới vuông đầy đủ (full square lattice connectivity).\nVới việc bổ sung IQM Emerald, khách hàng hiện có thể truy cập hai bộ xử lý lượng tử của IQM trên Amazon Braket:\nIQM Garnet – 20 qubit IQM Emerald – 54 qubit\nCả hai thiết bị đều được triển khai tại Vùng Châu Âu (Stockholm), mở rộng lựa chọn phần cứng cho các hoạt động nghiên cứu và phát triển thuật toán lượng tử.\nHình 1: Bộ xử lý lượng tử IQM Emerald\nTrong giai đoạn hiện tại của điện toán lượng tử, việc thử nghiệm trên nhiều nền tảng phần cứng là cực kỳ quan trọng nhằm đánh giá và phát triển thuật toán cho các bài toán phức tạp trong tài chính, năng lượng, dược phẩm và logistics. Với Amazon Braket, khách hàng có thể chạy workload lượng tử:\nTheo yêu cầu (on-demand)\nQua Hybrid Jobs cho các thuật toán biến phân\nĐặt trước tài nguyên thông qua Braket Direct\nTất cả đều theo mô hình pay-as-you-go.\nKiến trúc nâng cao cho nghiên cứu lượng tử\rIQM Emerald sử dụng kiến trúc Crystal 54, với các qubit transmon siêu dẫn được sắp xếp theo lưới vuông (square lattice) và kết nối bằng các tunable coupler. Thiết kế này cho phép ánh xạ (mapping) thuật toán lượng tử hiệu quả lên topology phần cứng.\nĐáng chú ý, kiến trúc lưới vuông hỗ trợ trực tiếp surface-code error correction, giúp Emerald trở thành nền tảng phù hợp cho các hệ thống lượng tử chịu lỗi trong tương lai.\nThiết bị hỗ trợ:\nCác phép quay X và Y bất kỳ (arbitrary X, Y rotations) cho cổng một qubit Cổng CZ là cổng hai qubit nguyên thủy\nDữ liệu ban đầu cho thấy:\nĐộ trung thực cổng 1-qubit (median): 99.93% Độ trung thực cổng 2-qubit (median): 99.5%\nCác chỉ số cập nhật được hiển thị trong Braket Console.\nHình 2: Topology lưới vuông 54-qubit của QPU Emerald\nTính khả dụng và khả năng truy cập\rCả IQM Emerald và Garnet đều khả dụng 19 giờ mỗi ngày, tạo điều kiện thuận lợi cho khách hàng trên toàn cầu. Việc đặt thiết bị tại EU giúp đáp ứng các yêu cầu về data residency đồng thời tận dụng các workflow hybrid quantum–classical trong cùng môi trường AWS.\nBắt đầu với IQM Emerald trên Amazon Braket\rAmazon Braket cung cấp giao diện lập trình thống nhất cho nhiều framework lượng tử, bao gồm:\nBraket SDK Qiskit PennyLane NVIDIA CUDA-Q\nĐể sử dụng Emerald, bạn chỉ cần chỉ định ARN của thiết bị:\nfrom braket.aws import AwsDevice device = AwsDevice( \"arn:aws:braket:eu-north-1::device/qpu/iqm/Emerald\" )\rVí dụ: Tạo trạng thái Bell\nfrom braket.circuits import Circuit bell = Circuit().h(0).cnot(control=0, target=1) result = device.run(bell, shots=1000).result()\rĐoạn code trên tạo trạng thái Bell bằng cách áp dụng cổng Hadamard lên qubit 0, sau đó CNOT giữa qubit 0 và 1, chạy 1000 shots để thu kết quả.\nKhám phá trạng thái vướng mắc quy mô lớn\nDung lượng 54 qubit cho phép Emerald triển khai các mạch lượng tử phức tạp hơn. Dựa trên các thí nghiệm GHZ trước đây trên Garnet, Emerald có thể tạo trạng thái GHZ 49-qubit nhờ topology kết nối cao.\nVí dụ sử dụng đường đi qua topology của Emerald, áp dụng Hadamard lên qubit đầu và chuỗi CNOT để tạo GHZ state với 5000 shots.\nLập trình nâng cao với Dynamic Circuits\nIQM Emerald hỗ trợ dynamic circuits (tính năng thử nghiệm), cho phép:\nĐo qubit giữa mạch (mid-circuit measurement)\nThực hiện phép toán có điều kiện dựa trên kết quả đo\nTái sử dụng qubit bằng active reset\nGiải thích các thành phần chính:\nEnableExperimentalCapability() – bật dynamic circuits\nmeasure_ff() – đo giữa mạch\ncc_prx() – cổng lượng tử có điều kiện\nadd_verbatim_box() – truyền mạch động trực tiếp xuống phần cứng\nKết quả đo chủ yếu trả về 0, chứng tỏ quá trình active reset hoạt động hiệu quả.\nBắt đầu ngay hôm nay\nBạn có thể bắt đầu với IQM Emerald bằng cách truy cập:\nAmazon Braket Management Console\nGitHub – Amazon Braket Examples\nAWS cũng cung cấp AWS Cloud Credits for Research cho các tổ chức nghiên cứu đủ điều kiện nhằm hỗ trợ chạy các thí nghiệm lượng tử trên Amazon Braket.",
    "description": "Amazon Braket ra mắt bộ xử lý lượng tử siêu dẫn 54-qubit IQM Emerald\rTác giả: Zia Mohammad, Charunethran Panchalam Govindarajan, Peter Komar, Stefan Seegerer Ngày: 21/07/2025 Chuyên mục: Amazon Braket – Quantum Technologies\nGiới thiệu\rAmazon Braket cho phép khách hàng thiết kế và chạy thuật toán lượng tử trên nhiều loại phần cứng lượng tử thông qua một giao diện thống nhất. Hôm nay, AWS mở rộng danh mục phần cứng trên Braket bằng việc chính thức cung cấp bộ xử lý lượng tử (QPU) mới nhất của IQM – IQM Emerald. Đây là một QPU siêu dẫn 54 qubit, cung cấp độ trung thực cổng cao hơn và kết nối lưới vuông đầy đủ (full square lattice connectivity).",
    "tags": [],
    "title": "Blog 9",
    "uri": "/vi/3-translated_blogs/blog_9/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 9 Objectives\rReview and check backend service code Develop and integrate frontend features for Notification \u0026 Auth Adjust and refine system architecture through team discussions Implement and update WebSocket for real-time notifications Integrate Google OAuth2 login for Authentication Service Fix bugs related to WebSocket reconnection and authentication state Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 03/11/2025 03/11/2025 Build the Notification interface, integrate APIs, and establish WebSocket connection Check the services code 2 Update WebSocket for Notification Service 04/11/2025 04/11/2025 Refactor NotificationService flow for real-time push notifications Code frontend: Review services UI for flaws 3 Implement Google OAuth2 Login for Auth Service 05/11/2025 05/11/2025 Test login flow and integrate Google OAuth callback Update worklog 4 Continue integrating Notification \u0026 Auth features on frontend 06/11/2025 06/11/2025 Fix bugs related to WebSocket reconnection \u0026 auth state 5 Testing for the week’s features 07/11/2025 07/11/2025 Prepare weekly report \u0026 deployment checklist",
    "description": "Week 9 Objectives\rReview and check backend service code Develop and integrate frontend features for Notification \u0026 Auth Adjust and refine system architecture through team discussions Implement and update WebSocket for real-time notifications Integrate Google OAuth2 login for Authentication Service Fix bugs related to WebSocket reconnection and authentication state Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss about the development process 03/11/2025 03/11/2025 Build the Notification interface, integrate APIs, and establish WebSocket connection Check the services code 2 Update WebSocket for Notification Service 04/11/2025 04/11/2025 Refactor NotificationService flow for real-time push notifications Code frontend: Review services UI for flaws 3 Implement Google OAuth2 Login for Auth Service 05/11/2025 05/11/2025 Test login flow and integrate Google OAuth callback Update worklog 4 Continue integrating Notification \u0026 Auth features on frontend 06/11/2025 06/11/2025 Fix bugs related to WebSocket reconnection \u0026 auth state 5 Testing for the week’s features 07/11/2025 07/11/2025 Prepare weekly report \u0026 deployment checklist",
    "tags": [],
    "title": "Week 9 Worklog",
    "uri": "/vi/1-worklog/1.9-week_9/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Empower đã mở rộng quy mô đảm bảo chất lượng trung tâm liên hệ như thế nào với Amazon Connect và Amazon Bedrock\rTác giả: Marcos Ortiz, Illan Geller (Accenture), Ozlem Celik-Tinmaz (Accenture), Prabhu Akula (Accenture), và Ryan Baham (Empower)\nNgày: 04/08/2025\nThể loại: Amazon Bedrock, Amazon Connect, Amazon Transcribe, Trung tâm liên hệ, AI tạo sinh\nGiới thiệu\rEmpower là một trong những công ty dịch vụ tài chính hàng đầu tại Hoa Kỳ, phục vụ hơn 18 triệu khách hàng với tổng tài sản quản lý lên đến 1,8 nghìn tỷ USD. Hàng năm, Empower xử lý khoảng 10 triệu cuộc gọi thông qua các trung tâm liên hệ của mình.\nĐể duy trì chất lượng dịch vụ ở quy mô lớn như vậy, Empower đã hợp tác với AWS (Amazon Web Services) và Accenture nhằm chuyển đổi quy trình đảm bảo chất lượng (QA) bằng cách ứng dụng AI tạo sinh. Thông qua việc triển khai một giải pháp tùy chỉnh dựa trên Amazon Connect và Amazon Bedrock, Empower đã mở rộng phạm vi kiểm soát chất lượng cuộc gọi lên gấp 20 lần, đồng thời rút ngắn thời gian đánh giá từ vài ngày xuống chỉ còn vài phút.\nGiải pháp này được đưa vào môi trường sản xuất chỉ trong 7 tháng, cho thấy hiệu quả của việc kết hợp hạ tầng AWS, chuyên môn triển khai của Accenture và tầm nhìn đổi mới công nghệ của Empower.\nThách thức: Đảm bảo chất lượng thủ công ở quy mô lớn\rEmpower sử dụng khung đánh giá GEDAC (Greeting, Engagement, Discovery, Action, Close) để đo lường hiệu suất của tổng đài viên. Trước đây, việc đánh giá được thực hiện thủ công bởi các chuyên viên QA thông qua việc nghe lại ghi âm cuộc gọi và chấm điểm theo các tiêu chí định sẵn.\nCách làm này tồn tại nhiều hạn chế:\nChỉ có thể đánh giá một tỷ lệ rất nhỏ trong số 10 triệu cuộc gọi mỗi năm Tính không nhất quán giữa các chuyên viên đánh giá Thời gian phản hồi chậm, đôi khi kéo dài hàng tuần Không thể mở rộng khi lưu lượng cuộc gọi ngày càng tăng “Để thực sự cải thiện trải nghiệm khách hàng trên quy mô lớn, chúng tôi buộc phải tái định hình hoàn toàn cách tiếp cận đối với việc đảm bảo chất lượng,”\n— Joe Mieras, VP Dịch vụ Thành viên tại Empower\nTổng quan giải pháp\rEmpower đã xây dựng một hệ thống QA tự động dựa trên:\nAmazon Connect Contact Lens: Gỡ băng cuộc gọi, loại bỏ PII Amazon Bedrock + Claude 3.5 Sonnet: Đánh giá nội dung cuộc gọi theo khung GEDAC AWS Lambda, SQS, EventBridge, Step Functions: Điều phối và xử lý hàng loạt Giải pháp xử lý 5.000 bản ghi mỗi ngày, đánh giá nhất quán và ghi kết quả trực tiếp trở lại Amazon Connect.\nSơ đồ kiến trúc tổng thể Quy trình xử lý\rGỡ băng cuộc gọi bằng Amazon Connect Contact Lens Lưu trữ bản ghi vào Amazon S3 EventBridge phát hiện dữ liệu mới Amazon SQS quản lý hàng đợi xử lý AWS Lambda \u0026 Step Functions điều phối quy trình GEDAC Amazon Bedrock đánh giá bằng Claude 3.5 Sonnet Kết quả được ghi trực tiếp vào Amazon Connect Lợi ích của việc tận dụng dịch vụ AWS có sẵn\rTự động loại bỏ PII – đảm bảo tuân thủ ngay từ đầu Không cần xây dựng pipeline ETL tùy chỉnh Giao diện hiển thị kết quả sẵn có trong Amazon Connect Dễ mở rộng và vận hành ở quy mô lớn “Chúng tôi không cần phải phát minh lại bánh xe,”\n— Joseph Mieras, VP Trải nghiệm Khách hàng tại Empower\nBảo mật và AI có trách nhiệm\rGiải pháp đáp ứng đầy đủ các yêu cầu về:\nMã hóa dữ liệu khi truyền và khi lưu trữ Kiểm soát truy cập theo vai trò Ghi log kiểm toán đầy đủ Giám sát mô hình AI liên tục Empower cũng thành lập Ủy ban Quản trị AI, đảm bảo việc triển khai AI phù hợp với các tiêu chuẩn pháp lý, đạo đức và minh bạch.\nKết quả đạt được\rPhạm vi QA tăng 20 lần Thời gian đánh giá giảm từ vài ngày xuống vài phút Đánh giá nhất quán và có khả năng giải thích Nhân sự QA tập trung vào các ca phức tạp và huấn luyện chuyên sâu Bài học kinh nghiệm\rBắt đầu từ mục tiêu kinh doanh rõ ràng Đầu tư nghiêm túc vào thiết kế prompt Lên kế hoạch mở rộng ngay từ đầu AI hỗ trợ, không thay thế con người Cải tiến liên tục dựa trên phản hồi thực tế Hướng phát triển tiếp theo\rEmpower đang xây dựng một nền tảng AI tạo sinh tập trung cho hơn 1.500 lập trình viên, hỗ trợ:\nQuản trị AI tập trung Theo dõi chi phí và hiệu suất Tái sử dụng mô hình và best practices Giải pháp QA trung tâm liên hệ là nền tảng cho chiến lược AI dài hạn của Empower trong toàn doanh nghiệp.",
    "description": "Empower đã mở rộng quy mô đảm bảo chất lượng trung tâm liên hệ như thế nào với Amazon Connect và Amazon Bedrock\rTác giả: Marcos Ortiz, Illan Geller (Accenture), Ozlem Celik-Tinmaz (Accenture), Prabhu Akula (Accenture), và Ryan Baham (Empower)\nNgày: 04/08/2025\nThể loại: Amazon Bedrock, Amazon Connect, Amazon Transcribe, Trung tâm liên hệ, AI tạo sinh",
    "tags": [],
    "title": "Blog 10",
    "uri": "/vi/3-translated_blogs/blog_10/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 10 Objectives\rConduct internal UAT for frontend, collect feedback, fix UI issues, and refine the user interface Fix backend bugs, mainly in Task Service and partially in User Service Participate in team meetings to discuss development workflow, architecture adjustments, and backend issues Update worklogs and track weekly progress Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss the development process 10/11/2025 10/11/2025 Update worklog 10/11/2025 10/11/2025 2 Frontend development: Conduct internal UAT, collect feedback, fix reported issues, and refine UI 11/11/2025 11/11/2025 Backend development: Fix bugs in Task Service 11/11/2025 11/11/2025 3 Frontend development: Continue internal UAT, fix issues, and refine UI 12/11/2025 12/11/2025 Backend development: Fix bugs in Task Service 12/11/2025 12/11/2025 4 Team meeting to discuss architecture adjustments and backend issues 13/11/2025 13/11/2025 Frontend development: Continue UAT and UI refinements 13/11/2025 13/11/2025 Backend development: Fix bugs in Task Service and User Service 13/11/2025 13/11/2025 5 Update worklog 14/11/2025 14/11/2025 Frontend development: Continue UAT, collect feedback, and finalize UI improvements 14/11/2025 14/11/2025",
    "description": "Week 10 Objectives\rConduct internal UAT for frontend, collect feedback, fix UI issues, and refine the user interface Fix backend bugs, mainly in Task Service and partially in User Service Participate in team meetings to discuss development workflow, architecture adjustments, and backend issues Update worklogs and track weekly progress Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss the development process 10/11/2025 10/11/2025 Update worklog 10/11/2025 10/11/2025 2 Frontend development: Conduct internal UAT, collect feedback, fix reported issues, and refine UI 11/11/2025 11/11/2025 Backend development: Fix bugs in Task Service 11/11/2025 11/11/2025 3 Frontend development: Continue internal UAT, fix issues, and refine UI 12/11/2025 12/11/2025 Backend development: Fix bugs in Task Service 12/11/2025 12/11/2025 4 Team meeting to discuss architecture adjustments and backend issues 13/11/2025 13/11/2025 Frontend development: Continue UAT and UI refinements 13/11/2025 13/11/2025 Backend development: Fix bugs in Task Service and User Service 13/11/2025 13/11/2025 5 Update worklog 14/11/2025 14/11/2025 Frontend development: Continue UAT, collect feedback, and finalize UI improvements 14/11/2025 14/11/2025",
    "tags": [],
    "title": "Week 10 Worklog",
    "uri": "/vi/1-worklog/1.10-week_10/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Làm thế nào để quản lý bot AI bằng AWS WAF và tăng cường bảo mật\rTác giả: Kartik Bheemisetty, David MacDonald\nNgày: 01/08/2025\nDanh mục: AWS WAF, Best Practices, Security, Identity \u0026 Compliance, Technical Guide, Thought Leadership\nGiới thiệu\rTrình thu thập dữ liệu web (web crawler) đầu tiên được tạo ra vào năm 1993 nhằm đo lường quy mô của World Wide Web. Kể từ đó, crawler đã phát triển thành những bot hiện đại được hỗ trợ bởi AI, có khả năng tự động hóa và tự hành.\nNgày nay, Internet ngày càng bị chi phối bởi các bot AI tự động tương tác với ứng dụng nhằm phục vụ nhiều tác vụ liên quan đến trí tuệ nhân tạo.\nBot AI có thể được phân thành ba nhóm chính:\nBot AI cào dữ liệu (AI scrapers): Thu thập dữ liệu một cách có hệ thống từ ứng dụng nhằm phục vụ huấn luyện mô hình AI.\nCông cụ AI (AI tools): Hiển thị và sử dụng dữ liệu ứng dụng thông qua các kỹ thuật như Function Calling.\nTác tử AI (AI agents): Có khả năng tự chủ điều hướng và tương tác động với ứng dụng để thực hiện các tác vụ phức tạp.\nMặc dù một số bot AI mang lại giá trị (ví dụ: tự động hóa các tác vụ lặp lại), nhưng bot độc hại có thể gây ra nhiều rủi ro nghiêm trọng đối với ứng dụng web như tiêu tốn tài nguyên, suy giảm hiệu năng hoặc gián đoạn dịch vụ. Nếu không được kiểm soát, các vấn đề này sẽ ảnh hưởng trực tiếp đến bảo mật, niềm tin người dùng và uy tín thương hiệu.\nBài viết này trình bày các rủi ro do bot AI gây ra và cách phát hiện, quản lý bot AI bằng AWS WAF.\nĐiều kiện tiên quyết\rBài viết tập trung vào AWS WAF như tuyến phòng thủ đầu tiên để quan sát và quản lý hoạt động của bot AI nhắm vào ứng dụng.\nNếu bạn chưa bật AWS WAF, hãy bắt đầu bằng việc:\nSử dụng AWS Shield Network Security Director để xác định các tài nguyên chưa được bảo vệ.\nThiết lập cấu hình bảo mật ban đầu thông qua tích hợp một cú nhấp chuột để tạo Web ACL.\nCác tích hợp được hỗ trợ:\nAmazon CloudFront: Bật AWS WAF trực tiếp từ CloudFront.\nApplication Load Balancer (ALB): Bật AWS WAF trực tiếp từ ALB.\nCác vấn đề do bot AI gây ra\rSự bùng nổ của Large Language Models (LLMs) và các tác tử AI tự hành đã khiến hành vi của bot ngày càng tinh vi, đặt ra nhiều thách thức:\n1. Sử dụng dữ liệu độc quyền để huấn luyện mô hình\rViệc thu thập dữ liệu trái phép có thể gây rủi ro về sở hữu trí tuệ và làm giảm giá trị nội dung độc quyền của doanh nghiệp.\n2. Suy giảm hiệu năng và gia tăng chi phí\rBot AI tạo ra lượng lớn lưu lượng truy cập, dẫn đến:\nTăng chi phí truyền dữ liệu (DTO)\nTiêu thụ tài nguyên backend\nNguy cơ gián đoạn dịch vụ\n3. Hành vi tự động không mong muốn\rBot AI có thể cạnh tranh trực tiếp với người dùng hợp lệ trong các quy trình nhạy cảm về thời gian như:\nSăn vé\nMua hàng số lượng giới hạn\nCác kỹ thuật thường được sử dụng:\nFunction calling và tìm kiếm AI\nTự động hóa trình duyệt (Playwright)\nTương tác thông qua môi trường VM\nXác định quy mô hoạt động của bot AI\rĐể đánh giá mức độ ảnh hưởng của bot AI:\n1. Thêm AWS WAF Bot Control – Common Inspection\n2. Đặt rule ở chế độ Count\nSau vài ngày thu thập dữ liệu, bạn có thể phân tích:\nLoại bot\nHành vi truy cập\nKhối lượng lưu lượng\nThông tin này giúp xây dựng chiến lược kiểm soát phù hợp trước khi triển khai các biện pháp chặn.\nQuản lý bot AI\rChặn sớm bằng robots.txt\rKịch bản 1: Chặn bot tuân thủ quy tắc\rTệp robots.txt cho phép kiểm soát các bot tuân thủ tiêu chuẩn. Các dự án như ai.robots.txt cung cấp danh sách bot AI phổ biến để chặn sớm.\nVí dụ:\nUser-agent: Amazonbot Disallow: /private/ Allow: /public/ Kịch bản 2: Kiểm soát cách bot sử dụng dữ liệu Amazonbot: sử dụng header X-Robots-Tag: noarchive Applebot: khai báo User-agent: Applebot-Extended trong robots.txt Googlebot: sử dụng User-agent: Google-Extended Lưu ý: Không phải bot nào cũng tôn trọng robots.txt, vì vậy cần kết hợp AWS WAF. Sử dụng AWS WAF để bảo vệ nâng cao Kịch bản 3: Giảm tác động hiệu năng và chi phí Bot Control -- Common Inspection: Chặn bot AI tự nhận diện (CategoryAI) Rate limiting \u0026 L7 DDoS protection: Bảo vệ trước lưu lượng bất thường AWS WAF Challenge: Buộc bot thực hiện các phép kiểm tra tốn chi phí Honeypot: Dẫn bot vào các endpoint giả để phát hiện hành vi độc hại Kịch bản 4: Quản lý bot AI tự hành Bot Control (Common \u0026 Targeted Inspection) CAPTCHA Các biện pháp xác thực nâng cao (bao gồm sinh trắc học) Kết luận Bot AI mang lại nhiều thách thức về bảo mật, hiệu năng và quyền kiểm soát dữ liệu. Bằng cách kết hợp robots.txt, AWS WAF Bot Control, giới hạn tỷ lệ, CAPTCHA và các kỹ thuật nâng cao khác, doanh nghiệp có thể: Ngăn chặn bot độc hại Giảm chi phí vận hành Vẫn cho phép các bot hợp lệ mang lại giá trị Để tìm hiểu sâu hơn, hãy theo dõi AWS WAF Security Blog và các tài nguyên thuộc lĩnh vực Security, Identity \u0026 Compliance của AWS.",
    "description": "Làm thế nào để quản lý bot AI bằng AWS WAF và tăng cường bảo mật\rTác giả: Kartik Bheemisetty, David MacDonald\nNgày: 01/08/2025\nDanh mục: AWS WAF, Best Practices, Security, Identity \u0026 Compliance, Technical Guide, Thought Leadership\nGiới thiệu\rTrình thu thập dữ liệu web (web crawler) đầu tiên được tạo ra vào năm 1993 nhằm đo lường quy mô của World Wide Web. Kể từ đó, crawler đã phát triển thành những bot hiện đại được hỗ trợ bởi AI, có khả năng tự động hóa và tự hành.",
    "tags": [],
    "title": "Blog 11",
    "uri": "/vi/3-translated_blogs/blog_11/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 11 Objectives\rIdentify and fix existing bugs Complete and refine the solution architecture Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss the development process 17/11/2025 17/11/2025 Adjust the solution architecture 17/11/2025 17/11/2025 Backend development: Fix bugs in User Service 17/11/2025 17/11/2025 2 Backend development: Fix bugs in User Service 18/11/2025 18/11/2025 3 Adjust solution architecture 19/11/2025 19/11/2025 Team meeting to review existing issues in Frontend and Backend 19/11/2025 19/11/2025 4 Adjust solution architecture 20/11/2025 20/11/2025 5 Team meeting 21/11/2025 21/11/2025 Experimental deployment of VPC and Subnets 21/11/2025 21/11/2025",
    "description": "Week 11 Objectives\rIdentify and fix existing bugs Complete and refine the solution architecture Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to discuss the development process 17/11/2025 17/11/2025 Adjust the solution architecture 17/11/2025 17/11/2025 Backend development: Fix bugs in User Service 17/11/2025 17/11/2025 2 Backend development: Fix bugs in User Service 18/11/2025 18/11/2025 3 Adjust solution architecture 19/11/2025 19/11/2025 Team meeting to review existing issues in Frontend and Backend 19/11/2025 19/11/2025 4 Adjust solution architecture 20/11/2025 20/11/2025 5 Team meeting 21/11/2025 21/11/2025 Experimental deployment of VPC and Subnets 21/11/2025 21/11/2025",
    "tags": [],
    "title": "Week 11 Worklog",
    "uri": "/vi/1-worklog/1.11-week_11/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Translated Blogs",
    "content": "Hỗ trợ tùy chỉnh trên quy mô lớn: Chuyển đổi một cơ sở kiến thức Salesforce hợp nhất thành các tác tử AI theo từng LOB\rTác giả: Bhaskar Rao, Saqib M, Dipkumar Mehta, Murtuza Kainan\nNgày: 01/08/2025\nDanh mục: Nâng cao (300), Amazon AppFlow, Amazon Connect, Amazon Q, Customer Engagement, Customer Solutions, Technical Guide\nGiới thiệu\rTrong bối cảnh các hệ thống CRM ngày càng phức tạp, các nhóm hỗ trợ khách hàng thường phải vận hành nhiều sản phẩm và dịch vụ khác nhau trong cùng một nền tảng như Salesforce. Tuy nhiên, việc sử dụng một cơ sở kiến thức (Knowledge Base – KB) hợp nhất cho tất cả các ngành kinh doanh (LOB – Line of Business) khiến nhân viên hỗ trợ mất nhiều thời gian tìm kiếm thông tin liên quan.\nĐiều này dẫn đến:\nTăng thời gian xử lý cuộc gọi Giảm tỷ lệ giải quyết ngay lần đầu Trải nghiệm khách hàng kém\nBài blog này trình bày một cách tiếp cận mở rộng và tối ưu hóa hệ thống kiến thức bằng cách phân tách KB theo từng LOB, kết hợp với Amazon Q in Connect và Salesforce Knowledge.\nThách thức \u0026 Giải pháp\rThách thức\rKhi Salesforce Knowledge được đồng bộ trực tiếp vào Amazon Q in Connect, toàn bộ nội dung được lưu trong một kho hợp nhất. Cách tiếp cận này không phù hợp với các tổ chức đa ngành vì:\nNội dung bị nhiễu\nKết quả tìm kiếm kém liên quan\nHiệu suất AI không tối ưu\nGiải pháp\rSử dụng AI Agents trong Amazon Q in Connect để:\nPhân tách Salesforce Knowledge thành nhiều KB theo từng LOB\nÁp dụng AI Prompts chuyên biệt cho từng lĩnh vực\nGiữ nguyên tích hợp Salesforce, nhưng triển khai logic KB tách biệt\nLợi ích chính:\nKết quả tìm kiếm chính xác hơn Thời gian xử lý nhanh hơn Trải nghiệm nhân viên và khách hàng tốt hơn\nNội dung bạn sẽ học được\rThông qua blog này, bạn sẽ:\nHiểu kiến trúc tích hợp Salesforce → Amazon Q in Connect\nTạo nhiều KB theo LOB từ Salesforce Knowledge\nTự động hóa nhập dữ liệu và phân loại KB\nTriển khai AI Agents và AI Prompts theo từng LOB\nĐo lường hiệu quả hệ thống sau triển khai\nĐo lường thành công\rCác chỉ số đánh giá:\nGiảm thời gian tìm kiếm thông tin của nhân viên Tăng tỷ lệ First Call Resolution (FCR) Nâng cao mức độ hài lòng của khách hàng Dashboard và best practices báo cáo rõ ràng\nTổng quan kiến trúc giải pháp\r(Hình minh họa kiến trúc tổng thể)\nKiến trúc chia Salesforce Knowledge theo từng Business Unit (BU), xử lý dữ liệu qua AppFlow, S3, SQS, Lambda và đồng bộ vào Amazon Q in Connect.\nHướng dẫn triển khai\rA. Tích hợp Salesforce với AWS AppFlow\rSalesforce Knowledge được đồng bộ thông qua AWS AppFlow, với các luồng riêng cho từng BU:\nauto_kb\ncredit_kb\npayments_kb\nAppFlow hỗ trợ:\nOn-Demand Flow: Lấy toàn bộ dữ liệu KB\nIncremental Flow: Đồng bộ các cập nhật mới\nDữ liệu được lưu trữ trong Amazon S3 theo prefix tương ứng.\nB. Phân tách dữ liệu trong Amazon S3\rMỗi BU được lưu tại prefix riêng:\nauto_kb/\ncredit_kb/\npayments_kb/\nS3 Event Notifications được cấu hình để kích hoạt bước xử lý tiếp theo.\nC. Gửi sự kiện S3 đến Amazon SQS\rKhi có dữ liệu mới:\nS3 gửi sự kiện đến Amazon SQS\nSQS đảm bảo tách rời và xử lý ổn định cho pipeline downstream\nD. Xử lý dữ liệu bằng AWS Lambda\rLambda thực hiện:\nLàm sạch (sanitize) HTML\nGhi tệp HTML vào các bucket:\n- qic-auto\n- qic-credit\n- qic-payments\nXử lý các trạng thái:\nPublish/Update → ghi đè nội dung\nArchived → xóa nội dung khỏi S3\nE. Đồng bộ KB với Amazon Q in Connect\rMỗi bucket S3 được liên kết với một KB EXTERNAL trong QiC:\nqic-auto-kb\nqic-credit-kb\nqic-payments-kb\nQiC tự động đồng bộ khi S3 thay đổi.\nF. Tích hợp Amazon Connect \u0026 AI Agents\rLuồng xử lý:\n1. Khách hàng gọi vào Amazon Connect 2. IVR xác định loại LOB 3. AWS Lambda cập nhật Agent Session 4. Gán KB tương ứng thông qua updateSession()\nĐiều kiện tiên quyết\rAWS\rTài khoản AWS hợp lệ\nAWS CLI \u0026 CDK CLI\nQuyền IAM cần thiết\nAmazon Connect\rConnect instance đang hoạt động\nQueue \u0026 quyền quản trị\nSalesforce\rSalesforce Org có API\nSalesforce Knowledge đã bật\nConnected App \u0026 OAuth scopes\nTriển khai CDK\rcdk bootstrap aws://ACCOUNT/REGION cdk diff cdk deploy\rTài nguyên được tạo:\nAppFlow Flows\nLambda Functions\nIAM Roles\nAmazon Q KBs\nAmazon Connect integrations\nXác minh \u0026 Vận hành\nKiểm tra CloudFormation\nChạy AppFlow On-Demand \u0026 Scheduled\nKiểm tra dữ liệu tại S3\nMonitor CloudWatch Logs\nDọn dẹp tài nguyên\nbash\nCopy code\ncdk destroy\nKết luận\nGiải pháp này cho phép các trung tâm liên hệ mở rộng quy mô hiệu quả bằng cách triển khai các tác tử AI theo từng LOB, giúp cung cấp nội dung chính xác, theo ngữ cảnh và theo thời gian thực cho nhân viên hỗ trợ, đồng thời nâng cao trải nghiệm khách hàng.",
    "description": "Hỗ trợ tùy chỉnh trên quy mô lớn: Chuyển đổi một cơ sở kiến thức Salesforce hợp nhất thành các tác tử AI theo từng LOB\rTác giả: Bhaskar Rao, Saqib M, Dipkumar Mehta, Murtuza Kainan\nNgày: 01/08/2025\nDanh mục: Nâng cao (300), Amazon AppFlow, Amazon Connect, Amazon Q, Customer Engagement, Customer Solutions, Technical Guide",
    "tags": [],
    "title": "Blog 12",
    "uri": "/vi/3-translated_blogs/blog_12/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 12 Objectives\rReview issues and deployment approaches Experiment with S3 single-region and multi-region deployment Successfully deploy frontend resources to S3 Update worklog and workshop documentation Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to review issues to be solved 24/11/2025 24/11/2025 Experimental S3 single-region deployment 24/11/2025 24/11/2025 2 Experimental S3 single-region deployment 25/11/2025 25/11/2025 3 Experimental S3 multi-region deployment 26/11/2025 26/11/2025 4 Experimental S3 multi-region deployment 27/11/2025 27/11/2025 5 Deploy frontend resources to S3 successfully 28/11/2025 28/11/2025 Update worklog and workshop documentation 28/11/2025 28/11/2025",
    "description": "Week 12 Objectives\rReview issues and deployment approaches Experiment with S3 single-region and multi-region deployment Successfully deploy frontend resources to S3 Update worklog and workshop documentation Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to review issues to be solved 24/11/2025 24/11/2025 Experimental S3 single-region deployment 24/11/2025 24/11/2025 2 Experimental S3 single-region deployment 25/11/2025 25/11/2025 3 Experimental S3 multi-region deployment 26/11/2025 26/11/2025 4 Experimental S3 multi-region deployment 27/11/2025 27/11/2025 5 Deploy frontend resources to S3 successfully 28/11/2025 28/11/2025 Update worklog and workshop documentation 28/11/2025 28/11/2025",
    "tags": [],
    "title": "Week 12 Worklog",
    "uri": "/vi/1-worklog/1.12-week_12/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 13 Objectives\rReview system issues and team progress Deploy and validate AWS infrastructure components Update and organize worklog documentation Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to review issues to be solved 01/11/2025 01/11/2025 Successful S3 multi-region deployment and access 01/11/2025 01/11/2025 Update worklog: create worklog categories based on team members 01/11/2025 01/11/2025 2 Setup VPC, Subnets, Internet Gateway 02/11/2025 02/11/2025 3 Setup VPC, Subnets, Internet Gateway 03/11/2025 03/11/2025 4 Setup ECR, Fargate 04/11/2025 04/11/2025 5 Setup ECR, Fargate 05/11/2025 05/11/2025",
    "description": "Week 13 Objectives\rReview system issues and team progress Deploy and validate AWS infrastructure components Update and organize worklog documentation Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 Team meeting to review issues to be solved 01/11/2025 01/11/2025 Successful S3 multi-region deployment and access 01/11/2025 01/11/2025 Update worklog: create worklog categories based on team members 01/11/2025 01/11/2025 2 Setup VPC, Subnets, Internet Gateway 02/11/2025 02/11/2025 3 Setup VPC, Subnets, Internet Gateway 03/11/2025 03/11/2025 4 Setup ECR, Fargate 04/11/2025 04/11/2025 5 Setup ECR, Fargate 05/11/2025 05/11/2025",
    "tags": [],
    "title": "Week 13 Worklog",
    "uri": "/vi/1-worklog/1.13-week_13/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập \u003e Nhật ký công việc",
    "content": "Week 14 Objectives\rUpdate weekly tasks and finalize remaining work Review project progress and documentation Prepare final reports and submissions Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 08/11/2025 08/11/2025 2 09/11/2025 09/11/2025 3 10/11/2025 10/11/2025 4 11/11/2025 11/11/2025 5 12/11/2025 12/11/2025",
    "description": "Week 14 Objectives\rUpdate weekly tasks and finalize remaining work Review project progress and documentation Prepare final reports and submissions Tasks to be carried out this week\rDay Task Start Date Completion Date Reference Material 1 08/11/2025 08/11/2025 2 09/11/2025 09/11/2025 3 10/11/2025 10/11/2025 4 11/11/2025 11/11/2025 5 12/11/2025 12/11/2025",
    "tags": [],
    "title": "Week 14 Worklog",
    "uri": "/vi/1-worklog/1.14-week_14/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Thể loại",
    "uri": "/vi/categories/index.html"
  },
  {
    "breadcrumb": "Báo Cáo Thực Tập",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Thẻ",
    "uri": "/vi/tags/index.html"
  }
]
